import logging

from google import genai as google_genai
from google.genai import types
import aiddit.model.gemini_upload_file as gemini_upload_file
import aiddit.utils as utils
from datetime import datetime, timezone
from tenacity import retry, stop_after_attempt, wait_fixed
import os
import json
from tqdm import tqdm
import concurrent.futures
from dotenv import load_dotenv
from aiddit.model.gemini_available_mime_types import AVAILABLE_MIME_TYPES

load_dotenv()

api_key = os.getenv("google_genai_api_key")
cache_dir = os.getenv("google_genai_upload_file_cache_dir")
generate_image_save_dir_path = os.getenv("google_genai_generated_image_save_dir")


google_genai_client = google_genai.Client(api_key=api_key)




# google å‡çº§çš„SDK https://ai.google.dev/gemini-api/docs/migrate?hl=zh-cn

class MaxTokenException(Exception):
    def __init__(self, message):
        super().__init__(message)
        self.message = message

    def __str__(self):
        return f"MaxTokenException: {self.message}"


MODEL_GEMINI_2_0_FLASH = "gemini-2.0-flash"
MODEL_GEMINI_2_5_PRO_EXPT_0325 = "gemini-2.5-pro-preview-05-06"
MODEL_GEMINI_2_5_FLASH = "gemini-2.5-flash-preview-05-20"
# MODEL_GEMINI_2_5_PRO_EXPT_0325 = "gemini-2.5-pro-exp-03-25"
MODEL_GEMINI_2_0_FLASH_EXP_IMAGE_GENERATION = "gemini-2.0-flash-exp-image-generation"


def google_genai(prompt, model_name=MODEL_GEMINI_2_0_FLASH, response_mime_type="application/json", images=None,
                 temperature=0, max_output_tokens=8192):
    contents = []
    if images is not None and len(images) > 0:
        seen = set()
        unique_image_urls = [url for url in images if not (url in seen or seen.add(url))]
        for image in tqdm(unique_image_urls):
            path = gemini_upload_file.handle_file_path(image)
            try:
                # image_content = Image.open(path)
                image_content = upload_file(image)
            except Exception as e:
                utils.delete_file(path)
                print(f"Image.open Error {image} , {path} error {str(e)}")
                raise e

            contents.append(image_content)

    contents.append(prompt)
    response = google_genai_client.models.generate_content(
        model=model_name,
        contents=contents,
        config=types.GenerateContentConfig(
            response_mime_type=response_mime_type,
            max_output_tokens=max_output_tokens,
            temperature=temperature
        )
    )

    if response.candidates[0].finish_reason == types.FinishReason.MAX_TOKENS:
        raise MaxTokenException(f"reached max tokens {max_output_tokens}")

    return response.text


@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def upload_file(image_url):
    image_local_path = gemini_upload_file.handle_file_path(image_url)
    return __do_file_upload_and_cache(image_local_path)


@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def upload_file_from_local(image_local_path):
    return __do_file_upload_and_cache(image_local_path)



def __do_file_upload_and_cache(local_image_path):
    cache_file_path = os.path.join(cache_dir, utils.md5_str(local_image_path) + ".json")

    if os.path.exists(cache_file_path):
        with open(cache_file_path, 'r') as file:
            file_ref_dict = json.load(file)
            file_ref = types.File()
            file_ref.name = file_ref_dict.get("name")
            file_ref.mime_type = file_ref_dict.get("mime_type")
            file_ref.size_bytes = file_ref_dict.get("size_bytes")
            file_ref.create_time = datetime.strptime(file_ref_dict.get("create_time"), '%Y-%m-%dT%H:%M:%S.%fZ').replace(
                tzinfo=timezone.utc)
            file_ref.expiration_time = datetime.strptime(file_ref_dict.get("expiration_time"),
                                                         '%Y-%m-%dT%H:%M:%S.%fZ').replace(tzinfo=timezone.utc)
            file_ref.update_time = file_ref_dict.get("update_time")
            file_ref.sha256_hash = file_ref_dict.get("sha256_hash")
            file_ref.uri = file_ref_dict.get("uri")
            file_ref.state = file_ref_dict.get("state")
            file_ref.source = file_ref_dict.get("source")

            current_time = datetime.utcnow().replace(tzinfo=timezone.utc)
            if current_time < file_ref.expiration_time:
                # print("cache hint")
                return file_ref

    file_ref = google_genai_client.files.upload(file=local_image_path)
    # print(f"real uploading to google {local_image_path}")
    os.makedirs(os.path.dirname(cache_file_path), exist_ok=True)
    with open(cache_file_path, 'w') as file:
        json.dump(file_ref.to_json_dict(), file)
    return file_ref


def google_genai_conversation(history_messages, prompt, response_mime_type=None):
    history = []
    for message in history_messages:
        # role  Must be either 'user' or  'model'
        part = types.Part.from_text(text=message.get("content", ""))
        # åˆ›å»ºä¸€ä¸ª Content å®ä¾‹
        content = types.Content(parts=[part], role="user" if message.get("role") == "user" else "model", )
        history.append(content)

    chat = google_genai_client.chats.create(model=MODEL_GEMINI_2_0_FLASH, history=history)
    response = chat.send_message(prompt, config=types.GenerateContentConfig(
        max_output_tokens=1000 * 20,
        temperature=0,
        response_mime_type=response_mime_type
    ))

    return response.text


from enum import Enum


class MessageType(Enum):
    TEXT = "text"
    LOCAL_IMAGE = "local_image"
    URL_IMAGE = "url_image"


class GenaiMessagePart:
    def __init__(self, message_type: MessageType, value: str):
        self.message_type = message_type
        self.value = value

    def __str__(self):
        return f"message_type: {self.message_type}, value: {self.value}"

    @staticmethod
    def image(image_url):
        message_type = MessageType.URL_IMAGE if image_url.startswith("http") else MessageType.LOCAL_IMAGE
        return GenaiMessagePart(message_type, image_url)


class GenaiConversationMessage:
    def __init__(self, role, content: list[GenaiMessagePart]):
        self.role = role
        self.content = content

    def __str__(self):
        break_line = "\n"
        return f"role: {self.role}, content: [\n{break_line.join(str(part) for part in self.content)}]"

    @staticmethod
    def one(role, value, message_type=MessageType.TEXT):
        return GenaiConversationMessage(role, [GenaiMessagePart(message_type, value)])

    @staticmethod
    def text_and_images(text, images):
        content = [GenaiMessagePart(MessageType.TEXT, text)]

        if type(images) is str:
            content.append(GenaiMessagePart.image(images))
        elif type(images) is list:
            for image in images:
                content.append(GenaiMessagePart.image(image))

        return GenaiConversationMessage("user", content)

    def is_empty(self):
        return len(self.content) == 0


def save_binary_file(file_name, data):
    if os.path.exists(generate_image_save_dir_path) is False:
        os.makedirs(generate_image_save_dir_path)

    save_path = os.path.join(generate_image_save_dir_path, file_name)
    f = open(save_path, "wb")
    f.write(data)
    f.close()
    return save_path


@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def _prepare_message_for_request(index, conversation_message):
    parts = []
    for gemini_message_part in conversation_message.content:
        if gemini_message_part.message_type == MessageType.TEXT:
            parts.append(types.Part.from_text(text=gemini_message_part.value))
        elif gemini_message_part.message_type == MessageType.URL_IMAGE:
            f = upload_file(gemini_message_part.value)
            if f.mime_type in AVAILABLE_MIME_TYPES:
                parts.append(types.Part.from_uri(file_uri=f.uri, mime_type=f.mime_type))
            else:
                print(f"Unsupported mime type: {f.mime_type} , MessageType.URL = {gemini_message_part.value}")
        elif gemini_message_part.message_type == MessageType.LOCAL_IMAGE:
            if gemini_message_part.value == "image safety":
                parts.append(types.Part.from_text(text="because image safety , cannot generate image"))
            else:
                f = upload_file_from_local(gemini_message_part.value)
                if f.mime_type in AVAILABLE_MIME_TYPES:
                    parts.append(types.Part.from_uri(file_uri=f.uri, mime_type=f.mime_type))
                else:
                    print(f"Unsupported mime type: {f.mime_type} , MessageType.LOCAL = {gemini_message_part.value}")

    if len(parts) == 0:
        raise Exception(f"parts is emptyï¼š{str(conversation_message)}")

    return index, types.Content(parts=parts,
                                role=conversation_message.role if conversation_message.role == "user" else "model", )


"""
response_mime_type : application/json text/plain
"""
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def google_genai_output_images_and_text(new_message: GenaiConversationMessage,
                                        model=MODEL_GEMINI_2_0_FLASH_EXP_IMAGE_GENERATION,
                                        history_messages: list[GenaiConversationMessage] | None = None,
                                        system_instruction_prompt : str = None,
                                        response_mime_type="text/plain",
                                        max_output_tokens: int = 8192*2,
                                        temperature: float = 1,
                                        print_messages: bool = True) -> GenaiConversationMessage:
    global chunk
    if print_messages:
        if history_messages is not None:
            for hm in history_messages:
                print(hm)
        print(new_message)

    prepared_message = []
    prepared_message_count = 0
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(_prepare_message_for_request, index, message) for index, message in
                   enumerate((history_messages or []) + [new_message])]
        print(f"\n-------preparing conversation 0 / {len(futures)}----------\n")
        for future in concurrent.futures.as_completed(futures):
            try:
                idx, result = future.result()
                prepared_message.append({
                    "index": idx,
                    "content": result
                })
                prepared_message_count += 1
                print(f"\rprepare message success : {prepared_message_count} / {len(futures)}")
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"prepare message failed, {str(e)}")

    prepared_message.sort(key=lambda x: x["index"])
    contents = [item["content"] for item in prepared_message]

    response_modalities = ["image", "text"] if model == MODEL_GEMINI_2_0_FLASH_EXP_IMAGE_GENERATION else None

    system_instruction = None if system_instruction_prompt is None else [
        types.Part.from_text(text=system_instruction_prompt),
    ],

    generate_content_config = types.GenerateContentConfig(
        temperature=temperature,
        top_p=0.95,
        top_k=40,
        system_instruction=system_instruction_prompt,
        max_output_tokens=max_output_tokens,
        response_modalities=response_modalities,
        response_mime_type=response_mime_type,
    )

    response_content: list[GenaiMessagePart] = []

    print("\n-------conversation prepared , waiting response ----------\n")

    text_response_content = ""
    for chunk in google_genai_client.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_content_config,
    ):
        if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:
            continue
        if chunk.candidates[0].content.parts[0].inline_data:
            file_name = f"{utils.generate_uuid_datetime()}.png"
            image_save_path = save_binary_file(
                file_name, chunk.candidates[0].content.parts[0].inline_data.data
            )
            print(
                "File of mime type"
                f" {chunk.candidates[0].content.parts[0].inline_data.mime_type} saved"
                f"to: {image_save_path}"
            )
            response_content.append(GenaiMessagePart(MessageType.LOCAL_IMAGE, image_save_path))
        else:
            text_response_content += chunk.text
            print(chunk.text, end = "")

    if chunk and chunk.candidates and chunk.candidates[0].finish_reason:
        if chunk.candidates[0].finish_reason == types.FinishReason.MAX_TOKENS:
            raise MaxTokenException(f"reached max tokens {max_output_tokens}")

        # if chunk.candidates[0].finish_reason != types.FinishReason.STOP:
        #     raise Exception("Unexpected Finish Reason: " + chunk.candidates[0].finish_reason)

    if chunk and chunk.prompt_feedback and chunk.prompt_feedback.block_reason:
        if chunk.prompt_feedback.block_reason == "IMAGE_SAFETY":
            response_content.append(GenaiMessagePart(MessageType.LOCAL_IMAGE, "image safety"))
        else:
            raise Exception("Prompt Feedback Block Reason: " + chunk.prompt_feedback.block_reason)

    if text_response_content is not None and len(text_response_content) > 0:
        response_content.append(GenaiMessagePart(MessageType.TEXT, text_response_content))

    response_conversation_message =  GenaiConversationMessage("model", response_content)

    if response_conversation_message.is_empty():
        raise Exception("response_conversation_message is empty")

    return response_conversation_message


def get_generated_images(all_messages):
    generated_images = []

    for msg in all_messages:
        if msg.role == "model":
            for gemini_message_part in msg.content:
                if gemini_message_part.message_type == MessageType.LOCAL_IMAGE:
                    generated_images.append(gemini_message_part.value)

    return generated_images


if __name__ == "__main__":
    # google_genai_conversation()

    #     prompt_list = ["""ä½ å°†è¦å¸®æˆ‘ç”Ÿæˆä¸€ç»„å›¾ç‰‡ï¼Œä¸‹é¢æ˜¯å›¾ç‰‡ä¸­çš„é€šç”¨ä¿¡æ¯ï¼š
    # {
    # "é˜¿å¸Œ": "å¹´è½»ç”·æ€§ï¼Œèº«ç©¿ä¼‘é—²åŠå…¬æœè£…ï¼Œå‘å‹ç®€å•åˆ©è½çš„çŸ­å‘ï¼Œä½“å‹ä¸­ç­‰ã€‚è¡¨æƒ…ç”ŸåŠ¨ä¸°å¯Œï¼Œèƒ½å±•ç°å‡ºä»å…´å¥‹åˆ°ç”Ÿæ— å¯æ‹çš„å¤šç§çŠ¶æ€ã€‚åå§¿è‡ªç„¶éšæ„ï¼Œç¬¦åˆå¹´è½»æ‰“å·¥äººç‰¹å¾ã€‚",
    # "åŠå…¬å®¤å·¥ä½": "æ ‡å‡†çš„å¼€æ”¾å¼åŠå…¬å·¥ä½ï¼Œé…å¤‡ç°è‰²åŠå…¬æ¡Œå’Œé»‘è‰²åŠå…¬æ¤…ï¼Œæ¡Œé¢ä¸Šæœ‰æ˜¾ç¤ºå™¨ã€é”®ç›˜ã€é¼ æ ‡ç­‰åŸºç¡€åŠå…¬è®¾å¤‡ã€‚å·¥ä½å››å‘¨æœ‰çŸ®éš”æ¿ï¼ŒèƒŒæ™¯æ˜¯å…¶ä»–åŒäº‹çš„å·¥ä½ã€‚",
    # "æ‰“å·¥äºº/ç”Ÿæ´»ç”¨å“": "åŠå…¬æ¡Œé¢ä¸Šæ‘†æ”¾ç€å·¥ç‰Œã€ä¾¿åˆ©è´´ã€æ°´æ¯ã€æ‰‹æœºã€è®¡ç®—å™¨ç­‰åŠå…¬å¿…éœ€å“ï¼Œä»¥åŠå¤–å–ç›’ã€é›¶é£ŸåŒ…è£…ç­‰ç”Ÿæ´»ç”¨å“ï¼Œå‘ˆç°å‡ºçœŸå®çš„åŠå…¬ç¯å¢ƒã€‚",
    # "ææ€ªè¡¨æƒ…": "å¤¸å¼ çš„é¢éƒ¨è¡¨æƒ…ï¼ŒåŒ…æ‹¬çªå¤§çœ¼ç›ã€å˜´è§’ä¸Šæ‰¬çš„å…´å¥‹è¡¨æƒ…ï¼Œä»¥åŠçœ¼ç¥ç©ºæ´ã€é¢æ— è¡¨æƒ…çš„å‘†æ»çŠ¶æ€ï¼Œä½“ç°å‡ºå¼ºçƒˆçš„æƒ…ç»ªåå·®ã€‚",
    # "æ‘¸é±¼çŠ¶æ€": "ç˜«ååœ¨åŠå…¬æ¤…ä¸Šï¼Œèº«ä½“å‰å€¾æˆ–åä»°ï¼ŒåŒæ‰‹æ— åŠ›ä¸‹å‚ï¼Œçœ¼ç¥æ”¾ç©ºï¼Œæ•´ä¸ªäººå‘ˆç°å‡ºç²¾ç¥æ¶£æ•£çš„çŠ¶æ€ã€‚"
    # }
    # å¦‚æœä½ å¬æ˜ç™½äº†ï¼Œè¯·å›å¤ å¥½çš„ã€‚""",
    #                    "åœ¨æ ‡å‡†çš„å¼€æ”¾å¼åŠå…¬å·¥ä½ä¸Šï¼Œå¹´è½»ç”·æ€§é˜¿å¸Œèº«ç©¿ä¼‘é—²åŠå…¬æœè£…ï¼Œçœ‹åˆ°æ‰‹æœºè¡¥è´´æ–°é—»ï¼Œå…´å¥‹åœ°ä¸¾èµ·æ‰‹æœºï¼Œè„¸ä¸Šéœ²å‡ºå¤¸å¼ çš„çªçœ¼ç¬‘å®¹ï¼ŒèƒŒæ™¯æ˜¯æ‘†æ»¡åŠå…¬ç”¨å“å’Œç”Ÿæ´»ç‰©å“çš„å·¥ä½ã€‚",
    #                    "å¹´è½»ç”·æ€§é˜¿å¸Œåœ¨å¼€æ”¾å¼åŠå…¬å·¥ä½ä¸Šï¼Œæ‰“å¼€è®¡ç®—å™¨ï¼Œè®¤çœŸè®¡ç®—å·¥èµ„ï¼Œæ¡Œé¢ä¸Šæ•´é½æ‘†æ”¾ç€å·¥ç‰Œã€ä¾¿åˆ©è´´ç­‰åŠå…¬ç”¨å“ï¼Œè¡¨æƒ…ä¸¥è‚ƒè®¤çœŸ",
    #                    "å¹´è½»ç”·æ€§é˜¿å¸Œåœ¨åŠå…¬å·¥ä½ä¸Šï¼Œæ°ç€æ‰‹æŒ‡å¤´ï¼Œè®¡ç®—å„é¡¹æ”¯å‡ºï¼Œå˜´é‡Œå¿µå¿µæœ‰è¯ï¼Œçœ‰å¤´ç´§é”ï¼Œä¼¼ä¹åœ¨ä¸ºé’±å‘æ„",
    #                    "å¹´è½»ç”·æ€§é˜¿å¸Œåœ¨åŠå…¬å·¥ä½ä¸Šï¼Œçœ‹ç€è®¡ç®—å™¨ä¸Šçš„ä½™é¢ï¼Œè¡¨æƒ…é€æ¸å‡å›ºï¼Œçœ¼ç¥ç©ºæ´å‘†æ»ï¼Œé¢éƒ¨è¡¨æƒ…å¤¸å¼ åœ°æ˜¾ç¤ºå‡ºéœ‡æƒŠï¼Œä¼¼ä¹å‘ç°äº†ä»€ä¹ˆå¯æ€•çš„äº‹æƒ…",
    #                    "å¹´è½»ç”·æ€§é˜¿å¸Œç˜«ååœ¨åŠå…¬å·¥ä½çš„æ¤…å­ä¸Šï¼Œèº«ä½“æ— åŠ›ä¸‹å‚ï¼Œçœ¼ç¥æ”¾ç©ºï¼Œæ¡Œé¢ä¸Šæ•£è½ç€åŠå…¬ç”¨å“å’Œç”Ÿæ´»ç‰©å“ï¼Œæ•´ä¸ªäººå‘ˆç°å‡ºç”Ÿæ— å¯æ‹çš„çŠ¶æ€"]
    # prompt_list = ["è§£é‡Šé©¬å¤ªæ•ˆåº”ï¼Œè¶Šè¯¦ç»†è¶Šå¥½"]
    #
    # hms = []
    #
    # for prompt in prompt_list:
    #     ml: list[GenaiMessagePart] = []
    #     ml.append(GenaiMessagePart(MessageType.TEXT, prompt))
    #     mess = GenaiConversationMessage("user", ml)
    #
    #     res = google_genai_output_images_and_text(mess, history_messages=hms, max_output_tokens=200)
    #     hms.append(mess)
    #     hms.append(res)
    #     print(res)

    # print(types.BlockedReason.BLOCKED_REASON_UNSPECIFIED.value== "11BLOCKED_REASON_UNSPECIFIED")
    #
    # print("å¯¹å•å¼ æˆ–å¤šå¼ å›¾ç‰‡è¿›è¡Œåˆ†æï¼Œå¹¶æ ¹æ®é—®é¢˜è¿›è¡Œå›ç­”ï¼›\n\nArgs:\n    image_url_list: éœ€è¦åˆ†æçš„å›¾ç‰‡URLåˆ—è¡¨ï¼Œæ”¯æŒå•å¼ æˆ–å¤šå¼ å›¾ç‰‡åŒæ—¶åˆ†æ\n    question: éœ€è¦åˆ†æçš„é—®é¢˜ï¼ˆæœ€å¥½ä¸€æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜ï¼‰\n")

    # ans =  google_genai(prompt="æè¿°è¿™å¼ å›¾ç‰‡", images=["http://res.cybertogether.net/crawler/image/9e9db9930ad678316454a5e3a75be389.webp"])
    # print(ans)

    # r = utils.try_remove_markdown_tag_and_to_json("[{\"title\": \"éª‘æ‰‹ä»¬åˆ«å¤ªæç¬‘äº†å“ˆå“ˆå“ˆ\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g008314s5modg1e4g5nmh0ctg8u6ns1atnho?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"å“¥ä»¬ï¼Œä½ è¶Šç•Œäº†å•Š\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg31d2ukbad106g5obcvu4gjv8bkscj3kg?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"ä»–æ˜¯ä¸æ˜¯æœ‰ä¸€ç‚¹ç‚¹å¯çˆ±\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg31ev441vn6sdg5n2hc5e4592ttlt3688?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"è€æ¿ä¸‹ç­å…¼èŒé€å¤–å–\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg30tr7esnj50505n8pm605huvn0ni9apg?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"å…³äºè€æ¿ä¸ºäº†ç»™æˆ‘ä»¬å‘å·¥èµ„å»\"é€å¤–å–\"è¿™ä»¶äº‹\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg31avrpndvng7040uh3kdkqufr38nev6o?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"è€æ¿å¼€å§‹é‡æ“æ—§ä¸šåšèµ·å¤–å–å°å“¥\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g0083134ajmdomq6g5n8pm605huvnoq12448?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"æ®µå­æœç„¶éƒ½æ¥æºäºç°å®\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg31dscbjt3gu705oidecr41suf2f73478?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"è°çš„è€æ¿è¿˜åœ¨ä¸€çº¿å¥‹æ–—ï¼\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/notes_pre_post/1040g3k031ghs92jjjo5g4buk8cgqvcop69df0k0?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"ä¸œå­äº²è‡ªé€å¤–å–ï¼Œè¿™æ³¢æ“ä½œå¤ªåœˆç²‰äº†ï¼\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/1040g2sg31gis1hfj3ujg5opgatuovno8eab7ieo?imageView2/2/w/1080/format/webp\"]}, {\"title\": \"åƒäº¿æ€»è£é€å¤–å–ï¼\", \"body_text\": \"\", \"image_url_list\": [\"https://ci.xiaohongshu.com/notes_pre_post/1040g3k831gj51r4f3qeg5nf78n808hf2qdqi6tg?imageView2/2/w/1080/format/webp\"]}]")
    #
    # print(json.dumps(r, ensure_ascii=False, indent=4))

    print("[\n  {\n    \"title\": \"ä¸Šç­è¦æ˜ç™½çš„é“ç†\",\n    \"body_text\": \"æ— è®ºåœ¨ä»»ä½•åœ°æ–¹ä¸Šç­ï¼Œ\\nåªè¦å…¬å¸ä¸å¼€é™¤ä½ ï¼Œé‚£ä½ å°±å…ˆå¹²ç€\\nåŒäº‹å¯¹ä½ æŒ‡æŒ‡ç‚¹ç‚¹çš„æ—¶å€™ï¼Œä½ å°±ç¬‘ç¬‘\\né¢†å¯¼æ‰¹è¯„ä½ çš„æ—¶å€™ï¼Œä½ å°±å¬å¬å°±å¥½ï¼Œä¸è¦å¤ªåœ¨æ„ã€‚\\n#è¢«æ–‡å­—æ²»æ„ˆ[è¯é¢˜]# #æ²»æ„ˆç³»æ¼«ç”»[è¯é¢˜]# #çœ‹æ·¡ä¸€åˆ‡çƒ¦æ¼[è¯é¢˜]# #å¥½å¥½æ´»åœ¨å½“ä¸‹[è¯é¢˜]# #äººé—´æ¸…é†’[è¯é¢˜]# #äººç”Ÿä¸å¿…å¤ªå¤šç„¦è™‘[è¯é¢˜]# #ä¸Šç­ä¸ºäº†ä»€ä¹ˆ[è¯é¢˜]# #æ‰“å·¥äººä¹Ÿæ˜¯äºº[è¯é¢˜]# #å¯¹å·¥ä½œçš„æ€åº¦[è¯é¢˜]# #å¥³ç”Ÿå¿…çœ‹[è¯é¢˜]#\",\n    \"image_url_list\": [\"http://res.cybertogether.net/crawler/image/5565693591ab874a9955f5791c942f86.webp\"]\n  },\n  {\n    \"title\": \"æ°¸è¿œä¼šè¢«é˜³å…‰æ²»æ„ˆğŸŒ\",\n    \"body_text\": \"ä»Šæ—¥å¼€çª—æ—¶åˆ†åœ¨ä¸‹åˆï¼Œæœ¬ä»¥ä¸ºå¯ä»¥é™é™ç­‰å¤©é»‘ï¼Œå´è¿æ¥äº†é˜³å…‰è¿”åœºï¼Œçªç„¶å°±æƒ³åˆ°ä¸€å¥è¯—ï¼š\\n\"æŸ³æš—èŠ±æ˜åˆä¸€æ‘\"ã€‚\\nçœŸåƒæ¢¦ä¸€æ ·ï¼Œç¾å¥½åˆ°ä¸çœŸå®ã€‚\\n#å¥½å¥½ç”Ÿæ´»å¤§èµ›[è¯é¢˜]# #å¹´åº¦æ—·é‡æ—¶åˆ†[è¯é¢˜]# #æµªæ¼«ç”Ÿæ´»çš„è®°å½•è€…[è¯é¢˜]#  #å†¬æ—¥å¥½å¥½å®…[è¯é¢˜]# #å°çº¢ä¹¦å±…å®¶è¶‹åŠ¿[è¯é¢˜]# #20åˆ†é’Ÿå®¶æ•ˆåº”[è¯é¢˜]# #ç‹¬å±…å¥³å­©[è¯é¢˜]# #è®°å½•å§å°±ç°åœ¨[è¯é¢˜]# #å®¶æœ‰è‰ºæœ¯æ„Ÿ[è¯é¢˜]# #è¾¹ç”Ÿæ´»è¾¹è‰ºæœ¯[è¯é¢˜]# @VLOGè–¯ @å®¶å±…è–¯\",\n    \"image_url_list\": [\"http://res.cybertogether.net/crawler/image/b0976a71d24ca0e6b06db02bf1c810e7.jpeg\"]\n  },\n  {\n    \"title\": \"åœ°é“ä¸Šæ´»æ‰ä¸€åªæ‰“å·¥äºº...\",\n    \"body_text\": \"ã€Šå¸Œè€å¸ˆæ‰“å·¥äººé¢œè‰ºåˆé›†ã€‹\\nä»€ä¹ˆæ—¶å€™æ‰æ”¾å¤§é•¿å‡å•Šå•Šå•Šå•Šå•Š!!!\\næœ€è¿‘å…¬å¸å‘¨å…­ä¹ŸåŠ ç­...\\næœ¬æ‰“å·¥äººçœŸçš„æœ‰ç‚¹æ’‘ä¸ä½äº†...[å“­æƒ¹R][å“­æƒ¹R][å“­æƒ¹R]\\n\\t\\n#æ‰“å·¥äººæ—¥å¸¸[è¯é¢˜]# #æ‰“å·¥äºº[è¯é¢˜]# #æç¬‘çš„æ—¥å¸¸[è¯é¢˜]# #æ²™é›•æç¬‘[è¯é¢˜]# #å¥‡è‘©åŒäº‹[è¯é¢˜]# #æ‰“å·¥äººæ—¥å¸¸[è¯é¢˜]# #æ‰“å·¥äººç²¾ç¥çŠ¶æ€[è¯é¢˜]#\",\n    \"image_url_list\": [\"http://res.cybertogether.net/crawler/image/0de587fd37a9d8eeb05548103845c39a.webp\"]\n  },\n  {\n    \"title\": \"æ‰“å·¥äººï¼šä½ å¥½ï¼Œåƒæ´¾å—ï¼Ÿ\",\n    \"body_text\": \"ã€Šæ‘¸é±¼æ‰“å·¥äººçš„ç²¾ç¥çŠ¶æ€ã€‹\\næ‹œæ‰˜é˜¿å¸Œå»æ‘¸é±¼çš„æ—¶å€™æ‰“åŒ…ä¸ªè‚¯å¾·åŸº...\\næ‘¸åˆ°è‚¯å¾·åŸºç–¯ç‹‚åƒæ´¾æ´»åŠ¨ï¼Œçˆ½æ­ªæ­ª...[doge]\\nç»“æœæ‹¿äº†ä¸ªæ™¾è¡£æ¶å»æ‰“åŒ…...[æ±—é¢œR]\\nè¿™æ˜¯å¾—å¤šæ€•åŒäº‹åƒä¸Šçƒ­ä¹çš„å‘€...[æ‚è„¸R][æ‚è„¸R]\\n\\t\\nå¥¶é»„é£å‘³æ´¾ç»µå¯†é¡ºæ»‘ï¼Œå¾®ç”œä¸è…»çš„æ¸¯å¼å¥¶é»„æµå¿ƒï¼\\nä¸€å£çˆ†æµ†çš„æµ“éƒå¥¶é¦™~[èŒèŒå“’R]\\nç™½æ¡ƒé£å‘³æ´¾é…¸ç”œçˆ†æ±ï¼Œå¤§é¢—äº¬åå››ç™½æ¡ƒæœè‚‰ï¼\\nä¸€å£æ¸…çˆ½æ˜¥å›~[å“‡R]\\nçº¢è±†æ´¾ç»å…¸é¥±æ»¡æœ‰å±‚æ¬¡ï¼Œé¢—ç²’æ‰å®çš„çº¢è±†é…±ï¼\\nå°Šå˜Ÿå¥½åƒï¼çˆ±äº†ï¼ï¼[å®³ç¾R][å®³ç¾R]\\n\\t\\n#æç¬‘çš„æ—¥å¸¸[è¯é¢˜]# #æ‘¸é±¼[è¯é¢˜]# #åˆ«æƒ¹æ‰“å·¥äºº[è¯é¢˜]# #å½“ä»£å¹´è½»äººæ‰“å·¥ç²¾ç¥çŠ¶æ€[è¯é¢˜]#\",\n    \"image_url_list\": [\"http://res.cybertogether.net/crawler/image/6c1a48cd0513ed898d9df91fdea097ac.jpeg\"]\n  }\n]")
    pass
