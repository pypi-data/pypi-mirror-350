"""Main script to run Bayesian analysis of data from an Ecological Momentary Assessment (EMA) study.
This script should be used as a template,
to be copied and modified for any desired analysis.

*** Usage: four main steps, see also explicit template example below:

*1: Set up an EmaFrame instance to define experiment and to select input data.
*2: Load a set of collected EMA data into an EmaDataSet instance
*3: Initialize and train an EmaModel instance for observed data.
*4: Display results and save figures and tables to a directory tree.

**  Recommended to run a couple of times with the same data set,
    to see random variability in estimated results.


*** Version history:
* Version 1.1.2:
2024-06-27, some comments clarified. Only updated ema_display

* Version 1.1.0:
2024-02-04, New argument for EmaDisplay.show(..., group_factors=[...],...),
            to show population differences within SELECTED subset of group "dimensions".
            New argument to EmaFrame.setup(..., population_weights)
            defining relative weights to merge population results across OTHER group "dimensions".
2024-01-30, new format arguments in EmaDisplay.show(...) for user control of plot styles.

* Version 1.0.0:
2023-05-17, EmaModel.initialize(..., n_participants_per_comp, ...) defines initial number of GMM components.
            Parameter max_n_comp no longer used.
2023-04-22, adapted to simplified group-key representation in module ema_data.py:
            Group categories specified in EmaFrame.setup(...)
            NOTE: changed signatures EmaFrame.setup(), EmaDataSet.load(), EmaDataSet.save().

* Version 0.9.5:
2023-03-07, ema_display.EmaDisplaySet include observed and model-predicted grade-count histograms
2023-03-01, timestamp_result if needed to avoid over-writing result files

* Version 0.9.3:
2022-08-14, Each ordinal rating scale may be unique or shared by more than one Attribute
2022-07-30, minor cleanup adapting to minor changes in package modules.

* Version 0.9.1:
2022-04-04, all result tables generated and saved as Pandas.DataFrame instances
2022-03-27, NAP and mean-grades results directly from raw data in ema_data.EmaDataSet
2022-03-21, using Pandas DataFrame format in EmaDataSet, allowing many input file formats

* Version 0.7.1:
2022-01-30, allow seed input to EmaModel.initialize for reproducible random results

* Version 0.7: minor update to include new calculation and display functions

* Version 0.6:
2021-12-08, allow user control of model restriction:
            restrict_attribute: sensory-variable location average forced -> 0.
            restrict_threshold: response-threshold median forced -> 0.

* Version 0.5:
2021-11-22, first functional version
"""
# -------- __main__ check to prevent multiprocessor sub-tasks to re-run this script
if __name__ == '__main__':
    import numpy as np
    from pathlib import Path
    import logging
    import datetime as dt
    import pickle

    from EmaCalc.ema_data import EmaFrame, EmaDataSet
    from EmaCalc.ema_model import EmaModel
    from EmaCalc.ema_display import EmaDisplaySet
    from EmaCalc import ema_logging, __version__
    from EmaCalc.ema_display_format import harmonize_ylim

    # ------------------------ Set up working directory and result logging:
    timestamp_result = True  # New result folder for each run, to prevent over-writing
    # timestamp_result = False  # Repeated runs will over-write existing results

    work_path = Path.home() / 'Documents' / 'EMA_sim'  # or whatever...
    data_path = work_path / 'data'  # to use simulation data generated by run_sim.py
    result_path = work_path / 'result'  # or whatever
    model_file = 'test_ema_model.pkl'  # name of saved model file (if saved)

    if timestamp_result:
        t = dt.datetime.now()
        result_path = result_path.with_name(result_path.name +
                                            f'-{t.year}-{t.month:02}-{t.day:02}-{t.hour:02}{t.minute:02}')

    ema_logging.setup(save_path=result_path,
                      log_file='run_ema_log.txt')  # to save the log file
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.INFO)

    logger.info(f'*** Running EmaCalc version {__version__} ***')

    # ------ 1: Define Experimental Framework: Situations, Attributes, and Groups

    # NOTE: This example uses data generated by template script run_sim.py
    # Edit as needed for any other EMA data source.

    situations = {'Phase': ('',),  # only One Test phase with empty label
                  'HA': ('A', 'B'),  # Two Hearing-aid programs
                  'CoSS': [f'C{i}' for i in range(1, 8)],  # Seven CoSS categories
                  }  # Categorical variables
    # NOTE: One situation dimension is always phase, even if only ONE phase category.
    # User may set arbitrary phase_key label.
    # Dimension 'Phase' may be omitted, if only one phase category.
    # Category labels may be strings or integers, which can be used as part of file names.
    # If string labels are intended, avoid strings that can be interpreted as numbers,
    # because Pandas.reader functions will read them as numbers by default.

    emf = EmaFrame.setup(situations=situations,
                         phase_key='Phase',
                         attributes={'Speech': ['Very Hard',
                                                'Hard',
                                                'Easy',
                                                'Very Easy',
                                                'Perfect'],
                                     'Comfort': ['Bad',
                                                 'Not Good',
                                                 'Not Bad',
                                                 'Good']},
                         groups={'Age': ['young', 'old'],
                                 'Gender': ('M', 'F'),
                                 },  # -> Four possible combinations of "dimensions" 'Age' and 'Gender'
                         population_weights={('old', 'M'): 2.,
                                             ('old', 'F'): 2.,
                                             }  # default = 1. for other populations
                         )
    # NOTE: String CASE is always distinctive, i.e., 'Good' and 'good' are DIFFERENT categories.

    # NOTE: situations, attributes, and groups keys will be parts of result file names,
    # so they can include only characters allowed in file names.

    # NOTE: situations, attributes, and groups are always analyzed as Categorical variables,
    # even if the categories / grades are defined by numeric labels.
    # The rank order of attribute grades is defined as given in EmaFrame.setup(...),
    # assumed to be ordered from "worst" to "best",
    # REGARDLESS OF the alphabetical or numerical value of grade labels.

    # NOTE: population_weights are needed only if results are to be shown separately
    # for only one or a few Group Dimensions, averaging across categories in other Group Dimensions.
    # In this example, we defined population Age = old to be twice as large as Age = young,
    # both for Gender = M and Gender = F.
    # Each element of population_weights must specify one category in each predefined Group Dimension.

    # NOTE: if EQUAL grade labels are used for more than one attribute,
    # the model still assumes separate rating scales for each attribute.
    # However, if grade sequences are IDENTICAL objects for more than one attribute,
    # the model uses the SAME rating scale for those attributes.
    #
    # Example:
    # common_ordinal_scale = ['Very Hard',
    #                         'Hard',
    #                         'Easy',
    #                         'Very Easy',
    #                         'Perfect']
    # emf = EmaFrame.setup(situations=situations,
    #                      phase_key='Phase',
    #                      attributes={'Speech': common_ordinal_scale,
    #                                  'Comfort': common_ordinal_scale}  # IDENTICAL scale object for both attributes
    #                      )

    # In either case, response thresholds are always estimated separately for each participant.

    # ------ 2: Load data from previously saved file(s):

    ds = EmaDataSet.load(emf, data_path,
                         # fmt='csv',  # or 'xlsx' (Excel); Undefined / None -> try ALL files in data_path
                         # fmt='sav',  # (SPSS), or 'dta' (Stata); may need extra package installed manually
                         participant='file',    # file name -> participant ID;
                         # participant='sheet',  # Sheet name -> participant ID (only for Excel-type files)
                         # participant='Subject ID',  # == a Column Header in each file
                         path_groups=['Age', 'Gender'], # groups defined in path string
                         # path_groups=None,    # One data column for each Group Dimension
                         # group_join_str='_'  # default for group name in path string
                         # rename_cols={'Old Header': 'New Header,...},  # if needed to match EmaFrame definitions
                         # dtype=str, # in case some Grade labels were defined as number-like strings '1', '2', etc.
                         #              but might be saved as numbers 1, 2, etc. in data files.
                         # converters={ColumnHeader: function, ...},  # in case data needs special recoding.
                         # ... any other keyword arguments to Pandas.read_xxx function.
                         )
    # NOTE: if 'path_groups' elements are specified, group names in path string must match EXACTLY
    # the labels specified in EmaFrame.setup(...,groups={...}), joined by group_join_str,
    # e.g. with directory data_path / 'Age_old'
    # containing data file(s) for group dimension = 'Age', category = 'old'

    # NOTE: See Pandas.read_csv (or any other read_xxx) documentation for other control arguments

    logger.info(f'Using data set ds=\n{ds}')

    # ----------------- (Optional) show rating counts for all participants
    for attr in emf.attribute_dtypes.keys():
        a_count = ds.attribute_grade_count(attr, groupby='HA')
        logger.info(str(attr) + '_grade_count:\n' + a_count.to_string())
        logger.info(str(attr) + ': sum grade_count= ' + f'{np.sum(a_count.to_numpy())}')
        # a_count.save(result_path / (str(attr) + '_grades.csv'))

    # ----------------- (Optional) show mean grades and NAP results for all participants
    mean_grades = ds.attribute_grade_mean(groupby=('HA', 'CoSS'))
    mean_grades.save(result_path / 'Attribute_mean_grades.txt', float_format='%.2f')
    # mean_grades.save(result_path / 'Attribute_mean_grades.csv',
    #                  float_format='%.4f')  # if needed for other analysis
    logger.info(f'Attribute mean grades saved in {result_path}'
                + '\nCAUTION: Mean values presume METRIC data, but attribute grades are only ORDINAL!')

    # ----------------- (Optional) show NAP results for all participants
    nap = ds.nap_table('HA', nap_cat=['A', 'B'], p=0.95)  # aggregated across other situation dimensions
    # high NAP>0.5 means B is better than A
    # nap = ds.nap_table('HA', nap_cat=['A', 'B'], groupby=('CoSS',), p=0.95)  # grouped results
    nap_file = 'NAP_HA_B-A'
    nap.save(result_path / (nap_file + '.txt'), float_format='%.2f')  # pretty-formatted by Pandas
    # nap.save(result_path / (nap_file + '.tex'), float_format='%.2f')  # for import to LaTeX doc.
    # nap.save(result_path / (nap_file + '.csv'), sep='\t')  # tab-delimited text, for input to other program
    # nap.save(result_path / (nap_file + '.xlsx'))  # for further Excel analysis
    logger.info(f'NAP results saved in {result_path}')

    # ------ 3: Learn Analysis Model from loaded data set:

    # Model ordinal-regression effects of Situations on each Attribute:

    # regression_effects = ['HA',     # main linear regression effect only
    #                       'CoSS',   # main linear regression effect only
    #                       # 'Phase',  # if there are several phase categories
    #                       ]

    regression_effects = [('HA', 'CoSS')  # joint effects, main AND interaction
                          # 'Phase',  # if there are several phase categories
                          ]

    # NOTE: A regression_effects element may include any combination of situation dimensions, BUT
    # including ALL interactions -> many model parameters,
    # possibly -> less reliable estimation for each parameter.

    # In this example: ['HA', 'CoSS'] -> 2 + (7 - 1) = 8 regression-effect parameters
    #                ['CoSS', 'HA'] -> 7 + (2 - 1) = 8 regression-effect parameters
    #                [('HA', 'CoSS')] -> 2 * 7 = 14 regression-effect parameters

    emm = EmaModel.initialize(ds, effects=regression_effects,
                              # n_participants_per_comp=10,   # default
                              # restrict_attribute=False,     # default
                              # restrict_threshold=True,      # default
                              # latent_class='logistic',      # default
                              )
    # n_participants_per_comp = initial number of participants per mixture component in population model
    # restrict_attribute=True -> force attribute mean location at zero
    # restrict_threshold=True -> force one mid-scale response threshold at zero
    #   for each respondent and each sample of each attribute.
    # latent_class = 'logistic' ("logit" model) OR 'normal' ("probit" model)

    ll = emm.learn(max_hours=1., max_minutes=0.)
    logger.info(f'*** Data log-likelihood = {ll[-1]:.1f}, indicating model fit to data. ***')
    # *** Recommended to re-run model learning with same data set a couple of times,
    # and then use best-fitting model result.

    emm.prune()  # keep only active mixture components.

    # -------- Save learned EmaModel (optional):
    with (work_path / model_file).open('wb') as f:
        pickle.dump(emm, f)
        logger.info('Model pickle-dumped as ' + f.name)

    # ------ 4: Generate result displays:

    # -------- Re-load learned EmaModel (optional, if saved):
    # with (work_path / model_file).open('rb') as f:
    #     emm = pickle.load(f)
    # -------------------------------------------------
    emd = EmaDisplaySet.show(emm,
                             situations=['CoSS',  # CoSS probabilities, aggregated across HA
                                         ('CoSS', 'HA'),  # conditional CoSS probabilities, given HA category
                                         ('HA', 'CoSS'),  # conditional HA probabilities, given CoSS category
                                         ],
                             # NOTE v 1.1.0: ('CoSS', 'HA') -> cred. diff. only between HA categories, for each CoSS
                             attributes=[('Speech', 'CoSS'),    # Speech, main effect of CoSS
                                         ('Speech', 'HA'),      # Speech, main effect of HA
                                         ('Speech', ('CoSS', 'HA')),    # joint effect of (CoSS, HA)
                                         ('Comfort', ('CoSS', 'HA'))],  # joint effect of (CoSS, HA)
                             # NOTE v 1.1.0: ('CoSS', 'HA') -> cred. diff. between HA categories, for each CoSS
                             grade_counts=['Speech',  # total 'Speech' grade-counts, sum across HA and CoSS
                                           ('Speech', 'HA'),    # 'Speech' grade-counts, separated by HA
                                           ('Comfort', 'HA')],  # 'Comfort' grade-counts, separated by HA
                             group_factors=['Age',      # main effects of 'Age'
                                            'Gender',   # main effects of 'Gender'
                                            ('Age', 'Gender')], # combined effects of both Dimensions
                             # group_factors=[('Age', 'Gender')], # Default: show all combinations separately
                             random_individual=True,    # random individual in population
                             population_mean=True,      # population mean
                             participants=False,        # individual results: True -> MANY plots and tables
                             grade_thresholds=True,     # True -> median response thresholds in attribute plots
                             percentiles=[2.5, 25, 50, 75, 97.5],   # in profile plots and tables
                             credibility_limit=0.7,     # minimum credibility in difference tables
                             mpl_params={'figure.max_open_warning': 0,  # suppress warning
                                         'figure.autolayout': True,     # -> tight figure layout
                                         'axes.labelsize': 'x-large',
                                         # 'axes.facecolor': '0.9',  # -> light gray
                                         # 'legend.facecolor': 'w',
                                         },  # any other settings -> matplotlib.rcParams
                             # mpl_style='my_style_sheet',  # use predefined matplotlib style sheet
                             # colors='rbgk',   # default, used cyclically
                             # markers='oxs*_'  # default, used cyclically
                             # threshold_linewidth=1, # default = 0.2 * rcParams.lines.linewidth
                             # threshold_color='w',   # default = rcParams.axes.edgecolor
                             # ... any other settings in ema_display.FMT or ema_display_format.FMT
                             )
    # NOTE: joint (=interaction) effects are correct only if included in model regression_effects

    # ------------------------------- (optionally) edit display elements, if desired
    for gf in emd.group_factors.values():
        for g_disp in gf.groups.values():
            harmonize_ylim([g_disp.population_mean.attributes[('Speech', ('CoSS', 'HA'))].plot.ax,
                            g_disp.random_individual.attributes[('Speech', ('CoSS', 'HA'))].plot.ax,
                            g_disp.population_mean.attributes[('Comfort', ('CoSS', 'HA'))].plot.ax,
                            g_disp.random_individual.attributes[('Comfort', ('CoSS', 'HA'))].plot.ax
                            ])
            harmonize_ylim([g_disp.population_mean.situations[('CoSS', 'HA')].plot.ax,
                            g_disp.random_individual.situations[('CoSS', 'HA')].plot.ax,
                            ])
    # -> matching y-axis limits: nice for plots to be shown side by side

    # ------------------------------- save all result displays
    emd.save(result_path,
             figure_format='pdf',   # or eps, png; any format that matplotlib can handle
             table_format='txt',    # or tex, csv, xlsx, odt; any format that Pandas can handle
             float_format='%.2f')   # for numerical results in tables

    # (optionally) save in other format(s), too:
    # emd.save(result_path,
    #          table_format='xlsx',  # for input to other package
    #          float_format='%.4f',  # any other parameters for Pandas table-writer function
    #          index=True,   # needed by Pandas.to_excel in some cases
    #          )
    # emd.save(result_path,
    #          table_format='csv',  # for input to other package
    #          float_format='%.4f',  # any other parameters for Pandas table-writer function
    #          sep='\t'  # -> tab-delimited
    #          )

    logging.info(f'All results saved in {result_path}')

    logging.shutdown()
