Metadata-Version: 2.3
Name: repo-gpt
Version: 0.4.2
Summary: Search your code repository using GPT4.
License: Apache-2.0
Keywords: openai,gpt,repo,repository,search,semantic-search,query,analyze-code,gpt3,gpt3.5
Author: Shruti Patel
Author-email: shruti222patel@gmail.com
Requires-Python: >=3.9,<3.13
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: Apache Software License
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Dist: autogen (>=0.8.3,<0.9.0)
Requires-Dist: code2flow (>=2.5.1,<3.0.0)
Requires-Dist: colored (>=2.2.3,<3.0.0)
Requires-Dist: configargparse (>=1.7,<2.0)
Requires-Dist: fuzzywuzzy (>=0.18.0,<0.19.0)
Requires-Dist: multilspy (>=0.0.14,<0.0.15)
Requires-Dist: networkx (>=3.1,<4.0)
Requires-Dist: numpy (>=1.24.3,<2.0.0)
Requires-Dist: openai (>=1.68.2,<2.0.0)
Requires-Dist: pandas (>=2.0.2,<3.0.0)
Requires-Dist: pathspec (>=0.11.1,<0.12.0)
Requires-Dist: polars (>=0.19.12,<0.20.0)
Requires-Dist: pydeps (>=1.12.17,<2.0.0)
Requires-Dist: pylint (>=3.0.1,<4.0.0)
Requires-Dist: python-levenshtein (>=0.23.0,<0.24.0)
Requires-Dist: rich (>=13.4.1,<14.0.0)
Requires-Dist: tenacity (>=8.2.2,<9.0.0)
Requires-Dist: tiktoken (>=0.4.0,<0.5.0)
Requires-Dist: toml (>=0.10.2,<0.11.0)
Requires-Dist: tqdm (>=4.67.1,<5.0.0)
Requires-Dist: tree-sitter-languages (>=1.10.2,<2.0.0)
Requires-Dist: tree_sitter (>=0.20.4,<0.21.0)
Project-URL: Repository, https://github.com/shruti222patel/repo-gpt
Description-Content-Type: text/markdown

# Repo GPT

Repo-GPT is a Python CLI tool designed to utilize the power of OpenAI's GPT-3 model. It facilitates the process of code analysis and search within your repositories.

![Repo-GPT in action](./imgs/example_output.png)

## Features

- Code extraction and processing from your repositories.
- Semantic search within your codebase through natural language queries.
- Response generation to natural language queries about your code.
- Specific file analysis within your codebase.

## Installation

Repo-GPT can be installed via [pip](https://pip.pypa.io/en/stable/):

```bash
brew install graphviz
pip install repo-gpt
```

Alternatively, you can clone and install from the source code:

```bash
git clone https://github.com/yourusername/repo-gpt.git
cd repo-gpt
poetry install
```

## Setting Up

Before starting, make sure to set up your OpenAI key in your environment variables.

```shell
export OPENAI_API_KEY=<insert your openai key>
```

To set up Repo-GPT, run the following command at the root of the project you want to search. This will create a `.repo_gpt` directory and store the code embeddings there:

```shell
repo-gpt setup
```

Repo-GPT will only add or update embeddings for new files or changed files. You can rerun the setup command as many times as needed.

## Usage

After setup, you can perform various tasks:

- **Semantic Search**: Find semantically similar code snippets in your codebase:

  ```shell
  repo-gpt search <text/question>
  ```

- **Codebase Query**: Ask questions about your codebase:

  ```shell
  repo-gpt query <text/question>
  ```

- **File Analysis**: Analyze a specific file:

  ```shell
  repo-gpt analyze <file_path>
  ```

- **Help**: Access the help guide:

  ```shell
  repo-gpt help
  ```

- **Generate tests**: Generate tests for a function:
Note: this assumes the function name is unique in the codebase, otherwise, it will pick the first function it finds with that name.

   ```shell
   repo-gpt add-test <unique function name> --test_save_file_path <absolute filepath to add tests to> --testing_package <testing package to use e.g. pytest>
   ```

Example:

```bash
repo-gpt setup --root_path ./my_project
repo-gpt search "extract handler"
repo-gpt query "What does the function `calculate_sum` do?"
repo-gpt analyze ./my_project/main.py
repo-gpt add-test function_name --test_save_file_path $PWD/test.py --testing_package pytest
```

## Contributing

We welcome your contributions! Before starting, please make sure to install Python `3.11` and the latest version of [poetry](https://python-poetry.org/docs/#installing-with-pipx). [Pyenv](https://github.com/pyenv/pyenv) is a convenient tool to manage multiple Python versions on your computer.

Here are the steps to set up your development environment:
0. Install global dependencies:

   ```shell
   nvm use --lts

   brew install graphviz
   export CFLAGS="-I $(brew --prefix graphviz)/include"
   export LDFLAGS="-L $(brew --prefix graphviz)/lib"
   pip install poetry
   ```

1. Export your OpenAI key to your environment variables:

   ```shell
   export OPENAI_API_KEY=<insert your openai key>
   ```

2. Install dependencies:

   ```shell
   poetry install --no-root
   jupyter lab build
   ```

3. Install pre-commit hooks:

   ```shell
   poetry run pre-commit install
   ```

4. Seed data:

   ```shell
   poetry run python cli.py setup
   ```

5. Query data:

   ```shell
   poetry run python cli.py search <text/question>
   ```

### Testing
#### Integration Tests
Run pytest with the --language option to filter tests by language:
```bash
# Run only Python tests
pytest --language python test/it
```
```bash
# Run only TypeScript tests
pytest --language typescript test/it
```
```bash
# Run only PHP tests
pytest --language php test/it
```
If the --language option is omitted, all tests will be run:
```bash
# Run all tests (default behavior)
pytest test/it
```
#### Unit
```bash
pytest test/unit
```

### Debugging

You can view the output of the `code_embeddings.pkl` using the following command:

```shell
poetry shell
python
import pandas as pd
pd.read_pickle('./.repo_gpt/code_embeddings.pkl', compression='infer')
```

#### Interpreter
```shell
poetry shell
ipython
%load_ext autoreload
%autoreload 2
```

## Roadmap

Here are the improvements we are currently considering:

- [X] Publishing to PyPi
- [X] Test suite addition
- [X] Add CI/CD
- [X] Prettify output
- [ ] Add readme section about how folks can contribute parsers for their own languages
- [ ] Save # of tokens each code snippet has so we can ensure we don't pass too many tokens to GPT
- [X] Add SQL file handler
- [ ] Add DBT file handler -- this may be a break in pattern as we'd want to use the manifest.json file
- [X] Create VSCode extension
- [ ] Ensure files can be added & deleted and the indexing picks up on the changes.
- [ ] Add .repogptignore file to config & use it in the indexing command
- [ ] Use pygments library for prettier code formatting

