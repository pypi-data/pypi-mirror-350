---
title: Test Implementation Plan for Token Bucket Rate Limiter
by: khive-implementer
created: 2025-05-18
updated: 2025-05-18
version: 1.0
doc_type: TI
output_subdir: ti
description: Comprehensive test plan for the token bucket algorithm implementation for precise API rate control
date: 2025-05-18
---

# Test Implementation Plan: Token Bucket Rate Limiter

## 1. Overview

### 1.1 Component Under Test

The Token Bucket Rate Limiter is a critical component that provides precise
control over API request rates. It implements the token bucket algorithm to
allow controlled bursts of requests while maintaining long-term rate limits.
This test plan covers the core TokenBucketRateLimiter class, the
EndpointRateLimiter for per-endpoint rate limiting, and the AdaptiveRateLimiter
for dynamic rate adjustments.

### 1.2 Test Approach

We will use a combination of:

- **Unit tests**: To verify the behavior of individual components in isolation
- **Integration tests**: To verify the interaction between rate limiters and
  other components
- **Performance tests**: To ensure rate limiting doesn't add significant
  overhead
- **Concurrency tests**: To verify rate limiting works correctly under
  concurrent load

### 1.3 Key Testing Goals

- Verify that the token bucket algorithm correctly limits request rates
- Ensure proper token refill behavior over time
- Verify that endpoint-specific rate limiting works correctly
- Ensure adaptive rate limiting correctly adjusts based on response headers
- Verify integration with API client and executor components
- Ensure thread safety and correct behavior under concurrent access

## 2. Test Environment

### 2.1 Test Framework

```
pytest
pytest-asyncio  # For testing async code
pytest-mock     # For mocking dependencies
pytest-cov      # For measuring test coverage
```

### 2.2 Mock Framework

```
unittest.mock   # For mocking time.monotonic and other dependencies
pytest-mock     # For fixture-based mocking
```

### 2.3 Test Database

Not applicable for this component.

## 3. Unit Tests

### 3.1 Test Suite: TokenBucketRateLimiter

#### 3.1.1 Test Case: Initialization

**Purpose:** Verify that TokenBucketRateLimiter initializes correctly with
various parameters.

**Setup:**

```python
@pytest.mark.parametrize(
    "rate,period,max_tokens,expected_tokens",
    [
        (10.0, 1.0, None, 10.0),  # Default max_tokens = rate
        (10.0, 1.0, 20.0, 20.0),  # Custom max_tokens
        (10.0, 2.0, 15.0, 15.0),  # Different period
    ],
)
```

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_token_bucket_rate_limiter_init(rate, period, max_tokens, expected_tokens):
    # Arrange & Act
    limiter = TokenBucketRateLimiter(rate=rate, period=period, max_tokens=max_tokens)

    # Assert
    assert limiter.rate == rate
    assert limiter.period == period
    assert limiter.max_tokens == expected_tokens
    assert limiter.tokens == expected_tokens
```

#### 3.1.2 Test Case: Token Refill

**Purpose:** Verify that tokens are refilled at the correct rate based on
elapsed time.

**Setup:**

```python
@pytest.fixture
def mock_time(monkeypatch):
    """Mock time.monotonic to return controlled values."""
    mock_monotonic = Mock()
    monkeypatch.setattr(time, "monotonic", mock_monotonic)
    return mock_monotonic
```

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_token_bucket_refill(mock_time):
    # Arrange
    mock_time.return_value = 1000.0  # Initial time
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)
    limiter.tokens = 5.0  # Start with 5 tokens

    # Advance time by 0.5 seconds
    mock_time.return_value = 1000.5

    # Act
    await limiter._refill()

    # Assert
    # After 0.5 seconds at 10 tokens/sec, should add 5 tokens
    assert limiter.tokens == 10.0  # 5 + 5 = 10, capped at max_tokens
```

#### 3.1.3 Test Case: Acquire Tokens - Available

**Purpose:** Verify that tokens can be acquired when available.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_acquire_tokens_available(mock_time):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)
    limiter.tokens = 5.0

    # Act
    wait_time = await limiter.acquire(3.0)

    # Assert
    assert wait_time == 0.0  # No wait time
    assert limiter.tokens == 2.0  # 5 - 3 = 2
```

#### 3.1.4 Test Case: Acquire Tokens - Not Available

**Purpose:** Verify that the correct wait time is returned when tokens are not
available.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_acquire_tokens_not_available(mock_time):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)
    limiter.tokens = 3.0

    # Act
    wait_time = await limiter.acquire(5.0)

    # Assert
    # Need 2 more tokens, at rate 10 per period 1.0
    # Wait time should be (5 - 3) * 1.0 / 10 = 0.2
    assert wait_time == 0.2
    assert limiter.tokens == 3.0  # Tokens unchanged
```

#### 3.1.5 Test Case: Execute - No Wait

**Purpose:** Verify that execute calls the function immediately when tokens are
available.

**Setup:**

```python
@pytest.fixture
def mock_sleep(monkeypatch):
    """Mock asyncio.sleep."""
    mock = AsyncMock()
    monkeypatch.setattr(asyncio, "sleep", mock)
    return mock
```

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_execute_no_wait(mock_time, mock_sleep):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)
    mock_func = AsyncMock(return_value="result")

    # Act
    result = await limiter.execute(mock_func, "arg1", kwarg1="value1")

    # Assert
    assert result == "result"
    mock_func.assert_called_once_with("arg1", kwarg1="value1")
    mock_sleep.assert_not_called()
```

#### 3.1.6 Test Case: Execute - With Wait

**Purpose:** Verify that execute waits before calling the function when tokens
are not available.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_execute_with_wait(mock_time, mock_sleep):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)
    limiter.tokens = 0.5  # Not enough tokens
    mock_func = AsyncMock(return_value="result")

    # Act
    result = await limiter.execute(mock_func, "arg1", kwarg1="value1")

    # Assert
    assert result == "result"
    mock_sleep.assert_called_once_with(0.05)  # (1 - 0.5) * 1.0 / 10 = 0.05
    mock_func.assert_called_once_with("arg1", kwarg1="value1")
```

### 3.2 Test Suite: EndpointRateLimiter

#### 3.2.1 Test Case: Initialization

**Purpose:** Verify that EndpointRateLimiter initializes correctly with default
parameters.

**Test Implementation:**

```python
def test_endpoint_rate_limiter_init():
    # Arrange & Act
    limiter = EndpointRateLimiter(default_rate=10.0, default_period=1.0)

    # Assert
    assert limiter.default_rate == 10.0
    assert limiter.default_period == 1.0
    assert isinstance(limiter.limiters, dict)
    assert len(limiter.limiters) == 0
```

#### 3.2.2 Test Case: Get Limiter - New Endpoint

**Purpose:** Verify that a new rate limiter is created for an unknown endpoint.

**Test Implementation:**

```python
def test_get_limiter_new_endpoint():
    # Arrange
    limiter = EndpointRateLimiter(default_rate=10.0, default_period=1.0)

    # Act
    endpoint_limiter = limiter.get_limiter("api/v1/users")

    # Assert
    assert isinstance(endpoint_limiter, RateLimiter)
    assert endpoint_limiter.bucket.rate == 10.0
    assert endpoint_limiter.bucket.period == 1.0
    assert "api/v1/users" in limiter.limiters
```

#### 3.2.3 Test Case: Get Limiter - Existing Endpoint

**Purpose:** Verify that an existing rate limiter is returned for a known
endpoint.

**Test Implementation:**

```python
def test_get_limiter_existing_endpoint():
    # Arrange
    limiter = EndpointRateLimiter(default_rate=10.0, default_period=1.0)
    endpoint = "api/v1/users"
    first_limiter = limiter.get_limiter(endpoint)

    # Act
    second_limiter = limiter.get_limiter(endpoint)

    # Assert
    assert second_limiter is first_limiter
```

#### 3.2.4 Test Case: Execute

**Purpose:** Verify that execute uses the correct endpoint-specific rate
limiter.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_endpoint_rate_limiter_execute():
    # Arrange
    limiter = EndpointRateLimiter(default_rate=10.0, default_period=1.0)
    endpoint = "api/v1/users"
    mock_func = AsyncMock(return_value="result")

    # Create a spy on the get_limiter method
    with patch.object(limiter, "get_limiter", wraps=limiter.get_limiter) as spy:
        # Act
        result = await limiter.execute(endpoint, mock_func, "arg1", kwarg1="value1")

        # Assert
        assert result == "result"
        spy.assert_called_once_with(endpoint)
        mock_func.assert_called_once_with("arg1", kwarg1="value1")
```

#### 3.2.5 Test Case: Update Rate Limit

**Purpose:** Verify that rate limit parameters can be updated for an endpoint.

**Test Implementation:**

```python
def test_update_rate_limit():
    # Arrange
    limiter = EndpointRateLimiter(default_rate=10.0, default_period=1.0)
    endpoint = "api/v1/users"
    endpoint_limiter = limiter.get_limiter(endpoint)

    # Act
    limiter.update_rate_limit(
        endpoint=endpoint,
        rate=5.0,
        period=2.0,
        max_tokens=15.0,
        reset_tokens=True
    )

    # Assert
    assert endpoint_limiter.bucket.rate == 5.0
    assert endpoint_limiter.bucket.period == 2.0
    assert endpoint_limiter.bucket.max_tokens == 15.0
    assert endpoint_limiter.bucket.tokens == 15.0
```

### 3.3 Test Suite: AdaptiveRateLimiter

#### 3.3.1 Test Case: Initialization

**Purpose:** Verify that AdaptiveRateLimiter initializes correctly with custom
parameters.

**Test Implementation:**

```python
def test_adaptive_rate_limiter_init():
    # Arrange & Act
    limiter = AdaptiveRateLimiter(
        initial_rate=10.0,
        initial_period=1.0,
        min_rate=2.0,
        safety_factor=0.8
    )

    # Assert
    assert limiter.bucket.rate == 10.0
    assert limiter.bucket.period == 1.0
    assert limiter.min_rate == 2.0
    assert limiter.safety_factor == 0.8
```

#### 3.3.2 Test Case: Update From Headers - X-RateLimit Format

**Purpose:** Verify that rate limits are updated correctly based on X-RateLimit
headers.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_update_from_headers_x_ratelimit(mock_time):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = AdaptiveRateLimiter(initial_rate=10.0)

    headers = {
        "X-RateLimit-Limit": "100",
        "X-RateLimit-Remaining": "80",
        "X-RateLimit-Reset": "1030"  # 30 seconds from now
    }

    # Act
    limiter.update_from_headers(headers)

    # Assert
    # 80 remaining / 30 seconds = 2.67 per second
    # With safety factor 0.9: 2.67 * 0.9 = 2.4
    assert limiter.bucket.rate == 2.4
```

#### 3.3.3 Test Case: Update From Headers - RateLimit Format

**Purpose:** Verify that rate limits are updated correctly based on RateLimit
headers.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_update_from_headers_ratelimit(mock_time):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = AdaptiveRateLimiter(initial_rate=10.0)

    headers = {
        "RateLimit-Limit": "100",
        "RateLimit-Remaining": "80",
        "RateLimit-Reset": "1030"  # 30 seconds from now
    }

    # Act
    limiter.update_from_headers(headers)

    # Assert
    # 80 remaining / 30 seconds = 2.67 per second
    # With safety factor 0.9: 2.67 * 0.9 = 2.4
    assert limiter.bucket.rate == 2.4
```

#### 3.3.4 Test Case: Update From Headers - No Relevant Headers

**Purpose:** Verify that rate limits remain unchanged when no relevant headers
are present.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_update_from_headers_no_relevant_headers():
    # Arrange
    limiter = AdaptiveRateLimiter(initial_rate=10.0)
    original_rate = limiter.bucket.rate

    headers = {
        "Content-Type": "application/json",
        "Server": "nginx"
    }

    # Act
    limiter.update_from_headers(headers)

    # Assert
    assert limiter.bucket.rate == original_rate
```

#### 3.3.5 Test Case: Minimum Rate Enforcement

**Purpose:** Verify that the minimum rate is enforced when headers would result
in a lower rate.

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_minimum_rate_enforcement(mock_time):
    # Arrange
    mock_time.return_value = 1000.0
    limiter = AdaptiveRateLimiter(initial_rate=10.0, min_rate=3.0)

    headers = {
        "X-RateLimit-Limit": "100",
        "X-RateLimit-Remaining": "10",
        "X-RateLimit-Reset": "1030"  # 30 seconds from now
    }

    # Act
    limiter.update_from_headers(headers)

    # Assert
    # 10 remaining / 30 seconds = 0.33 per second
    # With safety factor 0.9: 0.33 * 0.9 = 0.3
    # But min_rate is 3.0, so should be 3.0
    assert limiter.bucket.rate == 3.0
```

## 4. Integration Tests

### 4.1 Test Suite: API Client Integration

**Components Involved:** TokenBucketRateLimiter, AsyncAPIClient

**Setup:**

```python
@pytest.fixture
async def rate_limited_api_client():
    """Create an API client with rate limiting."""
    limiter = TokenBucketRateLimiter(rate=5.0, period=1.0)
    client = AsyncAPIClient(
        base_url="https://api.example.com",
        timeout=10.0
    )

    # Patch the request method to avoid actual HTTP requests
    with patch.object(client, "request", AsyncMock(return_value={"data": "response"})):
        yield client, limiter
```

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_api_client_with_rate_limiting(rate_limited_api_client, mock_time):
    # Arrange
    client, limiter = rate_limited_api_client
    mock_time.return_value = 1000.0

    # Act
    start_time = time.monotonic()

    # Make 10 requests with rate limit of 5 per second
    results = []
    for i in range(10):
        result = await limiter.execute(
            client.get,
            f"/endpoint/{i}"
        )
        results.append(result)

        # Advance time slightly for each request
        mock_time.return_value += 0.1

    end_time = time.monotonic()

    # Assert
    assert len(results) == 10
    assert all(r == {"data": "response"} for r in results)

    # Should have made at least one call to sleep due to rate limiting
    # (10 requests at 5 per second should take at least 2 seconds)
    assert end_time - start_time >= 2.0
```

### 4.2 Test Suite: Executor Integration

**Components Involved:** TokenBucketRateLimiter, RateLimitedExecutor

**Setup:**

```python
@pytest.fixture
async def rate_limited_executor():
    """Create a rate-limited executor."""
    executor = RateLimitedExecutor(rate=5.0, period=1.0, max_concurrency=3)
    async with executor:
        yield executor
```

**Test Implementation:**

```python
@pytest.mark.asyncio
async def test_rate_limited_executor_integration(rate_limited_executor):
    # Arrange
    executor = rate_limited_executor

    async def test_operation(i):
        return i * 2

    # Act
    start_time = time.monotonic()

    # Execute 10 operations with rate limit of 5 per second
    results = await asyncio.gather(*[
        executor.execute(test_operation, i) for i in range(10)
    ])

    end_time = time.monotonic()

    # Assert
    assert results == [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]

    # Should take at least 2 seconds to execute 10 operations at 5 per second
    assert end_time - start_time >= 2.0
```

## 5. API Tests

Not applicable for this component as it doesn't expose HTTP endpoints.

## 6. Error Handling Tests

### 6.1 Test Suite: Rate Limiter Error Handling

```python
@pytest.mark.asyncio
async def test_rate_limiter_with_failing_function():
    # Arrange
    limiter = TokenBucketRateLimiter(rate=10.0, period=1.0)

    async def failing_function():
        raise ValueError("Test error")

    # Act & Assert
    with pytest.raises(ValueError, match="Test error"):
        await limiter.execute(failing_function)
```

## 7. Performance Tests

### 7.1 Benchmark / Load Testing

```python
@pytest.mark.asyncio
async def test_rate_limiter_performance(benchmark):
    # Arrange
    limiter = TokenBucketRateLimiter(rate=1000.0, period=1.0)  # High rate to avoid actual limiting

    async def dummy_function():
        return "result"

    # Define async function to benchmark
    async def run_with_rate_limiter():
        return await limiter.execute(dummy_function)

    # Act & Assert
    # Ensure overhead is minimal (less than 1ms)
    result = await benchmark(run_with_rate_limiter)
    assert result == "result"
```

## 8. Mock Implementation Details

```python
class MockTimeProvider:
    """Mock time provider for testing time-based logic."""

    def __init__(self, initial_time=0.0):
        self.current_time = initial_time

    def monotonic(self):
        """Return the current mock time."""
        return self.current_time

    def advance(self, seconds):
        """Advance the mock time by the specified number of seconds."""
        self.current_time += seconds
        return self.current_time
```

## 9. Test Data

```python
# Test rate configurations
rate_configs = [
    {"rate": 10.0, "period": 1.0, "max_tokens": None},  # 10 per second, default max
    {"rate": 5.0, "period": 1.0, "max_tokens": 10.0},   # 5 per second, custom max
    {"rate": 60.0, "period": 60.0, "max_tokens": 60.0}, # 1 per minute, burst up to 60
    {"rate": 1000.0, "period": 1.0, "max_tokens": 100.0}, # 1000 per second, limited burst
]

# Test API response headers
rate_limit_headers = [
    {  # X-RateLimit format
        "X-RateLimit-Limit": "100",
        "X-RateLimit-Remaining": "80",
        "X-RateLimit-Reset": "1030"
    },
    {  # RateLimit format
        "RateLimit-Limit": "100",
        "RateLimit-Remaining": "80",
        "RateLimit-Reset": "1030"
    },
    {  # GitHub format
        "X-RateLimit-Limit": "5000",
        "X-RateLimit-Remaining": "4990",
        "X-RateLimit-Reset": "1644461060"
    },
    {  # Retry-After format
        "Retry-After": "30"
    }
]
```

## 10. Helper Functions

```python
async def measure_execution_time(limiter, func, num_calls):
    """Measure the time it takes to execute a function multiple times with rate limiting."""
    start_time = time.monotonic()

    results = []
    for _ in range(num_calls):
        result = await limiter.execute(func)
        results.append(result)

    end_time = time.monotonic()

    return {
        "results": results,
        "duration": end_time - start_time,
        "calls_per_second": num_calls / (end_time - start_time)
    }
```

## 11. Test Coverage Targets

- **Line Coverage Target:** 90%
- **Branch Coverage Target:** 85%
- **Critical Modules:**
  - `TokenBucketRateLimiter`: 95% coverage
  - `EndpointRateLimiter`: 90% coverage
  - `AdaptiveRateLimiter`: 90% coverage

## 12. Continuous Integration

```yaml
name: Test Rate Limiter
on: [push, pull_request]
jobs:
  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
      - name: Run tests
        run: |
          pytest tests/clients/test_rate_limiter.py --cov=src/khive/clients/rate_limiter.py --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

## 13. Notes and Caveats

### 13.1 Known Limitations

- Time-based tests can be flaky if not properly mocked
- Rate limiting adds some overhead to each request
- Adaptive rate limiting depends on consistent header formats from APIs

### 13.2 Future Improvements

- Implement distributed rate limiting for multi-instance deployments
- Add support for more complex rate limit patterns (e.g., tiered limits)
- Implement quota management across multiple users/services
- Add telemetry for rate limit usage and wait times
