"""
This type stub file was generated by pyright.
"""

import numpy as np
from pathlib import Path
from typing import TypeVar
from sklearn.pipeline import Pipeline
from model2vec.model import PathLike, StaticModel

_DEFAULT_TRUST_PATTERN = ...
_DEFAULT_MODEL_FILENAME = ...
LabelType = TypeVar("LabelType", list[str], list[list[str]])
class StaticModelPipeline:
    def __init__(self, model: StaticModel, head: Pipeline) -> None:
        """Create a pipeline with a StaticModel encoder."""
        ...
    
    @property
    def classes_(self) -> np.ndarray:
        """The classes of the classifier."""
        ...
    
    @classmethod
    def from_pretrained(cls: type[StaticModelPipeline], path: PathLike, token: str | None = ..., trust_remote_code: bool = ...) -> StaticModelPipeline:
        """
        Load a StaticModel from a local path or huggingface hub path.

        NOTE: if you load a private model from the huggingface hub, you need to pass a token.

        :param path: The path to the folder containing the pipeline, or a repository on the Hugging Face Hub
        :param token: The token to use to download the pipeline from the hub.
        :param trust_remote_code: Whether to trust the remote code. If this is False, we will only load components coming from `sklearn`.
        :return: The loaded pipeline.
        """
        ...
    
    def save_pretrained(self, path: str) -> None:
        """Save the model to a folder."""
        ...
    
    def push_to_hub(self, repo_id: str, token: str | None = ..., private: bool = ...) -> None:
        """
        Save a model to a folder, and then push that folder to the hf hub.

        :param repo_id: The id of the repository to push to.
        :param token: The token to use to push to the hub.
        :param private: Whether the repository should be private.
        """
        ...
    
    def predict(self, X: list[str] | str, show_progress_bar: bool = ..., max_length: int | None = ..., batch_size: int = ..., use_multiprocessing: bool = ..., multiprocessing_threshold: int = ..., threshold: float = ...) -> np.ndarray:
        """
        Predict the labels of the input.

        :param X: The input data to predict. Can be a list of strings or a single string.
        :param show_progress_bar: Whether to display a progress bar during prediction. Defaults to False.
        :param max_length: The maximum length of the input sequences. Defaults to 512.
        :param batch_size: The batch size for prediction. Defaults to 1024.
        :param use_multiprocessing: Whether to use multiprocessing for encoding. Defaults to True.
        :param multiprocessing_threshold: The threshold for the number of samples to use multiprocessing. Defaults to 10,000.
        :param threshold: The threshold for multilabel classification. Defaults to 0.5. Ignored if not multilabel.
        :return: The predicted labels or probabilities.
        """
        ...
    
    def predict_proba(self, X: list[str] | str, show_progress_bar: bool = ..., max_length: int | None = ..., batch_size: int = ..., use_multiprocessing: bool = ..., multiprocessing_threshold: int = ...) -> np.ndarray:
        """
        Predict the labels of the input.

        :param X: The input data to predict. Can be a list of strings or a single string.
        :param show_progress_bar: Whether to display a progress bar during prediction. Defaults to False.
        :param max_length: The maximum length of the input sequences. Defaults to 512.
        :param batch_size: The batch size for prediction. Defaults to 1024.
        :param use_multiprocessing: Whether to use multiprocessing for encoding. Defaults to True.
        :param multiprocessing_threshold: The threshold for the number of samples to use multiprocessing. Defaults to 10,000.
        :return: The predicted labels or probabilities.
        """
        ...
    
    def evaluate(self, X: list[str], y: LabelType, batch_size: int = ..., threshold: float = ..., output_dict: bool = ...) -> str | dict[str, dict[str, float]]:
        """
        Evaluate the classifier on a given dataset using scikit-learn's classification report.

        :param X: The texts to predict on.
        :param y: The ground truth labels.
        :param batch_size: The batch size.
        :param threshold: The threshold for multilabel classification.
        :param output_dict: Whether to output the classification report as a dictionary.
        :return: A classification report.
        """
        ...
    


def save_pipeline(pipeline: StaticModelPipeline, folder_path: str | Path) -> None:
    """
    Save a pipeline to a folder.

    :param pipeline: The pipeline to save.
    :param folder_path: The path to the folder to save the pipeline to.
    """
    ...

def evaluate_single_or_multi_label(predictions: np.ndarray, y: LabelType, output_dict: bool = ...) -> str | dict[str, dict[str, float]]:
    """
    Evaluate the classifier on a given dataset using scikit-learn's classification report.

    :param predictions: The predictions.
    :param y: The ground truth labels.
    :param output_dict: Whether to output the classification report as a dictionary.
    :return: A classification report.
    """
    ...

