{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a418ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypekit import Task\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class IrisLoader(Task):\n",
    "    input_types = [\"source\"]\n",
    "    output_types = [\"raw\"]\n",
    "\n",
    "    def run(self, _):\n",
    "        from sklearn.datasets import load_iris\n",
    "        iris = load_iris()\n",
    "        iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "        iris_df['target'] = iris.target\n",
    "        return iris_df\n",
    "\n",
    "\n",
    "class TrainTestSplitter(Task):\n",
    "    input_types = [\"raw\"]\n",
    "    output_types = [\"split\"]\n",
    "\n",
    "    def run(self, df):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "        train_df['train'] = 1\n",
    "        test_df['train'] = 0\n",
    "        df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "class Scaler(Task):\n",
    "    input_types = [\"split\"]\n",
    "    output_types = [\"processed\"]\n",
    "\n",
    "    def run(self, df):\n",
    "        X = df.drop(columns=['target', 'train'])\n",
    "        X_train = X[df['train'] == 1]\n",
    "\n",
    "        scaler = self.get_scaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_scaled = scaler.transform(X)\n",
    "        scaled_df = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "        scaled_df['target'] = df['target']\n",
    "        scaled_df['train'] = df['train']\n",
    "\n",
    "        return scaled_df\n",
    "\n",
    "    def get_scaler(self):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method.\")\n",
    "\n",
    "\n",
    "class MinMaxScaler(Scaler):\n",
    "    def get_scaler(self):\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        return MinMaxScaler()\n",
    "\n",
    "\n",
    "class StandardScaler(Scaler):\n",
    "    def get_scaler(self):\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        return StandardScaler()\n",
    "\n",
    "\n",
    "class PCA(Task):\n",
    "    input_types = [\"split\", \"processed\"]\n",
    "    output_types = [\"processed\"]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def run(self, df):\n",
    "        X = df.drop(columns=['target', 'train'])\n",
    "        X_train = X[df['train'] == 1]\n",
    "\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(**self.kwargs)\n",
    "        pca.fit(X_train)\n",
    "\n",
    "        X_pca = pca.transform(X)\n",
    "        pca_df = pd.DataFrame(data=X_pca, columns=[\n",
    "                              f'PC[i+1]' for i in range(X_pca.shape[1])])\n",
    "        pca_df['target'] = df['target']\n",
    "        pca_df['train'] = df['train']\n",
    "\n",
    "        return pca_df\n",
    "\n",
    "\n",
    "class Classifier(Task):\n",
    "    input_types = [\"split\", \"processed\"]\n",
    "    output_types = [\"processed\", \"predicted\"]\n",
    "\n",
    "    def run(self, df):\n",
    "        X = df.drop(columns=['target', 'train'])\n",
    "        y = df['target']\n",
    "        X_train = X[df['train'] == 1]\n",
    "        y_train = y[df['train'] == 1]\n",
    "\n",
    "        classifier = self.get_classifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = classifier.predict(X)\n",
    "        df['predicted'] = y_pred\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        raise NotImplementedError(\"Subclasses should implement this method.\")\n",
    "\n",
    "\n",
    "class LogisticRegression(Classifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_classifier(self):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression(**self.kwargs)\n",
    "\n",
    "\n",
    "class RandomForestClassifier(Classifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_classifier(self):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier(**self.kwargs)\n",
    "\n",
    "\n",
    "class SVC(Classifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_classifier(self):\n",
    "        from sklearn.svm import SVC\n",
    "        return SVC(**self.kwargs)\n",
    "\n",
    "\n",
    "class Evaluator(Task):\n",
    "    input_types = [\"predicted\"]\n",
    "    output_types = [\"sink\"]\n",
    "\n",
    "    def run(self, df):\n",
    "        df_test = df[df['train'] == 0]\n",
    "        return (df_test['target'] == df_test['predicted']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b55c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "└── Root()\n",
      "    └── IrisLoader()\n",
      "        └── TrainTestSplitter()\n",
      "            ├── MinMaxScaler()\n",
      "            │   ├── PCA()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── SVC()\n",
      "            │   │       ├── LogisticRegression()\n",
      "            │   │       │   ├── RandomForestClassifier()\n",
      "            │   │       │   │   └── Evaluator()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       ├── RandomForestClassifier()\n",
      "            │   │       │   ├── LogisticRegression()\n",
      "            │   │       │   │   └── Evaluator()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       └── Evaluator()\n",
      "            │   ├── LogisticRegression()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       ├── RandomForestClassifier()\n",
      "            │   │   │       │   └── Evaluator()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── SVC()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── RandomForestClassifier()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   ├── RandomForestClassifier()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       ├── LogisticRegression()\n",
      "            │   │   │       │   └── Evaluator()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── SVC()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── LogisticRegression()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   └── SVC()\n",
      "            │       ├── PCA()\n",
      "            │       │   ├── LogisticRegression()\n",
      "            │       │   │   ├── RandomForestClassifier()\n",
      "            │       │   │   │   └── Evaluator()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── RandomForestClassifier()\n",
      "            │       │       ├── LogisticRegression()\n",
      "            │       │       │   └── Evaluator()\n",
      "            │       │       └── Evaluator()\n",
      "            │       ├── LogisticRegression()\n",
      "            │       │   ├── PCA()\n",
      "            │       │   │   └── RandomForestClassifier()\n",
      "            │       │   │       └── Evaluator()\n",
      "            │       │   ├── RandomForestClassifier()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       ├── RandomForestClassifier()\n",
      "            │       │   ├── PCA()\n",
      "            │       │   │   └── LogisticRegression()\n",
      "            │       │   │       └── Evaluator()\n",
      "            │       │   ├── LogisticRegression()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       └── Evaluator()\n",
      "            ├── StandardScaler()\n",
      "            │   ├── PCA()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── SVC()\n",
      "            │   │       ├── LogisticRegression()\n",
      "            │   │       │   ├── RandomForestClassifier()\n",
      "            │   │       │   │   └── Evaluator()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       ├── RandomForestClassifier()\n",
      "            │   │       │   ├── LogisticRegression()\n",
      "            │   │       │   │   └── Evaluator()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       └── Evaluator()\n",
      "            │   ├── LogisticRegression()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       ├── RandomForestClassifier()\n",
      "            │   │   │       │   └── Evaluator()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── SVC()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── RandomForestClassifier()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   ├── RandomForestClassifier()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   ├── SVC()\n",
      "            │   │   │   │   │   └── Evaluator()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       ├── LogisticRegression()\n",
      "            │   │   │       │   └── Evaluator()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── SVC()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── PCA()\n",
      "            │   │   │   │   └── LogisticRegression()\n",
      "            │   │   │   │       └── Evaluator()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   └── SVC()\n",
      "            │       ├── PCA()\n",
      "            │       │   ├── LogisticRegression()\n",
      "            │       │   │   ├── RandomForestClassifier()\n",
      "            │       │   │   │   └── Evaluator()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── RandomForestClassifier()\n",
      "            │       │       ├── LogisticRegression()\n",
      "            │       │       │   └── Evaluator()\n",
      "            │       │       └── Evaluator()\n",
      "            │       ├── LogisticRegression()\n",
      "            │       │   ├── PCA()\n",
      "            │       │   │   └── RandomForestClassifier()\n",
      "            │       │   │       └── Evaluator()\n",
      "            │       │   ├── RandomForestClassifier()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       ├── RandomForestClassifier()\n",
      "            │       │   ├── PCA()\n",
      "            │       │   │   └── LogisticRegression()\n",
      "            │       │   │       └── Evaluator()\n",
      "            │       │   ├── LogisticRegression()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       └── Evaluator()\n",
      "            ├── PCA()\n",
      "            │   ├── LogisticRegression()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   ├── RandomForestClassifier()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   ├── LogisticRegression()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   └── SVC()\n",
      "            │       ├── LogisticRegression()\n",
      "            │       │   ├── RandomForestClassifier()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       ├── RandomForestClassifier()\n",
      "            │       │   ├── LogisticRegression()\n",
      "            │       │   │   └── Evaluator()\n",
      "            │       │   └── Evaluator()\n",
      "            │       └── Evaluator()\n",
      "            ├── LogisticRegression()\n",
      "            │   ├── PCA()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── SVC()\n",
      "            │   │       ├── RandomForestClassifier()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       └── Evaluator()\n",
      "            │   ├── RandomForestClassifier()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   ├── SVC()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   └── RandomForestClassifier()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── RandomForestClassifier()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   └── Evaluator()\n",
      "            ├── RandomForestClassifier()\n",
      "            │   ├── PCA()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   ├── SVC()\n",
      "            │   │   │   │   └── Evaluator()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── SVC()\n",
      "            │   │       ├── LogisticRegression()\n",
      "            │   │       │   └── Evaluator()\n",
      "            │   │       └── Evaluator()\n",
      "            │   ├── LogisticRegression()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   └── SVC()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── SVC()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   ├── SVC()\n",
      "            │   │   ├── PCA()\n",
      "            │   │   │   └── LogisticRegression()\n",
      "            │   │   │       └── Evaluator()\n",
      "            │   │   ├── LogisticRegression()\n",
      "            │   │   │   └── Evaluator()\n",
      "            │   │   └── Evaluator()\n",
      "            │   └── Evaluator()\n",
      "            └── SVC()\n",
      "                ├── PCA()\n",
      "                │   ├── LogisticRegression()\n",
      "                │   │   ├── RandomForestClassifier()\n",
      "                │   │   │   └── Evaluator()\n",
      "                │   │   └── Evaluator()\n",
      "                │   └── RandomForestClassifier()\n",
      "                │       ├── LogisticRegression()\n",
      "                │       │   └── Evaluator()\n",
      "                │       └── Evaluator()\n",
      "                ├── LogisticRegression()\n",
      "                │   ├── PCA()\n",
      "                │   │   └── RandomForestClassifier()\n",
      "                │   │       └── Evaluator()\n",
      "                │   ├── RandomForestClassifier()\n",
      "                │   │   └── Evaluator()\n",
      "                │   └── Evaluator()\n",
      "                ├── RandomForestClassifier()\n",
      "                │   ├── PCA()\n",
      "                │   │   └── LogisticRegression()\n",
      "                │   │       └── Evaluator()\n",
      "                │   ├── LogisticRegression()\n",
      "                │   │   └── Evaluator()\n",
      "                │   └── Evaluator()\n",
      "                └── Evaluator()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypekit import Repository, CachedExecutor\n",
    "\n",
    "repository = Repository([\n",
    "    IrisLoader,\n",
    "    TrainTestSplitter,\n",
    "    MinMaxScaler,\n",
    "    StandardScaler,\n",
    "    PCA,\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    SVC,\n",
    "    Evaluator\n",
    "])\n",
    "\n",
    "repository.build_tree()\n",
    "print(repository.build_tree_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92319db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), LogisticRegression(), RandomForestClassifier(), SVC(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), LogisticRegression(), RandomForestClassifier(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), LogisticRegression(), SVC(), RandomForestClassifier(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), LogisticRegression(), SVC(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), LogisticRegression(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), RandomForestClassifier(), LogisticRegression(), SVC(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), RandomForestClassifier(), LogisticRegression(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), RandomForestClassifier(), SVC(), LogisticRegression(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), RandomForestClassifier(), SVC(), Evaluator()]),\n",
       " Pipeline(tasks=[IrisLoader(), TrainTestSplitter(), MinMaxScaler(), PCA(), RandomForestClassifier(), Evaluator()])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines = repository.build_pipelines()\n",
    "pipelines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21da542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1/144 completed. Runtime: 0.58s.\n",
      "Pipeline 2/144 completed. Runtime: 0.58s.\n",
      "Pipeline 3/144 completed. Runtime: 0.53s.\n",
      "Pipeline 4/144 completed. Runtime: 0.47s.\n",
      "Pipeline 5/144 completed. Runtime: 0.46s.\n",
      "Pipeline 6/144 completed. Runtime: 0.53s.\n",
      "Pipeline 7/144 completed. Runtime: 0.52s.\n",
      "Pipeline 8/144 completed. Runtime: 0.52s.\n",
      "Pipeline 9/144 completed. Runtime: 0.52s.\n",
      "Pipeline 10/144 completed. Runtime: 0.51s.\n",
      "Pipeline 11/144 completed. Runtime: 0.55s.\n",
      "Pipeline 12/144 completed. Runtime: 0.45s.\n",
      "Pipeline 13/144 completed. Runtime: 0.53s.\n",
      "Pipeline 14/144 completed. Runtime: 0.52s.\n",
      "Pipeline 15/144 completed. Runtime: 0.45s.\n",
      "Pipeline 16/144 completed. Runtime: 0.52s.\n",
      "Pipeline 17/144 completed. Runtime: 0.52s.\n",
      "Pipeline 18/144 completed. Runtime: 0.50s.\n",
      "Pipeline 19/144 completed. Runtime: 0.43s.\n",
      "Pipeline 20/144 completed. Runtime: 0.50s.\n",
      "Pipeline 21/144 completed. Runtime: 0.49s.\n",
      "Pipeline 22/144 completed. Runtime: 0.49s.\n",
      "Pipeline 23/144 completed. Runtime: 0.50s.\n",
      "Pipeline 24/144 completed. Runtime: 0.50s.\n",
      "Pipeline 25/144 completed. Runtime: 0.43s.\n",
      "Pipeline 26/144 completed. Runtime: 0.43s.\n",
      "Pipeline 27/144 completed. Runtime: 0.50s.\n",
      "Pipeline 28/144 completed. Runtime: 0.50s.\n",
      "Pipeline 29/144 completed. Runtime: 0.50s.\n",
      "Pipeline 30/144 completed. Runtime: 0.49s.\n",
      "Pipeline 31/144 completed. Runtime: 0.50s.\n",
      "Pipeline 32/144 completed. Runtime: 0.49s.\n",
      "Pipeline 33/144 completed. Runtime: 0.49s.\n",
      "Pipeline 34/144 completed. Runtime: 0.50s.\n",
      "Pipeline 35/144 completed. Runtime: 0.49s.\n",
      "Pipeline 36/144 completed. Runtime: 0.49s.\n",
      "Pipeline 37/144 completed. Runtime: 0.49s.\n",
      "Pipeline 38/144 completed. Runtime: 0.52s.\n",
      "Pipeline 39/144 completed. Runtime: 0.43s.\n",
      "Pipeline 40/144 completed. Runtime: 0.51s.\n",
      "Pipeline 41/144 completed. Runtime: 0.50s.\n",
      "Pipeline 42/144 completed. Runtime: 0.52s.\n",
      "Pipeline 43/144 completed. Runtime: 0.50s.\n",
      "Pipeline 44/144 completed. Runtime: 0.43s.\n",
      "Pipeline 45/144 completed. Runtime: 0.50s.\n",
      "Pipeline 46/144 completed. Runtime: 0.50s.\n",
      "Pipeline 47/144 completed. Runtime: 0.49s.\n",
      "Pipeline 48/144 completed. Runtime: 0.43s.\n",
      "Pipeline 49/144 completed. Runtime: 0.52s.\n",
      "Pipeline 50/144 completed. Runtime: 0.52s.\n",
      "Pipeline 51/144 completed. Runtime: 0.50s.\n",
      "Pipeline 52/144 completed. Runtime: 0.43s.\n",
      "Pipeline 53/144 completed. Runtime: 0.43s.\n",
      "Pipeline 54/144 completed. Runtime: 0.50s.\n",
      "Pipeline 55/144 completed. Runtime: 0.50s.\n",
      "Pipeline 56/144 completed. Runtime: 0.50s.\n",
      "Pipeline 57/144 completed. Runtime: 0.49s.\n",
      "Pipeline 58/144 completed. Runtime: 0.49s.\n",
      "Pipeline 59/144 completed. Runtime: 0.53s.\n",
      "Pipeline 60/144 completed. Runtime: 0.44s.\n",
      "Pipeline 61/144 completed. Runtime: 0.51s.\n",
      "Pipeline 62/144 completed. Runtime: 0.50s.\n",
      "Pipeline 63/144 completed. Runtime: 0.43s.\n",
      "Pipeline 64/144 completed. Runtime: 0.54s.\n",
      "Pipeline 65/144 completed. Runtime: 0.53s.\n",
      "Pipeline 66/144 completed. Runtime: 0.50s.\n",
      "Pipeline 67/144 completed. Runtime: 0.43s.\n",
      "Pipeline 68/144 completed. Runtime: 0.50s.\n",
      "Pipeline 69/144 completed. Runtime: 0.50s.\n",
      "Pipeline 70/144 completed. Runtime: 0.49s.\n",
      "Pipeline 71/144 completed. Runtime: 0.50s.\n",
      "Pipeline 72/144 completed. Runtime: 0.49s.\n",
      "Pipeline 73/144 completed. Runtime: 0.43s.\n",
      "Pipeline 74/144 completed. Runtime: 0.43s.\n",
      "Pipeline 75/144 completed. Runtime: 0.49s.\n",
      "Pipeline 76/144 completed. Runtime: 0.49s.\n",
      "Pipeline 77/144 completed. Runtime: 0.49s.\n",
      "Pipeline 78/144 completed. Runtime: 0.49s.\n",
      "Pipeline 79/144 completed. Runtime: 0.49s.\n",
      "Pipeline 80/144 completed. Runtime: 0.49s.\n",
      "Pipeline 81/144 completed. Runtime: 0.49s.\n",
      "Pipeline 82/144 completed. Runtime: 0.49s.\n",
      "Pipeline 83/144 completed. Runtime: 0.49s.\n",
      "Pipeline 84/144 completed. Runtime: 0.49s.\n",
      "Pipeline 85/144 completed. Runtime: 0.48s.\n",
      "Pipeline 86/144 completed. Runtime: 0.52s.\n",
      "Pipeline 87/144 completed. Runtime: 0.43s.\n",
      "Pipeline 88/144 completed. Runtime: 0.51s.\n",
      "Pipeline 89/144 completed. Runtime: 0.50s.\n",
      "Pipeline 90/144 completed. Runtime: 0.51s.\n",
      "Pipeline 91/144 completed. Runtime: 0.50s.\n",
      "Pipeline 92/144 completed. Runtime: 0.43s.\n",
      "Pipeline 93/144 completed. Runtime: 0.51s.\n",
      "Pipeline 94/144 completed. Runtime: 0.50s.\n",
      "Pipeline 95/144 completed. Runtime: 0.49s.\n",
      "Pipeline 96/144 completed. Runtime: 0.43s.\n",
      "Pipeline 97/144 completed. Runtime: 0.52s.\n",
      "Pipeline 98/144 completed. Runtime: 0.51s.\n",
      "Pipeline 99/144 completed. Runtime: 0.50s.\n",
      "Pipeline 100/144 completed. Runtime: 0.43s.\n",
      "Pipeline 101/144 completed. Runtime: 0.43s.\n",
      "Pipeline 102/144 completed. Runtime: 0.50s.\n",
      "Pipeline 103/144 completed. Runtime: 0.50s.\n",
      "Pipeline 104/144 completed. Runtime: 0.50s.\n",
      "Pipeline 105/144 completed. Runtime: 0.49s.\n",
      "Pipeline 106/144 completed. Runtime: 0.49s.\n",
      "Pipeline 107/144 completed. Runtime: 0.51s.\n",
      "Pipeline 108/144 completed. Runtime: 0.43s.\n",
      "Pipeline 109/144 completed. Runtime: 0.50s.\n",
      "Pipeline 110/144 completed. Runtime: 0.49s.\n",
      "Pipeline 111/144 completed. Runtime: 0.43s.\n",
      "Pipeline 112/144 completed. Runtime: 0.53s.\n",
      "Pipeline 113/144 completed. Runtime: 0.52s.\n",
      "Pipeline 114/144 completed. Runtime: 0.50s.\n",
      "Pipeline 115/144 completed. Runtime: 0.44s.\n",
      "Pipeline 116/144 completed. Runtime: 0.50s.\n",
      "Pipeline 117/144 completed. Runtime: 0.50s.\n",
      "Pipeline 118/144 completed. Runtime: 0.49s.\n",
      "Pipeline 119/144 completed. Runtime: 0.50s.\n",
      "Pipeline 120/144 completed. Runtime: 0.50s.\n",
      "Pipeline 121/144 completed. Runtime: 0.43s.\n",
      "Pipeline 122/144 completed. Runtime: 0.43s.\n",
      "Pipeline 123/144 completed. Runtime: 0.49s.\n",
      "Pipeline 124/144 completed. Runtime: 0.49s.\n",
      "Pipeline 125/144 completed. Runtime: 0.49s.\n",
      "Pipeline 126/144 completed. Runtime: 0.49s.\n",
      "Pipeline 127/144 completed. Runtime: 0.49s.\n",
      "Pipeline 128/144 completed. Runtime: 0.49s.\n",
      "Pipeline 129/144 completed. Runtime: 0.49s.\n",
      "Pipeline 130/144 completed. Runtime: 0.49s.\n",
      "Pipeline 131/144 completed. Runtime: 0.49s.\n",
      "Pipeline 132/144 completed. Runtime: 0.48s.\n",
      "Pipeline 133/144 completed. Runtime: 0.48s.\n",
      "Pipeline 134/144 completed. Runtime: 0.52s.\n",
      "Pipeline 135/144 completed. Runtime: 0.43s.\n",
      "Pipeline 136/144 completed. Runtime: 0.50s.\n",
      "Pipeline 137/144 completed. Runtime: 0.50s.\n",
      "Pipeline 138/144 completed. Runtime: 0.52s.\n",
      "Pipeline 139/144 completed. Runtime: 0.50s.\n",
      "Pipeline 140/144 completed. Runtime: 0.43s.\n",
      "Pipeline 141/144 completed. Runtime: 0.50s.\n",
      "Pipeline 142/144 completed. Runtime: 0.49s.\n",
      "Pipeline 143/144 completed. Runtime: 0.49s.\n",
      "Pipeline 144/144 completed. Runtime: 0.42s.\n"
     ]
    }
   ],
   "source": [
    "executor = CachedExecutor(pipelines, verbose=True)\n",
    "results = executor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b1dd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5790615909991175, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5767250099988814, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5309084829996209, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4669725429994287, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4643488539995815, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5276213039996946, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5246188619994427, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5210413779996088, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5172074130005058, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5145910439996442, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5494158370001969, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.45424612700026046, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5284010790001048, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5223905179991561, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4500443510005425, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5241138249984942, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5209666259988808, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5019276799994259, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4326921179990677, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4962138210003104, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4939621610001268, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49195655299990904, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49758441199992376, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4967451129996334, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42937137499939126, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.427564044999599, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5016441420002593, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4992716869992364, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49729852100063, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49351783500060264, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4968471089987361, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49429479699847434, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49201009499938664, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49625863099936396, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49418539599992073, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49071138100043754, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4883871980000549, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5185708050003086, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4313022579999597, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5109695369992551, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49795586700020067, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.51663926800029, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.499732455999947, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4287835309996808, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5012220220005474, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49526353500004916, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49174502400001074, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42559637399972416, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'MinMaxScaler()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5197937900011311, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5168112070005009, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5018211190008515, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.43160564100162446, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4294215850004548, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5008629220010334, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.49604362700119964, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.49766305499906593, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4933531390006465, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.49019223200048145, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5287136250008189, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4353018530009649, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5057520350001141, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.501001749000352, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4285196070013626, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5371918569990157, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5344575369990707, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4975468180000462, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4325594240008286, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49852103000011994, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4956101040006615, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.493328957999438, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49833735800075374, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49034903200026747, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4293659110007866, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42733231999955024, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4945485580001332, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4913790609998614, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49381370799983415, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4883825910001178, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49449316400114185, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.48991012100032094, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4870508640005937, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4918817580000905, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4900286910005889, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4860261020003236, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4833219359998111, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5208667849992707, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.43147129099997983, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5096775210004125, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4987383529996805, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.513036256000305, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4981568130006053, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.430096549001064, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.506116958000348, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4964759790009339, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49268929900063085, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4255749559997639, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'StandardScaler()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5175594370011822, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5148977450007806, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49641906900160393, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.428606089000823, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42626329000086116, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5012450350013751, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4984516300000905, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49635481199948117, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49272271700010606, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4900429899998926, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5124047859990242, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.43002850499942724, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4977219669999613, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4930467879994467, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42601843899956293, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5250381300002118, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5225795229998766, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.5027769329999501, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'PCA()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(1.0), 'runtime': 0.4352392129994769, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49836129899904336, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4961082899990288, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4941516769986265, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5011472809992483, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49655103199893347, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.43181747699873085, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4297885249998217, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4943834900004731, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4916376430001037, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4911463630014623, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4875109690010504, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4942362140000114, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'LogisticRegression()', 'PCA()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49172053700021934, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'LogisticRegression()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.48919311000099697, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4901089940003658, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4913906000001589, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.484442232001129, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'SVC()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.48258246400018834, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.521875433999412, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'PCA()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42977509499996813, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5011399730001358, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.49651827899924683, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5215335039993079, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'LogisticRegression()', 'PCA()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.5008753599986449, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'LogisticRegression()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.43038453400004073, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.498968331998185, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'RandomForestClassifier()', 'PCA()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.4941188559987495, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'RandomForestClassifier()', 'LogisticRegression()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.48710407599901373, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'RandomForestClassifier()', 'Evaluator()']}\n",
      "{'output': np.float64(0.9666666666666667), 'runtime': 0.42407821100005094, 'tasks': ['IrisLoader()', 'TrainTestSplitter()', 'SVC()', 'Evaluator()']}\n"
     ]
    }
   ],
   "source": [
    "for r in results.values():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb2e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypekit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
