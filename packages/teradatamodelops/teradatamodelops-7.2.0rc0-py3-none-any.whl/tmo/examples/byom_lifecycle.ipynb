{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOM Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmo import TmoClient\n",
    "\n",
    "client = TmoClient()\n",
    "\n",
    "# list all projects\n",
    "list(client.projects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set values for model file and project id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./artifacts/pima.pmml\"\n",
    "language = \"PMML\"\n",
    "client.project_id = \"23e1df4b-b630-47a1-ab80-7ad5385fcd8d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dataset templates along with train and evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template = client.dataset_templates().find_by_name_like(\"PIMA\")[\"_embedded\"][\n",
    "    \"datasetTemplates\"\n",
    "][0]\n",
    "dataset_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = client.datasets().find_by_dataset_template_id(dataset_template[\"id\"])[\n",
    "    \"_embedded\"\n",
    "][\"datasets\"]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train dataset\n",
    "\n",
    "train_dataset = [d for d in datasets if d[\"scope\"] == \"train\"][0]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluate dataset\n",
    "\n",
    "evaluate_dataset = [d for d in datasets if d[\"scope\"] == \"evaluate\"][0]\n",
    "eval_dataset_id = evaluate_dataset[\"id\"]\n",
    "eval_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Default Dataset Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New API, allows users do fetch a default dataset connection\n",
    "# (notice it only works for real users, service account probably don't have personal connections)\n",
    "\n",
    "default_connection = client.user_attributes().get_default_connection()\n",
    "default_connection\n",
    "default_connection_id = default_connection[\"value\"][\"defaultDatasetConnectionId\"]\n",
    "default_connection_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a BYOM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "model_dict = {\n",
    "    \"name\": f\"{language}_Python_{uuid.uuid4().clock_seq}\",\n",
    "    \"description\": f\"{language} model defined from Python SDK\",\n",
    "    \"language\": language,\n",
    "}\n",
    "\n",
    "model_response = client.models().save(model_dict)\n",
    "model = model_response[\"id\"]\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_id = client.trained_model_artefacts().upload_byom_model(\"PMML\", file)\n",
    "import_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import BYOM model and monitor the compute statistics job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import_request parameters**:\n",
    "\n",
    "To skip Model Monitoring, you can remove the `modelMonitoring` JSON object and instead use the `metadata` object: \n",
    "```json\n",
    "metadata: {\n",
    "    \"language\": language,\n",
    "    \"evaluationEnabled\": False,\n",
    "    \"datasetId\": train_dataset[\"id\"],\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "}\n",
    "```\n",
    "\n",
    "This will disable model monitoring and should be used for models that just need to be approved and deployed after importing.\n",
    "To enable model monitoring and evaluation, use the below parameters:\n",
    "\n",
    "modelMonitoring:\n",
    "- *useDefaultEvaluation* - Set to True to enable default evaluation. Set to False while using custom metrics for evaluation, performance monitoring,\n",
    "  feature and prediction drift monitoring (True is required when enabling model monitoring with default metrics)\n",
    "- *evaluationEnabled* - Set to True to enable model evaluation and performance monitoring\n",
    "- *modelType* - The type of the model, either CLASSIFICATION or REGRESSION\n",
    "- *byomColumnExpression*: The predicition expression for the model\n",
    "- *driftMonitoringEnabled*: Set to True to enable feature and prediction drift monitoring. This will run the computing statistics after importing the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_request = {\n",
    "    \"artefactImportId\": import_id,\n",
    "    \"externalId\": str(uuid.uuid4()),\n",
    "    \"modelMonitoring\": {\n",
    "        \"language\": language,\n",
    "        \"useDefaultEvaluation\": True,\n",
    "        \"evaluationEnabled\": True,\n",
    "        \"modelType\": \"CLASSIFICATION\",\n",
    "        \"byomColumnExpression\": (\n",
    "            \"CAST(CAST(json_report AS JSON).JSONExtractValue('$.predicted_HasDiabetes')\"\n",
    "            \" AS INT)\"\n",
    "        ),\n",
    "        \"driftMonitoringEnabled\": True,\n",
    "        \"datasetId\": train_dataset[\"id\"],\n",
    "        \"datasetConnectionId\": default_connection_id,\n",
    "    },\n",
    "}\n",
    "\n",
    "response = client.models().import_byom(model, import_request)\n",
    "import_job_id = response[\"id\"]\n",
    "\n",
    "client.jobs().wait(import_job_id)\n",
    "\n",
    "print(\"Model imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitoring Compute Statistics Job\n",
    "\n",
    "totalPages = client.jobs().find_all()[\"page\"][\"totalPages\"]\n",
    "compute_stats_job = None\n",
    "\n",
    "for page in range(totalPages):\n",
    "    jobs = client.jobs().find_all(page=page)\n",
    "\n",
    "    for job in jobs[\"_embedded\"][\"jobs\"]:\n",
    "        if job[\"type\"] == \"COMPUTE_STATISTICS\" and job[\"modelId\"] == model:\n",
    "            job_events = client.job_events().find_by_job_id(job[\"id\"])\n",
    "            status = job_events[\"_embedded\"][\"jobEvents\"][-1][\"status\"]\n",
    "            if status in [\"CREATED\", \"SCHEDULED\", \"ASSIGNED\", \"RUNNING\"]:\n",
    "                compute_stats_job = job\n",
    "                break\n",
    "\n",
    "    if compute_stats_job:\n",
    "        break\n",
    "\n",
    "if compute_stats_job:\n",
    "    client.jobs().wait(compute_stats_job[\"id\"])\n",
    "    print(\"Compute statistics completed\")\n",
    "else:\n",
    "    print(\"No running compute statistics job found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_model_id = response[\"metadata\"][\"trainedModel\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "eval_request = {\n",
    "    \"datasetId\": eval_dataset_id,\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "    \"automationOverrides\": {\n",
    "        \"resources\": {\"memory\": \"500m\", \"cpu\": \"0.5\"},\n",
    "        \"dockerImage\": (\n",
    "            \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.11.4\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "evaluate_response = client.trained_models().evaluate(imported_model_id, eval_request)\n",
    "\n",
    "eval_job_id = evaluate_response[\"id\"]\n",
    "client.jobs().wait(eval_job_id)\n",
    "\n",
    "print(\"Model evaluated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.trained_models().approve(imported_model_id, comments=\"LGTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy model and monitor batch prediction job"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "deploy_request = {\n",
    "    \"engineType\": \"IN_VANTAGE\",\n",
    "    \"engineTypeConfig\": {\n",
    "        \"dockerImage\": (\n",
    "            \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.11.4\"\n",
    "        ),\n",
    "        \"engine\": \"byom\",\n",
    "        \"resources\": {\n",
    "            \"memory\": \"500m\",\n",
    "            \"cpu\": \"0.5\",\n",
    "        },\n",
    "    },\n",
    "    \"language\": \"PMML\",\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "    \"byomModelLocation\": {\"database\": \"trng_modelops\", \"table\": \"vmo_byom_models\"},\n",
    "    \"datasetTemplateId\": dataset_template[\"id\"],\n",
    "    \"cron\": \"@once\",\n",
    "    \"publishOnly\": \"false\",\n",
    "    \"customProperties\": {},\n",
    "}\n",
    "\n",
    "deploy_response = client.trained_models().deploy(imported_model_id, deploy_request)\n",
    "\n",
    "client.jobs().wait(deploy_response[\"id\"])\n",
    "print(\"Model deployed\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# monitoring Batch Prediction Job\n",
    "\n",
    "deployment = client.deployments().find_by_deployment_job_id(deploy_response[\"id\"])\n",
    "jobs = client.jobs().find_by_deployment_id(deployment[\"id\"], \"expandJob\")[\"_embedded\"][\n",
    "    \"jobs\"\n",
    "]\n",
    "\n",
    "if len(jobs) == 1:\n",
    "    client.jobs().wait(jobs[0][\"id\"])\n",
    "    print(\"Job completed\")\n",
    "elif len(jobs) == 0:\n",
    "    print(\"No jobs found\")\n",
    "else:\n",
    "    print(\"Multiple jobs found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
