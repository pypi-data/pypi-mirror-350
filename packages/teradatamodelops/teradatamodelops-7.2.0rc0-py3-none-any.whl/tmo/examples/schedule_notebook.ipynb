{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows an example of importing and scheduling another notebook in ModelOps. The notebook that's being scheduled is available [in artifacts directory](./artifacts/BYO_Notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "First, we need to initialize a client. It will pickup ModelOps instance configuration automatically from `~/.tmo/` directory. Alternatively, you could provide connection parameters to `TmoClient` constructor."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmo import TmoClient\n",
    "\n",
    "client = TmoClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a couple of helper functions that will help us to format some API outputs, and let's see if we have a project configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"max_colwidth\", 140)\n",
    "\n",
    "\n",
    "def dict_to_frame(d, columns=None):\n",
    "    if columns:\n",
    "        return pd.DataFrame(\n",
    "            [[k, v] for (k, v) in list(d.items()) if k in columns],\n",
    "            columns=[\"attribute\", \"value\"],\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame(list(d.items()), columns=[\"attribute\", \"value\"])\n",
    "\n",
    "\n",
    "def list_to_frame(d, columns):\n",
    "    return pd.DataFrame(\n",
    "        [[l.get(column) for column in columns] for l in d], columns=columns\n",
    "    )\n",
    "\n",
    "\n",
    "list_to_frame(\n",
    "    list(client.projects()),\n",
    "    [\"id\", \"name\", \"description\", \"groupId\", \"gitRepositoryUrl\", \"createdAt\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll configure a current project for our client instance. It will allow us to skip project ID for all other calls we make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_project_id(\"70d4659b-92a2-4723-841a-9ba5629b5f27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask ModelOps to describe this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.describe_current_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define BYOM model and import model version (the notebook itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should define what we want to import:\n",
    "1. The notebook itself\n",
    "2. Optionally, `requirements.txt` file for any additional Python requirements\n",
    "3. Any additional artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"./artifacts/BYO_Notebook.ipynb\", \"./artifacts/requirements.txt\"]\n",
    "language = \"Jupyter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a model in ModelOps, under which we'll register this notebook as a new model version. Alternatively, you could use an existing model, make sure its ID is in `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "import_id = str(uuid.uuid4())\n",
    "\n",
    "model_dict = {\n",
    "    \"name\": f\"{language}_Demo_{uuid.uuid4().clock_seq}\",\n",
    "    \"description\": f\"{language} model defined from Python SDK\",\n",
    "    \"language\": language,\n",
    "}\n",
    "model_response = client.models().save(model_dict)\n",
    "model = model_response[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we upload desired artifacts. Notice that we should preserve `import_id` for additional imports and to instruct ModelOps to registed imported artifacts as BYOM model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.trained_model_artefacts().upload_artefacts(import_id, artefacts=files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can register this imported artifact as a BYOM model version. `import_request` here is very simple:\n",
    "- `artefactImportId` is that `import_id` we've used before to upload artifacts\n",
    "- `externalId` is any non-empty string that you could use to track this particular artifact (e.g. Notebook identifier in a different system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_request = {\"artefactImportId\": import_id, \"externalId\": str(uuid.uuid4())}\n",
    "import_job = client.models().import_byom(model, import_request)\n",
    "imported_model_id = import_job[\"metadata\"][\"trainedModel\"][\"id\"]\n",
    "client.jobs().wait(import_job[\"id\"])\n",
    "print(\"Model imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approve imported model version (notebook) for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is simple, but important. We have to approve the model version in order to allow us (and others) to deploy it. We need just a model version ID, and we are free to provide any comment for the approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_frame(client.trained_models().approve(imported_model_id, comments=\"LGTM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule a notebook for single execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model version is approved, we can schedule it for regular (or singular) execution. First, we need a `dataset_template` identifier, that will be provided as metadata to our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template = client.dataset_templates().find_by_name_like(\"PIMA\")[\"_embedded\"][\n",
    "    \"datasetTemplates\"\n",
    "][0]\n",
    "dict_to_frame(dataset_template, columns=[\"id\", \"name\", \"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a deployment request and use it to deploy the model version. This deployment doesn't have a schedule defined (see `cron` value), and we'll trigger scoring jobs for it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_request = {\n",
    "    \"engineType\": \"DOCKER_BATCH\",\n",
    "    \"engineTypeConfig\": {\n",
    "        \"dockerImage\": (\n",
    "            \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.11.4\"\n",
    "        ),\n",
    "        \"engine\": \"jupyter\",\n",
    "        \"resources\": {\n",
    "            \"memory\": \"2g\",\n",
    "            \"cpu\": \"1\",\n",
    "        },\n",
    "    },\n",
    "    \"language\": \"jupyter\",\n",
    "    \"datasetConnectionId\": client.get_default_connection_id(),\n",
    "    \"byomModelLocation\": {\"database\": \"trng_modelops\", \"table\": \"vmo_byom_models\"},\n",
    "    \"datasetTemplateId\": dataset_template[\"id\"],\n",
    "    \"cron\": \"None\",\n",
    "    \"publishOnly\": \"false\",\n",
    "    \"customProperties\": {},\n",
    "}\n",
    "\n",
    "deploy_job = client.trained_models().deploy(imported_model_id, deploy_request)\n",
    "\n",
    "client.jobs().wait(deploy_job[\"id\"])\n",
    "deployment = client.deployments().find_by_deployment_job_id(deploy_job[\"id\"])\n",
    "print(\"Model deployed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger the prediction job\n",
    "Now we can trigger prediction jobs manually. Please note `args` dictionary, it could be used to pass any scoring requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_request = {\n",
    "    \"args\": {\"USER_VARIABLE \": \"scoring_job\"},\n",
    "    \"datasetConnectionId\": \"6b07ae1e-0d79-46a7-8f9b-2f05ca957cdc\",\n",
    "    \"automationOverrides\": {\n",
    "        \"resources\": {\"memory\": \"1g\", \"cpu\": \"1\"},\n",
    "        \"dockerImage\": (\n",
    "            \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.11.4\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "client.deployments().run_scoring(deployment[\"id\"], scoring_request)\n",
    "print(\"Scoring job submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor the prediction job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model version is deployed, we should start looking for prediction jobs initiated by this deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = client.jobs().find_by_deployment_id(deployment[\"id\"], \"expandJob\")[\"_embedded\"][\n",
    "    \"jobs\"\n",
    "]\n",
    "list_to_frame(jobs, [\"id\", \"type\", \"status\", \"createdAt\", \"updatedAt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there's at least a single job, let's monitor it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(jobs) == 1:\n",
    "    client.jobs().wait(jobs[0][\"id\"])\n",
    "    print(\"Job completed\")\n",
    "elif len(jobs) == 0:\n",
    "    print(\"No jobs found\")\n",
    "else:\n",
    "    print(\"Multiple jobs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
