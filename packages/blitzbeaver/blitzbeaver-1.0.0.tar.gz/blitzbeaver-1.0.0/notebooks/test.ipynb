{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import blitzbeaver as bb\n",
    "\n",
    "pl.Config.set_tbl_rows(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # we need to cap the string values to a maximum of 256 characters\n",
    "    # to avoid issues in the computation of the levenshtein distance\n",
    "    return df.with_columns(\n",
    "        df[\"enfants_chez_parents_prenom\"]\n",
    "        .str.split(\"|\")\n",
    "        .list.eval(pl.element().filter(pl.element() != \"\").slice(0, 255))\n",
    "        .alias(\"enfants_chez_parents_prenom\"),\n",
    "        df[\"nom_rue\"].str.slice(0, 255).alias(\"nom_rue\"),\n",
    "        df[\"chef_prenom\"].str.slice(0, 255).alias(\"chef_prenom\"),\n",
    "        df[\"chef_nom\"].str.slice(0, 255).alias(\"chef_nom\"),\n",
    "        df[\"chef_origine\"].str.slice(0, 255).alias(\"chef_origine\"),\n",
    "        df[\"epouse_nom\"].str.slice(0, 255).alias(\"epouse_nom\"),\n",
    "        df[\"chef_vocation\"].str.slice(0, 255).alias(\"chef_vocation\"),\n",
    "    )\n",
    "\n",
    "def postprocess_df(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(\n",
    "        df[\"enfants_chez_parents_prenom\"].list.join(\"|\").alias(\"enfants_chez_parents_prenom\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../../aptihramy/data/csv_cleaned\"\n",
    "\n",
    "start_year = 1835\n",
    "end_year = 1892\n",
    "\n",
    "dataframes = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df = pl.read_csv(f\"{csv_path}/{year}.csv\", infer_schema_length=10000)\n",
    "    dataframes.append(preprocess_df(df))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph from a .beaver file\n",
    "path_graph = \"../graph.beaver\"\n",
    "\n",
    "graph = bb.read_beaver(path_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_schema = bb.RecordSchema(\n",
    "    [\n",
    "        bb.FieldSchema(\"nom_rue\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_prenom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_nom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_origine\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"epouse_nom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_vocation\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"enfants_chez_parents_prenom\", bb.ElementType.MultiStrings),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_metric_config = bb.DistanceMetricConfig(\n",
    "    metric=\"lv_opti\",\n",
    "    caching_threshold=4,\n",
    "    use_sigmoid=False,\n",
    "    lv_substring_weight=0.5,\n",
    ")\n",
    "normal_memory_config = bb.MemoryConfig(\n",
    "    memory_strategy=\"median\",\n",
    ")\n",
    "multi_memory_config = bb.MemoryConfig(\n",
    "    memory_strategy=\"mw-median\",\n",
    "    multiword_threshold_match=0.6,\n",
    "    multiword_distance_metric=distance_metric_config,\n",
    ")\n",
    "\n",
    "config = bb.config(\n",
    "    record_schema=record_schema,\n",
    "    distance_metric_config=distance_metric_config,\n",
    "    record_scorer_config=bb.RecordScorerConfig(\n",
    "        record_scorer=\"average\",\n",
    "        weights=None,\n",
    "        min_weight_ratio=None\n",
    "    ),\n",
    "    resolver_config=bb.ResolverConfig(\n",
    "        resolving_strategy=\"best-match\",\n",
    "    ),\n",
    "    memory_config=normal_memory_config,\n",
    "    multistring_memory_config=multi_memory_config,\n",
    "    interest_threshold=0.6,\n",
    "    limit_no_match_streak=3,\n",
    "    num_threads=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = bb.deserialize_tracking_config(\n",
    "    {\n",
    "        \"num_threads\": 17,\n",
    "        \"tracker\": {\n",
    "            \"interest_threshold\": 0.79,\n",
    "            \"limit_no_match_streak\": 4,\n",
    "            \"record_scorer\": {\n",
    "                \"record_scorer\": \"weighted-average\",\n",
    "                \"weights\": [\n",
    "                    0.15,\n",
    "                    0.20,\n",
    "                    0.30,\n",
    "                    0.15,\n",
    "                    0.15,\n",
    "                    0.15,\n",
    "                    0.15,\n",
    "                ],\n",
    "                \"min_weight_ratio\": 0.7,\n",
    "            },\n",
    "            \"memories\": [\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"ls-median\",\n",
    "                    \"multiword_threshold_match\": None,\n",
    "                    \"multiword_distance_metric\": None,\n",
    "                },\n",
    "                {\n",
    "                    \"memory_strategy\": \"mw-median\",\n",
    "                    \"multiword_threshold_match\": 0.8,\n",
    "                    \"multiword_distance_metric\": {\n",
    "                        \"metric\": \"lv_substring\",\n",
    "                        \"caching_threshold\": 4,\n",
    "                        \"use_sigmoid\": False,\n",
    "                        \"lv_edit_weights\": None,\n",
    "                        \"lv_substring_weight\": 0.7,\n",
    "                        \"lv_multiword_separator\": None,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        \"distance_metric\": {\n",
    "            \"metric\": \"lv_substring\",\n",
    "            \"caching_threshold\": 4,\n",
    "            \"use_sigmoid\": False,\n",
    "            \"lv_edit_weights\": None,\n",
    "            \"lv_substring_weight\": 0.7,\n",
    "            \"lv_multiword_separator\": None,\n",
    "        },\n",
    "        \"resolver\": {\"resolving_strategy\": \"best-match\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the graph\n",
    "graph = bb.execute_tracking(config, record_schema, dataframes, \"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_histograms(histograms: list[list[int]]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Aggregates a list of histograms into a single histogram.\n",
    "    \"\"\"\n",
    "    max_len = max([len(h) for h in histograms])\n",
    "    result = [0] * max_len\n",
    "    for h in histograms:\n",
    "        for i, v in enumerate(h):\n",
    "            result[i] += v\n",
    "    return result\n",
    "\n",
    "def summary_graph(graph: bb.TrackingGraph):\n",
    "\n",
    "    # compute the sum of the histograms for all frames\n",
    "    histogram_records = aggregate_histograms([resolving.histogram_record_matchs for resolving in graph.diagnostics.resolvings])\n",
    "    # do not show beyond 10 elements as the counts are very low\n",
    "    histogram_records = histogram_records\n",
    "    histogram_trackers = aggregate_histograms([resolving.histogram_tracker_matchs for resolving in graph.diagnostics.resolvings])\n",
    "    histogram_trackers = histogram_trackers[:10]\n",
    "\n",
    "    chain_metrics = bb.evaluate_tracking_chain_length(graph._raw)\n",
    "    graph_metrics = bb.evaluate_tracking_graph_properties(graph._raw)\n",
    "        \n",
    "    records_match_ratios = graph_metrics.records_match_ratios[1:]\n",
    "    trackers_match_ratios = graph_metrics.trackers_match_ratios[1:-1]\n",
    "    avg_records_match = sum(records_match_ratios) / len(records_match_ratios)\n",
    "    avg_trackers_match = sum(trackers_match_ratios) / len(trackers_match_ratios)\n",
    "\n",
    "    per_divergence = sum(histogram_trackers[2:]) / sum(histogram_trackers[1:])\n",
    "    per_conflict = sum(histogram_records[2:]) / sum(histogram_records[1:])\n",
    "\n",
    "    print(sum(chain_metrics.histogram[2:]))\n",
    "    print(sum(chain_metrics.histogram[5:]))\n",
    "    print(sum(chain_metrics.histogram[10:]))\n",
    "    print(sum(chain_metrics.histogram[20:]))\n",
    "\n",
    "    # total number of trackers created\n",
    "    print(f\"Number of chains: {len(graph.trackers_ids)}\")\n",
    "    # average percentage of records that have been match with an existing tracker\n",
    "    print(f\"Percentage of matching records: {avg_records_match*100:.2f}%\")\n",
    "    # average percentage of trackers that have match with a record of the current frame\n",
    "    print(f\"Percentage of matching trackers: {avg_trackers_match*100:.2f}%\")\n",
    "    # number of times a tracker matched with more that one record\n",
    "    # divided by the number of times a tracker matched with a record\n",
    "    print(f\"Percentage of divergences: {per_divergence*100:.2f}%\")\n",
    "    # number of times a record matched with multiple trackers\n",
    "    # divided by the number of times a record matched with a tracker\n",
    "    print(f\"Percentage of conflicts: {per_conflict*100:.2f}%\")\n",
    "\n",
    "    plt.bar(range(1, len(chain_metrics.histogram)), chain_metrics.histogram[1:])\n",
    "    plt.title(\"Histogram of tracking chain lengths\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(range(len(histogram_records)), histogram_records)\n",
    "    plt.title(\"Histogram of # matchs per record\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.bar(range(len(histogram_trackers)), histogram_trackers)\n",
    "    plt.title(\"Histogram of # matchs per tracker\")\n",
    "    plt.show()\n",
    "    \n",
    "summary_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_graph = \"../graph.beaver\"\n",
    "\n",
    "bb.save_beaver(path_graph, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_config = bb.NormalizationConfig(\n",
    "    threshold_cluster_match=0.5,\n",
    "    min_cluster_size=2,\n",
    "    distance_metric=config.distance_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dfs = bb.execute_normalization(\n",
    "    normalization_config,\n",
    "    record_schema,\n",
    "    graph,\n",
    "    dataframes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_csv_path = \"/home/plouc314/Documents/epfl/ma2/shs/shs-ma1/data/normalized\"\n",
    "\n",
    "start_year = 1835\n",
    "end_year = 1892\n",
    "\n",
    "for year, df in zip(range(start_year, end_year + 1), normalized_dfs):\n",
    "    df = postprocess_df(df)\n",
    "    df.write_csv(f\"{normalized_csv_path}/{year}.csv\", include_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chain_with_length(graph: bb.TrackingGraph, start_idx: int, length: int) -> None:\n",
    "    idx = start_idx\n",
    "    while idx < len(graph.trackers_ids):\n",
    "        tracker_id = graph.trackers_ids[idx]\n",
    "        chain = graph._raw.get_tracking_chain(tracker_id)\n",
    "        if len(chain) >= length:\n",
    "            return tracker_id\n",
    "        idx += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = find_chain_with_length(graph, dataframes, record_schema, 0, 3)\n",
    "tracker_id = find_chain_with_length(graph, 2000, 50)\n",
    "chain = graph.materialize_tracking_chain(tracker_id, dataframes, record_schema)\n",
    "chain.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.as_dataframe(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chain.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_as_list(df: pl.DataFrame, col: str) -> list[str]:\n",
    "    return [v for v in df[col] if v is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"magimelien\",\n",
    "    \"mazimilien\",\n",
    "    \"mazirelien\",\n",
    "    \"marinelien\",\n",
    "    \"hgdfzs\",\n",
    "    \"bob\",\n",
    "    \"boob\",\n",
    "]\n",
    "bb.compute_median_word(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.compute_words_clusters(\n",
    "    words,\n",
    "    distance_metric_config,\n",
    "    threshold_match=0.6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.normalize_words(\n",
    "    get_col_as_list(df, \"nom_rue\"),\n",
    "    distance_metric_config,\n",
    "    threshold_match=0.6,\n",
    "    min_cluster_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
