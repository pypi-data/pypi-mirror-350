{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import blitzbeaver as bb\n",
    "import random\n",
    "from typing import Any\n",
    "from Levenshtein import distance\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"../../aptihramy/data/csv_cleaned\"\n",
    "beaver_folder_path = \"../data/beaver_files\"\n",
    "json_folder_path = \"../data/json_files\"\n",
    "verifier_dropped_cols = [\"frame_idx\", \"enfants_chez_parents_prenom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_35_45 = [\n",
    "    pl.read_csv(f\"{csv_path}/{year}.csv\", infer_schema_length=10000)\n",
    "    for year in range(1835, 1845 + 1)\n",
    "]\n",
    "\n",
    "dataframes_60_70 = [\n",
    "    pl.read_csv(f\"{csv_path}/{year}.csv\", infer_schema_length=10000)\n",
    "    for year in range(1860, 1870 + 1)\n",
    "]\n",
    "\n",
    "dataframes_87_97 = [\n",
    "    pl.read_csv(f\"{csv_path}/{year}.csv\", infer_schema_length=10000)\n",
    "    for year in range(1887, 1897 + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_children(dataframes: pl.DataFrame) -> pl.DataFrame:\n",
    "    for i in range(len(dataframes)):\n",
    "        df = dataframes[i]\n",
    "        dataframes[i] = df.with_columns(\n",
    "            df[\"enfants_chez_parents_prenom\"]\n",
    "            .str.split(\"|\")\n",
    "            .list.eval(pl.element().filter(pl.element() != \"\"))\n",
    "            .alias(\"enfants_chez_parents_prenom\")\n",
    "        )\n",
    "\n",
    "\n",
    "clean_children(dataframes_35_45)\n",
    "clean_children(dataframes_60_70)\n",
    "clean_children(dataframes_87_97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_schema_base = bb.RecordSchema(\n",
    "    [\n",
    "        bb.FieldSchema(\"nom_rue\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_prenom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_nom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_origine\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"epouse_nom\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_vocation\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"enfants_chez_parents_prenom\", bb.ElementType.MultiStrings),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_schema_normalized = bb.RecordSchema(\n",
    "    [\n",
    "        bb.FieldSchema(\"nom_rue_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_prenom_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_nom_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_origine_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"epouse_nom_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"chef_vocation_norm\", bb.ElementType.String),\n",
    "        bb.FieldSchema(\"enfants_chez_parents_prenom\", bb.ElementType.MultiStrings),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caching_threshold = 4\n",
    "\n",
    "lv_substring_weights = [0.6, 0.7, 0.8]\n",
    "\n",
    "distance_metric_lv_opti = bb.DistanceMetricConfig(\n",
    "    metric=\"lv_opti\",\n",
    "    caching_threshold=caching_threshold,\n",
    "    use_sigmoid=False,\n",
    ")\n",
    "\n",
    "distance_metrics = [\n",
    "    bb.DistanceMetricConfig(\n",
    "        metric=\"lv_substring\",\n",
    "        caching_threshold=caching_threshold,\n",
    "        use_sigmoid=False,\n",
    "        lv_substring_weight=w,\n",
    "    )\n",
    "    for w in lv_substring_weights\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_weight_ratios = [0.7]\n",
    "weights = [\n",
    "    [\n",
    "        0.15,\n",
    "        0.25,\n",
    "        0.30,\n",
    "        0.15,\n",
    "        0.15,\n",
    "        0.15,\n",
    "        0.15,\n",
    "    ],\n",
    "]\n",
    "\n",
    "record_scorers = [\n",
    "    bb.RecordScorerConfig(\n",
    "        record_scorer=\"weighted-average\",\n",
    "        weights=w,\n",
    "        min_weight_ratio=ratio,\n",
    "    )\n",
    "    for w in weights\n",
    "    for ratio in min_weight_ratios\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver_config = bb.ResolverConfig(\n",
    "    resolving_strategy=\"best-match\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_strategies = [\n",
    "    \"ls-median\",\n",
    "]\n",
    "memory_configs = [bb.MemoryConfig(memory_strategy=m) for m in memory_strategies]\n",
    "\n",
    "multistring_memory_config = [\n",
    "    bb.MemoryConfig(\n",
    "        memory_strategy=\"mw-median\",\n",
    "        multiword_threshold_match=0.8,\n",
    "        multiword_distance_metric=distance_metrics[1],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.79, 0.8]\n",
    "configs = [\n",
    "    bb.config(\n",
    "        record_schema=record_schema_base,\n",
    "        distance_metric_config=d,\n",
    "        record_scorer_config=r,\n",
    "        resolver_config=resolver_config,\n",
    "        memory_config=m,\n",
    "        multistring_memory_config=mm,\n",
    "        interest_threshold=t,\n",
    "        limit_no_match_streak=4,\n",
    "        num_threads=17,\n",
    "    )\n",
    "    for d in distance_metrics\n",
    "    for r in record_scorers\n",
    "    for m in memory_configs\n",
    "    for mm in multistring_memory_config\n",
    "    for t in thresholds\n",
    "]\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_distance_averages(avgs: list[list[float]], nb_features: int):\n",
    "    agg = [0] * nb_features\n",
    "\n",
    "    for avg in avgs:\n",
    "\n",
    "        for i, val in enumerate(avg):\n",
    "            agg[i] += val\n",
    "\n",
    "    return [v / len(avgs) for v in agg]\n",
    "\n",
    "\n",
    "def avg_distance_metrics(\n",
    "    graph: bb.TrackingGraph,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    record_schema: bb.RecordSchema,\n",
    "    id: bb.ID,\n",
    ") -> list[float] | None:\n",
    "    \"\"\"\n",
    "    Computes the average distance per feature (column) across matching records in a tracker chain.\n",
    "\n",
    "    For each frame in the tracker diagnostics, it identifies the record matching the materialized\n",
    "    tracking chain and computes the average of the distance metrics per feature.\n",
    "\n",
    "    Args:\n",
    "        graph (bb.TrackingGraph): The tracking graph containing diagnostics.\n",
    "        dataframes (list[pl.DataFrame]): List of Polars DataFrames used for materialization.\n",
    "        record_schema (RecordSchema): The schema defining the order and number of features.\n",
    "        id (ID): The tracker ID whose chain should be processed.\n",
    "\n",
    "    Returns:\n",
    "        list[float] | None: A list of average distances per feature. Returns None if the tracker\n",
    "        doesn't exist or has no matching frames.\n",
    "    \"\"\"\n",
    "    nb_features = len(record_schema.fields)\n",
    "    tracker_diag = graph.diagnostics.get_tracker(id)\n",
    "\n",
    "    if tracker_diag is None:\n",
    "        return None\n",
    "\n",
    "    materialized = graph.materialize_tracking_chain(id, dataframes, record_schema, None)\n",
    "\n",
    "    avg = [0] * nb_features\n",
    "    counts = [0] * nb_features\n",
    "\n",
    "    # Map each frame index to the corresponding record index (excluding the first frame)\n",
    "    frame_to_record = {\n",
    "        m.frame_idx: m.record_idx for m in materialized.matched_frames[1:]\n",
    "    }\n",
    "\n",
    "    if len(frame_to_record) == 0:\n",
    "        return None\n",
    "\n",
    "    for frame in tracker_diag.frames:\n",
    "        record_idx = frame_to_record.get(frame.frame_idx)\n",
    "        if record_idx is None:\n",
    "            continue\n",
    "\n",
    "        for record in frame.records:\n",
    "            if record.record_idx != record_idx:\n",
    "                continue\n",
    "\n",
    "            for i, distance in enumerate(record.distances):\n",
    "                if distance is not None:\n",
    "                    avg[i] += distance\n",
    "                    counts[i] += 1\n",
    "            break\n",
    "\n",
    "    # Compute average for each feature\n",
    "    ret = []\n",
    "    for i, v in enumerate(avg):\n",
    "        count = counts[i]\n",
    "        if count == 0:\n",
    "            count = 1\n",
    "        ret.append(v / count)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def print_column_scores(\n",
    "    graph: bb.TrackingGraph, dataframes: list[pl.DataFrame], record_schema: bb.RecordSchema\n",
    "):\n",
    "    print(\"Column scores:\")\n",
    "    avgs = [\n",
    "        avg_distance_metrics(graph, dataframes, record_schema, id)\n",
    "        for id in graph.trackers_ids\n",
    "    ]\n",
    "\n",
    "    agg_avgs = aggregate_distance_averages(\n",
    "        [a for a in avgs if a is not None], len(record_schema.fields)\n",
    "    )\n",
    "    zipped = list(zip(record_schema.fields, agg_avgs))\n",
    "    for schema, avg in zipped:\n",
    "        print(f\"{schema.name}: {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chain_with_length(\n",
    "    graph: bb.TrackingGraph, start_idx: int, length: int\n",
    ") -> None | int:\n",
    "    idx = start_idx\n",
    "    while idx < len(graph.trackers_ids):\n",
    "        tracker_id = graph.trackers_ids[idx]\n",
    "        chain = graph._raw.get_tracking_chain(tracker_id)\n",
    "        if len(chain) >= length:\n",
    "            return tracker_id\n",
    "        idx += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def take_n_random_ids(n: int, graph: bb.TrackingGraph, min_length: int) -> list[int]:\n",
    "    # Filter only tracker IDs with chain length >= min_length\n",
    "    valid_ids = [\n",
    "        tracker_id\n",
    "        for tracker_id in graph.trackers_ids\n",
    "        if len(graph._raw.get_tracking_chain(tracker_id)) >= min_length\n",
    "    ]\n",
    "\n",
    "    # Adjust n if there are fewer valid IDs than requested\n",
    "    n = min(n, len(valid_ids))\n",
    "\n",
    "    return random.sample(valid_ids, n)\n",
    "\n",
    "\n",
    "def print_verify_df(chain: bb.MaterializedTrackingChain):\n",
    "    values, columns = verify_columns_of_chain(chain)\n",
    "    for i, v in enumerate(values):\n",
    "        print(f\"{columns[i]}: {v}\")\n",
    "\n",
    "\n",
    "def verify_columns_of_chain(\n",
    "    chain: bb.MaterializedTrackingChain,\n",
    ") -> tuple[list[float], list[str]]:\n",
    "    df = chain.as_dataframe().drop(verifier_dropped_cols)\n",
    "\n",
    "    results = []\n",
    "    for col in df.columns:\n",
    "        results.append(verify_column(df[col].to_list()))\n",
    "\n",
    "    return results, df.columns\n",
    "\n",
    "\n",
    "def print_aggregate_verifiers(\n",
    "    agg_values: list[float], fields: list[str]\n",
    ") -> list[float]:\n",
    "    print(\"Aggregated verifiers:\")\n",
    "    for i, r in enumerate(agg_values):\n",
    "        print(f\"{fields[i]}: {r}\")\n",
    "\n",
    "\n",
    "def aggregate_column_verifiers(l: list[list[float]]) -> list[float]:\n",
    "    results = [0] * len(l[0])\n",
    "    for values in l:\n",
    "        for i, v in enumerate(values):\n",
    "            results[i] += v\n",
    "\n",
    "    return [v / len(l) for v in results]\n",
    "\n",
    "\n",
    "def verify_column(l: list[str | None]) -> float:\n",
    "    ratio = 0\n",
    "    count = 0\n",
    "\n",
    "    for i, value in enumerate(l[:-1]):\n",
    "        next = l[i + 1]\n",
    "        if value is None:\n",
    "            value = \"\"\n",
    "        if next is None:\n",
    "            next = \"\"\n",
    "        max_len = max(len(value), len(next))\n",
    "        if max_len == 0:\n",
    "            continue\n",
    "        ratio += 1 - distance(value, next) / max_len\n",
    "        count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        return 0.0\n",
    "    return ratio / count\n",
    "\n",
    "\n",
    "def verify_n_samples(\n",
    "    tracking_graph: bb.TrackingGraph,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    schema: bb.RecordSchema,\n",
    "    nb_samples: int,\n",
    "    min_length: int,\n",
    ") -> list[float]:\n",
    "    ids = take_n_random_ids(nb_samples, tracking_graph, min_length)\n",
    "    a = []\n",
    "\n",
    "    for id in ids:\n",
    "        chain = tracking_graph.materialize_tracking_chain(\n",
    "            id, dataframes, schema, normalized_dataframes=None\n",
    "        )\n",
    "        values, _ = verify_columns_of_chain(chain)\n",
    "        a.append(values)\n",
    "\n",
    "    return aggregate_column_verifiers(a)\n",
    "\n",
    "\n",
    "def print_verify_n_samples(\n",
    "    tracking_graph: bb.TrackingGraph,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    schema: bb.RecordSchema,\n",
    "    nb_samples: int,\n",
    "    min_length: int,\n",
    "):\n",
    "    r = verify_n_samples(tracking_graph, dataframes, schema, nb_samples, min_length)\n",
    "    fields = [f.name for f in schema.fields if f.name not in verifier_dropped_cols]\n",
    "    print_aggregate_verifiers(r, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_histograms(histograms: list[list[int]]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Aggregates a list of histograms into a single histogram.\n",
    "    \"\"\"\n",
    "    max_len = max([len(h) for h in histograms])\n",
    "    result = [0] * max_len\n",
    "    for h in histograms:\n",
    "        for i, v in enumerate(h):\n",
    "            result[i] += v\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_start_end_years(\n",
    "    graph: bb.TrackingGraph,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    record_schema: bb.RecordSchema,\n",
    "    nb_of_years: int,\n",
    ") -> tuple[list[int], list[int]]:\n",
    "\n",
    "    start_years = [0] * nb_of_years\n",
    "    end_years = [0] * nb_of_years\n",
    "    for id in graph.trackers_ids:\n",
    "        materialized = graph.materialize_tracking_chain(id, dataframes, record_schema)\n",
    "        start_years[materialized.matched_frames[0].frame_idx] += 1\n",
    "        end_years[materialized.matched_frames[-1].frame_idx] += 1\n",
    "\n",
    "    return start_years, end_years\n",
    "\n",
    "\n",
    "def get_avg_record_tracker_match(graph: bb.TrackingGraph):\n",
    "    graph_metrics = bb.evaluate_tracking_graph_properties(graph._raw)\n",
    "\n",
    "    records_match_ratios = graph_metrics.records_match_ratios[1:]\n",
    "    trackers_match_ratios = graph_metrics.trackers_match_ratios[1:-1]\n",
    "\n",
    "    avg_records_match = sum(records_match_ratios) / len(records_match_ratios)\n",
    "    avg_trackers_match = sum(trackers_match_ratios) / len(trackers_match_ratios)\n",
    "\n",
    "    return avg_records_match, avg_trackers_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def compute_and_save_beaver(\n",
    "    config: bb.TrackingConfig,\n",
    "    record_schema: bb.RecordSchema,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    filepath: str,\n",
    ") -> bb.TrackingGraph:\n",
    "    path_graph = f\"{beaver_folder_path}/{filepath}\"\n",
    "    graph = bb.execute_tracking(config, record_schema, dataframes, \"debug\")\n",
    "    bb.save_beaver(path_graph, graph)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def save_json(filepath: str, d: dict[str, Any]):\n",
    "    path_json = f\"{json_folder_path}/{filepath}\"\n",
    "    with open(path_json, \"w\") as f:\n",
    "        json.dump(d, f, indent=2)\n",
    "\n",
    "\n",
    "def build_tracking_summary(\n",
    "    config: bb.TrackingConfig,\n",
    "    record_schema: bb.RecordSchema,\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    nb_samples: int,\n",
    "    min_length: int,\n",
    "    nb_of_years: int,\n",
    ") -> dict[str, Any]:\n",
    "\n",
    "    all_dict = {}\n",
    "\n",
    "    all_dict[\"config\"] = bb.serialize_tracking_config(config)\n",
    "    graph = bb.execute_tracking(config, record_schema, dataframes, \"info\")\n",
    "    \n",
    "    r = verify_n_samples(graph, dataframes, record_schema, nb_samples, min_length)\n",
    "    all_fields_names = [f.name for f in record_schema.fields]\n",
    "    filtered_fields = [\n",
    "        f_name for f_name in all_fields_names if f_name not in verifier_dropped_cols\n",
    "    ]\n",
    "\n",
    "    data_dict = {}\n",
    "    data_dict[\"verifier\"] = dict(zip(filtered_fields, r))\n",
    "\n",
    "    avgs = [\n",
    "        avg_distance_metrics(graph, dataframes, record_schema, id)\n",
    "        for id in graph.trackers_ids\n",
    "    ]\n",
    "\n",
    "    agg_avgs = aggregate_distance_averages(\n",
    "        [a for a in avgs if a is not None], len(all_fields_names)\n",
    "    )\n",
    "\n",
    "    data_dict[\"memory_distance\"] = dict(zip(all_fields_names, agg_avgs))\n",
    "\n",
    "    chain_metrics = bb.evaluate_tracking_chain_length(graph._raw)\n",
    "    start_years, end_years = get_start_end_years(\n",
    "        graph, dataframes, record_schema, nb_of_years\n",
    "    )\n",
    "\n",
    "    data_dict[\"start_years\"] = start_years\n",
    "    data_dict[\"end_years\"] = end_years\n",
    "    data_dict[\"chain_lengths\"] = chain_metrics.histogram\n",
    "\n",
    "    avg_records_match, avg_trackers_match = get_avg_record_tracker_match(graph)\n",
    "    data_dict[\"avg_records_match\"] = avg_records_match\n",
    "    data_dict[\"avg_trackers_match\"] = avg_trackers_match\n",
    "\n",
    "    histogram_records = aggregate_histograms(\n",
    "        [\n",
    "            resolving.histogram_record_matchs\n",
    "            for resolving in graph.diagnostics.resolvings\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    histogram_trackers = aggregate_histograms(\n",
    "        [\n",
    "            resolving.histogram_tracker_matchs\n",
    "            for resolving in graph.diagnostics.resolvings\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data_dict[\"histogram_records\"] = histogram_records\n",
    "    data_dict[\"histogram_trackers\"] = histogram_trackers\n",
    "\n",
    "    all_dict[\"data\"] = data_dict\n",
    "    return all_dict\n",
    "\n",
    "\n",
    "def compute_for_all_configs(\n",
    "    configs: list[bb.TrackingConfig],\n",
    "    dataframes: list[pl.DataFrame],\n",
    "    record_schema: bb.RecordSchema,\n",
    "    nb_samples: int,\n",
    "    min_length: int,\n",
    "    filepath: str,\n",
    "    step_before_save: int,\n",
    "):\n",
    "    all_dicts: list[dict, Any] = []\n",
    "    count = 1\n",
    "    for i, config in enumerate(configs):\n",
    "        print(\"execute config\", i)\n",
    "        all_dicts.append(\n",
    "            build_tracking_summary(\n",
    "                config, record_schema, dataframes, nb_samples, min_length, len(dataframes)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if len(all_dicts) >= step_before_save:\n",
    "            save_json(f\"{filepath}_{count}.json\", all_dicts)\n",
    "            all_dicts = []\n",
    "            count += 1\n",
    "      \n",
    "        gc.collect()\n",
    "\n",
    "    if len(all_dicts) > 0:\n",
    "        save_json(f\"{filepath}_{count}.json\", all_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"configs_p7\"\n",
    "configs = configs[:]\n",
    "compute_for_all_configs(\n",
    "    configs=configs,\n",
    "    dataframes=dataframes_35_45,\n",
    "    record_schema=record_schema_base,\n",
    "    nb_samples=1,\n",
    "    min_length=7,\n",
    "    filepath=filename,\n",
    "    step_before_save=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_results_files(filenames: list[str], out_filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Merges multiple JSON files into a single JSON file.\n",
    "\n",
    "    Args:\n",
    "        filenames (list[str]): List of input JSON filenames to merge.\n",
    "        out_filename (str): Output filename for the merged JSON file.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for filename in filenames:\n",
    "        filepath = f\"{json_folder_path}/{filename}\"\n",
    "        with open(filepath, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            all_data.extend(data)\n",
    "\n",
    "    filepath = f\"{json_folder_path}/{out_filename}\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(all_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_results_files(\n",
    "#     [\n",
    "#         \"configs_p6.json\",\n",
    "#         \"configs_p7.json\",\n",
    "\n",
    "#     ],\n",
    "#     \"configs_p8.json\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
