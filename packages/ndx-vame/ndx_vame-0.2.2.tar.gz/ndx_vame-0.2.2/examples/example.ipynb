{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This example notebook demonstrates how to write VAME results to an NWB file, using the [ndx-vame](https://github.com/catalystneuro/ndx-vame) extension.\n",
    "\n",
    "It will also include:\n",
    "- [Subject](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.Subject) metadata\n",
    "- [PoseEstimation](https://github.com/rly/ndx-pose) data\n",
    "\n",
    "Let's start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "from pynwb import NWBFile, NWBHDF5IO\n",
    "from pynwb.file import Subject\n",
    "from ndx_pose import PoseEstimationSeries, PoseEstimation\n",
    "from ndx_vame import VAMEProject, LatentSpaceSeries, MotifSeries, CommunitySeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the NWB file object containing basic metadata and pose estimation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an NWBFile object\n",
    "nwbfile = NWBFile(\n",
    "    session_description=\"session_description\",\n",
    "    identifier=\"identifier\",\n",
    "    session_start_time=datetime.datetime.now(datetime.timezone.utc),\n",
    ")\n",
    "\n",
    "# add a subject to the NWB file\n",
    "subject = Subject(subject_id=\"subject1\", species=\"Mus musculus\")\n",
    "nwbfile.subject = subject\n",
    "\n",
    "# create a device for the camera\n",
    "camera1 = nwbfile.create_device(\n",
    "    name=\"camera1\",\n",
    "    description=\"camera for recording behavior\",\n",
    "    manufacturer=\"manufacturer\",\n",
    ")\n",
    "\n",
    "# a PoseEstimationSeries represents the estimated position of a single marker.\n",
    "# in this example, we have three PoseEstimationSeries: one for the body and one for each front paw.\n",
    "data = np.random.rand(100, 2)  # num_frames x (x, y) but can be (x, y, z)\n",
    "confidence = np.random.rand(100)  # a confidence value for every frame\n",
    "reference_frame = \"(0,0,0) corresponds to ...\"\n",
    "front_left_paw = PoseEstimationSeries(\n",
    "    name=\"front_left_paw\",\n",
    "    description=\"Marker placed around fingers of front left paw.\",\n",
    "    data=data,\n",
    "    unit=\"pixels\",\n",
    "    rate=10.,\n",
    "    reference_frame=reference_frame,\n",
    "    confidence=confidence,\n",
    ")\n",
    "\n",
    "data = np.random.rand(100, 2)  # num_frames x (x, y) but can be (x, y, z)\n",
    "confidence = np.random.rand(100)  # a confidence value for every frame\n",
    "body = PoseEstimationSeries(\n",
    "    name=\"body\",\n",
    "    description=\"Marker placed on center of body.\",\n",
    "    data=data,\n",
    "    unit=\"pixels\",\n",
    "    rate=10.,\n",
    "    reference_frame=reference_frame,\n",
    "    confidence=confidence,\n",
    ")\n",
    "\n",
    "data = np.random.rand(100, 2)  # num_frames x (x, y) but can be num_frames x (x, y, z)\n",
    "confidence = np.random.rand(100)  # a confidence value for every frame\n",
    "front_right_paw = PoseEstimationSeries(\n",
    "    name=\"front_right_paw\",\n",
    "    description=\"Marker placed around fingers of front right paw.\",\n",
    "    data=data,\n",
    "    unit=\"pixels\",\n",
    "    rate=10.,\n",
    "    reference_frame=reference_frame,\n",
    "    confidence=confidence,\n",
    ")\n",
    "\n",
    "# create a PoseEstimation object\n",
    "pose_estimation = PoseEstimation(\n",
    "    name=\"PoseEstimation\",\n",
    "    pose_estimation_series=[front_left_paw, body, front_right_paw],\n",
    "    description=\"Estimated positions of front paws of subject1 using DeepLabCut.\",\n",
    "    original_videos=[\"path/to/camera1.mp4\"],\n",
    "    dimensions=np.array([[640, 480]], dtype=\"uint16\"),  # pixel dimensions of the video\n",
    "    devices=[camera1],\n",
    "    scorer=\"DLC_resnet50_openfieldOct30shuffle1_1600\",\n",
    "    source_software=\"DeepLabCut\",\n",
    "    source_software_version=\"2.3.8\",\n",
    ")\n",
    "\n",
    "# create a \"behavior\" processing module to store the PoseEstimation and Skeletons objects\n",
    "behavior_pm = nwbfile.create_processing_module(\n",
    "    name=\"behavior\",\n",
    "    description=\"processed behavioral data\",\n",
    ")\n",
    "behavior_pm.add(pose_estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can include VAME-related data to the NWB file:\n",
    "\n",
    "- Latent space data\n",
    "- Motifs data\n",
    "- Communities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAME data\n",
    "latent_data = np.random.rand(100, 30)  # (n_samples, z_dims)\n",
    "data_motifs = np.random.randint(0, 15, size=100)  # (n_samples)\n",
    "data_communities = np.random.randint(0, 3, size=100)  # (n_samples)\n",
    "\n",
    "latent_space_series = LatentSpaceSeries(\n",
    "    name=\"LatentSpaceSeries\",\n",
    "    data=latent_data,\n",
    "    rate=10.,\n",
    ")\n",
    "\n",
    "motif_series = MotifSeries(\n",
    "    name=\"MotifSeries\",\n",
    "    data=data_motifs,\n",
    "    rate=10.,\n",
    "    algorithm=\"hmm\",\n",
    "    latent_space_series=latent_space_series,\n",
    ")\n",
    "community_series = CommunitySeries(\n",
    "    name=\"CommunitySeries\",\n",
    "    data=data_communities,\n",
    "    rate=10.,\n",
    "    algorithm=\"hierarchical_clustering\",\n",
    "    motif_series=motif_series,\n",
    ")\n",
    "\n",
    "config_dict = {}  # Configuration dictionary from VAME project\n",
    "vame_project = VAMEProject(\n",
    "    name=\"VAMEProject\",\n",
    "    pose_estimation=pose_estimation,\n",
    "    latent_space_series=latent_space_series,\n",
    "    motif_series=motif_series,\n",
    "    community_series=community_series,\n",
    "    vame_config=json.dumps(config_dict),\n",
    ")\n",
    "\n",
    "behavior_pm.add(vame_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the NWBFile to disk\n",
    "path = \"test_vame.nwb\"\n",
    "with NWBHDF5IO(path, mode=\"w\") as io:\n",
    "    io.write(nwbfile)\n",
    "\n",
    "# read the NWBFile from disk\n",
    "io = NWBHDF5IO(path, mode=\"r\")\n",
    "nwbfile = io.read()\n",
    "print(nwbfile.processing[\"behavior\"][\"VAMEProject\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vame-desktop",
   "language": "python",
   "name": "vame-desktop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
