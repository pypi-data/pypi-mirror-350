# Command runner for autodoc_ai

# Default recipe
default:
    @just --list

# Install project
install:
    uv venv
    uv pip install .
    brew install aicommit

# Development install
dev:
    uv venv
    uv pip install -e ".[dev]"

# Run linter and formatter
check:
    ruff check --fix .
    ruff format .

# Run tests with coverage
test: check
    coverage run -m pytest
    coverage report
    coverage html

# Clean build artifacts
clean:
    rm -rf dist build *.egg-info .pytest_cache .mypy_cache .ruff_cache htmlcov
    find . -type d -name "__pycache__" -exec rm -rf {} +

# Commit with AI (without push)
cm:
    git add .
    @if git diff --cached --quiet; then echo "No changes to commit"; else just enrich && aicommit; fi

# Commit with AI and push
cmp:
    just cm
    git push

# Build packages
build: clean
    uv build

# Deploy to PyPI
deploy: build
    uv publish
    git tag -a v$(just version) -m "Release v$(just version)"
    git push origin v$(just version)
    gh release create v$(just version) --title "v$(just version)" --notes "Release v$(just version)" ./dist/*

# Get current version
version:
    @grep -m1 'version = ' pyproject.toml | cut -d'"' -f2

# Enrich README and Wiki with AI
enrich:
    #!/usr/bin/env python3
    import sys
    from autodoc_ai.crews.pipeline import PipelineCrew
    crew = PipelineCrew()
    result = crew.run()
    if not result.get("success"):
        print(f"Enrichment failed: {result.get('error', 'Unknown error')}", file=sys.stderr)
        sys.exit(1)

# Generate summary of changes
summary:
    python -c "from autodoc_ai.crews.pipeline import PipelineCrew; crew = PipelineCrew(); print(crew.generate_summary())"

# Evaluate document quality
eval path:
    python -c "from autodoc_ai.crews.evaluation import EvaluationCrew; crew = EvaluationCrew(); _, report = crew.run('{{path}}'); print(report)"

# Evaluate document with extra criteria
eval-with-prompt path prompt:
    python -c "from autodoc_ai.crews.evaluation import EvaluationCrew; crew = EvaluationCrew(); _, report = crew.run('{{path}}', extra_criteria='{{prompt}}'); print(report)"

# Evaluate all documents in directory
eval-all path:
    #!/usr/bin/env python3
    from pathlib import Path
    from autodoc_ai.crews.evaluation import EvaluationCrew
    crew = EvaluationCrew()
    results = {}
    for file_path in Path("{{path}}").glob("**/*.md"):
        if file_path.is_file():
            score, _ = crew.run(str(file_path))
            results[file_path.name] = score
    for filename, score in sorted(results.items(), key=lambda x: x[1], reverse=True):
        print(f"{filename}: {score}")
    print(f"\nEvaluated {len(results)} documents")

# Improve document iteratively
improve path:
    python -c "from autodoc_ai.crews.improvement import ImprovementCrew; import json; crew = ImprovementCrew(); print(json.dumps(crew.run('{{path}}'), indent=2))"

# Improve document with custom settings
improve-with-settings path target_score="85" max_iterations="3":
    python -c "from autodoc_ai.crews.improvement import ImprovementCrew; import json; crew = ImprovementCrew(target_score={{target_score}}, max_iterations={{max_iterations}}); print(json.dumps(crew.run('{{path}}'), indent=2))"

# Improve all documents in directory
improve-all path:
    #!/usr/bin/env python3
    from pathlib import Path
    from autodoc_ai.crews.improvement import ImprovementCrew
    crew = ImprovementCrew()
    for file_path in Path("{{path}}").glob("**/*.md"):
        if file_path.is_file():
            print(f"\n{'='*60}")
            print(f"Processing: {file_path.name}")
            print('='*60)
            result = crew.run(str(file_path))
            if "error" in result:
                print(f"‚ùå Error: {result['error']}")
            else:
                print(f"‚úÖ Improved from {result['initial_score']}% to {result['final_score']}%")
                print(f"   Iterations: {result['iterations']}")
                print(f"   Target reached: {'Yes' if result['target_reached'] else 'No'}")

# Deploy wiki to GitHub
deploy-wiki:
    python3 deploy_wiki.py

# Enrich documentation based on last commit only
enrich-commit:
    #!/usr/bin/env python3
    import sys
    import subprocess
    from autodoc_ai.crews.pipeline import PipelineCrew
    from autodoc_ai import logger
    
    # Check if there's at least one commit
    try:
        subprocess.check_output(["git", "rev-parse", "HEAD"], text=True)
    except subprocess.CalledProcessError:
        print("‚ùå No commits found in repository")
        sys.exit(1)
    
    # Get the last commit info
    last_commit_hash = subprocess.check_output(["git", "rev-parse", "HEAD"], text=True).strip()
    last_commit_info = subprocess.check_output(["git", "log", "-1", "--oneline"], text=True).strip()
    print(f"üìù Processing single commit: {last_commit_info}")
    
    # Get the diff for just the last commit
    try:
        # Check if this is the first commit
        subprocess.check_output(["git", "rev-parse", "HEAD~1"], text=True)
        # Not the first commit, get diff from parent
        diff = subprocess.check_output(["git", "diff", "HEAD~1", "HEAD", "-U1"], text=True)
    except subprocess.CalledProcessError:
        # This is the first commit, get diff from empty tree
        diff = subprocess.check_output(["git", "diff", "4b825dc642cb6eb9a060e54bf8d69288fbee4904", "HEAD", "-U1"], text=True)
    
    print(f"üìä Git diff length: {len(diff)} characters")
    
    if not diff:
        print("‚úÖ No changes in the last commit")
        sys.exit(0)
    
    # Create pipeline and process with the specific diff
    crew = PipelineCrew()
    # Directly call the internal methods to process this specific diff
    ctx = crew._create_context()
    
    logger.info(f"üìè Your changes are {len(diff):,} characters long!")
    logger.info(f"üî¢ That's about {crew._count_tokens(diff):,} tokens for the AI to read.")
    
    # Process documents with this specific diff
    logger.info("üìù Processing documents...")
    result_data = crew._process_documents(diff, ctx)
    
    # Write outputs
    crew._write_outputs(result_data["suggestions"], ctx)
    
    logger.info("‚úÖ Pipeline complete!")
    print(f"‚úÖ Documentation enriched based on single commit: {last_commit_info}")

# Enrich documentation based on commits from last n days
enrich-days days="7":
    #!/usr/bin/env python3
    import sys
    from autodoc_ai.crews.pipeline import PipelineCrew
    crew = PipelineCrew()
    result = crew.run(days={{days}})
    if not result.get("success"):
        print(f"Enrichment failed: {result.get('error', 'Unknown error')}", file=sys.stderr)
        sys.exit(1)
    else:
        print(f"‚úÖ Documentation enriched based on {{days}} days of commits")

# Update documentation for a release (based on commits since last tag)
enrich-release:
    #!/usr/bin/env python3
    import subprocess
    import sys
    from autodoc_ai.crews.pipeline import PipelineCrew

    # Get the last tag
    try:
        last_tag = subprocess.check_output(["git", "describe", "--tags", "--abbrev=0"], text=True).strip()
        # Count days since last tag
        tag_date = subprocess.check_output(["git", "log", "-1", "--format=%ci", last_tag], text=True).strip()
        days_since = subprocess.check_output(["git", "log", "-1", "--format=%cr", last_tag], text=True).strip()
        print(f"üìå Last tag: {last_tag} ({days_since})")

        # Get commits since last tag
        commits = subprocess.check_output(["git", "log", f"{last_tag}..HEAD", "--oneline"], text=True).strip()
        if not commits:
            print("‚úÖ No new commits since last release")
            sys.exit(0)

        print(f"üìù Commits since {last_tag}:")
        print(commits)
        print()

        # Create diff from last tag to HEAD
        crew = PipelineCrew()
        # Use a large number of days to ensure we capture all changes
        result = crew.run(days=365)
        if not result.get("success"):
            print(f"Enrichment failed: {result.get('error', 'Unknown error')}", file=sys.stderr)
            sys.exit(1)
        else:
            print(f"‚úÖ Documentation enriched for release")
    except subprocess.CalledProcessError:
        print("‚ùå No tags found in repository")
        sys.exit(1)
