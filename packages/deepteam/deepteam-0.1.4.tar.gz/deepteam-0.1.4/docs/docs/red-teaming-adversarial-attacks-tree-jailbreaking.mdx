---
id: red-teaming-adversarial-attacks-tree-jailbreaking
title: Tree Jailbreaking
sidebar_label: Tree Jailbreaking
---

import AttackTagsDisplayer from "@site/src/components/AttackTagsDisplayer";

<AttackTagsDisplayer multiTurn={true} llmSimulated={true} />

Tree Jailbreaking explores **multiple paths simultaneously**, with each branch representing a different variation of the attack. This method generates multiple child nodes from the initial attack, testing different scenarios that might bypass the model’s safety constraints. The branches are expanded based on success, and those that perform poorly are pruned, meaning they are discarded to focus on the more successful attack variations. The process continues to iterate, refining and expanding on the most promising paths.

<div
  style={{
    display: "flex",
    alignItems: "center",
    justifyContent: "center",
  }}
>
  <img
    src="https://confident-bucket.s3.amazonaws.com/attack_enhancements_jailbreaking_tree.svg"
    alt="LangChain"
    style={{
      marginTop: "20px",
      marginBottom: "40px",
      height: "auto",
      maxHeight: "700px",
    }}
  />
</div>

:::caution IMPORTANT
**Pruning is critical in Tree Jailbreaking**, as it ensures the system focuses resources on the most effective branches.
:::

The search continues until the most successful path is found within the specified time limit. Tree Jailbreaking is particularly powerful because it allows for a broad exploration of possible attack variations, making it more likely to find a successful path to bypass the model's defenses. However, the method’s efficiency relies on effective pruning and scoring of the branches to avoid wasting time on less promising options.

## Usage

_to be documented..._

## Example

_to be documented..._
