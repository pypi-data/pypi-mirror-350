"""Otherwise known as *chat completions*. See the [`litellm` documention](https://docs.litellm.ai/docs/completion)."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../pts/api/llm/06_completions.pct.py.

# %% auto 0
__all__ = ['completion', 'async_completion', 'sig', 'prompt', 'async_prompt']

# %% ../../../pts/api/llm/06_completions.pct.py 3
try:
    import litellm
    import inspect
    import functools
    from typing import List
    from adulib.llm._utils import _llm_func_factory, _llm_async_func_factory
    from adulib.llm.tokens import token_counter
except ImportError as e:
    raise ImportError(f"Install adulib[llm] to use this API.") from e

# %% ../../../pts/api/llm/06_completions.pct.py 8
completion = _llm_func_factory(
    func=litellm.completion,
    func_name="completion",
    func_cache_name="completion",
    retrieve_log_data=lambda model, func_kwargs, response: {
        "method": "completion",
        "input_tokens": token_counter(model=model, messages=func_kwargs['messages']),
        "output_tokens": sum([token_counter(model=model, messages=[{'role': c.message.role, 'content': c.message.content}]) for c in response.choices]),
        "cost": response._hidden_params['response_cost'],
    }
)

completion.__doc__ = """
This function is a wrapper around a corresponding function in the `litellm` library, see [this](https://docs.litellm.ai/docs/completion/input) for a full list of the available arguments.
""".strip()

# %% ../../../pts/api/llm/06_completions.pct.py 14
async_completion = _llm_async_func_factory(
    func=litellm.acompletion,
    func_name="async_completion",
    func_cache_name="completion",
    retrieve_log_data=lambda model, func_kwargs, response: {
        "method": "completion",
        "input_tokens": token_counter(model=model, messages=func_kwargs['messages']),
        "output_tokens": sum([token_counter(model=model, messages=[{'role': c.message.role, 'content': c.message.content}]) for c in response.choices]),
        "cost": response._hidden_params['response_cost'],
    }
)

completion.__doc__ = """
This function is a wrapper around a corresponding function in the `litellm` library, see [this](https://docs.litellm.ai/docs/completion/input) for a full list of the available arguments.
""".strip()

# %% ../../../pts/api/llm/06_completions.pct.py 17
@functools.wraps(completion)
def prompt(
    model: str,
    context: str,
    prompt: str,
    *args,
    return_full_response: bool=False,
    **kwargs,
):
    messages = [
        {"role": "system", "content": context},
        {"role": "user", "content": prompt}
    ]
    response = completion(model, messages, *args, **kwargs)
    if return_full_response: return response
    else: return response.choices[0].message.content
    
sig = inspect.signature(completion)
prompt.__signature__ = sig.replace(parameters=[p for p in sig.parameters.values() if p.name != 'messages'])
prompt.__name__ = "prompt"
prompt.__doc__ = """
Simplified chat completions designed for single-turn tasks like classification, summarization, or extraction. For a full list of the available arguments see the [documentation](https://docs.litellm.ai/docs/completion/input) for the `completion` function in `litellm`.
""".strip()

# %% ../../../pts/api/llm/06_completions.pct.py 21
@functools.wraps(completion)
async def async_prompt(
    model: str,
    context: str,
    prompt: str,
    *args,
    return_full_response: bool=False,
    **kwargs,
):
    messages = [
        {"role": "system", "content": context},
        {"role": "user", "content": prompt}
    ]
    response = await async_completion(model, messages, *args, **kwargs)
    if return_full_response: return response
    else: return response.choices[0].message.content
    
sig = inspect.signature(completion)
async_prompt.__signature__ = sig.replace(parameters=[p for p in sig.parameters.values() if p.name != 'messages'])
async_prompt.__name__ = "async_prompt"
async_prompt.__doc__ = """
Simplified chat completions designed for single-turn tasks like classification, summarization, or extraction. For a full list of the available arguments see the [documentation](https://docs.litellm.ai/docs/completion/input) for the `completion` function in `litellm`.
""".strip()
