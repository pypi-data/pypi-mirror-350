"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""

import builtins
import collections.abc
from . import common_pb2
from . import datasource_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
from . import spikesorter_pb2
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _TrainPhase:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _TrainPhaseEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_TrainPhase.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    TRAIN_PHASE_0: _TrainPhase.ValueType  # 0
    TRAIN_PHASE_1: _TrainPhase.ValueType  # 1
    TRAIN_PHASE_2: _TrainPhase.ValueType  # 2
    TRAIN_PHASE_3: _TrainPhase.ValueType  # 3

class TrainPhase(_TrainPhase, metaclass=_TrainPhaseEnumTypeWrapper): ...

TRAIN_PHASE_0: TrainPhase.ValueType  # 0
TRAIN_PHASE_1: TrainPhase.ValueType  # 1
TRAIN_PHASE_2: TrainPhase.ValueType  # 2
TRAIN_PHASE_3: TrainPhase.ValueType  # 3
global___TrainPhase = TrainPhase

class _LossType:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _LossTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_LossType.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    LOSS_TYPE_MSE: _LossType.ValueType  # 0
    LOSS_TYPE_WMSE: _LossType.ValueType  # 1
    LOSS_TYPE_CROSS_ENTROPY: _LossType.ValueType  # 2

class LossType(_LossType, metaclass=_LossTypeEnumTypeWrapper): ...

LOSS_TYPE_MSE: LossType.ValueType  # 0
LOSS_TYPE_WMSE: LossType.ValueType  # 1
LOSS_TYPE_CROSS_ENTROPY: LossType.ValueType  # 2
global___LossType = LossType

class _SpkSortTrainerNetworkSize:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _SpkSortTrainerNetworkSizeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SpkSortTrainerNetworkSize.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    SST_SIZE_DEFAULT: _SpkSortTrainerNetworkSize.ValueType  # 0
    SST_SIZE_ARB: _SpkSortTrainerNetworkSize.ValueType  # 1
    SST_SIZE_SMALL: _SpkSortTrainerNetworkSize.ValueType  # 2
    SST_SIZE_NOMINAL: _SpkSortTrainerNetworkSize.ValueType  # 3
    SST_SIZE_LARGE: _SpkSortTrainerNetworkSize.ValueType  # 4

class SpkSortTrainerNetworkSize(_SpkSortTrainerNetworkSize, metaclass=_SpkSortTrainerNetworkSizeEnumTypeWrapper): ...

SST_SIZE_DEFAULT: SpkSortTrainerNetworkSize.ValueType  # 0
SST_SIZE_ARB: SpkSortTrainerNetworkSize.ValueType  # 1
SST_SIZE_SMALL: SpkSortTrainerNetworkSize.ValueType  # 2
SST_SIZE_NOMINAL: SpkSortTrainerNetworkSize.ValueType  # 3
SST_SIZE_LARGE: SpkSortTrainerNetworkSize.ValueType  # 4
global___SpkSortTrainerNetworkSize = SpkSortTrainerNetworkSize

class _SpkSortTrainerNeighborPattern:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _SpkSortTrainerNeighborPatternEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SpkSortTrainerNeighborPattern.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    SST_PATTERN_DEFAULT: _SpkSortTrainerNeighborPattern.ValueType  # 0
    SST_PATTERN_ARB: _SpkSortTrainerNeighborPattern.ValueType  # 1
    SST_PATTERN_DIST: _SpkSortTrainerNeighborPattern.ValueType  # 2
    SST_PATTERN_SPATIAL_TIGHT: _SpkSortTrainerNeighborPattern.ValueType  # 3
    SST_PATTERN_SPATIAL_LOOSE: _SpkSortTrainerNeighborPattern.ValueType  # 4

class SpkSortTrainerNeighborPattern(_SpkSortTrainerNeighborPattern, metaclass=_SpkSortTrainerNeighborPatternEnumTypeWrapper): ...

SST_PATTERN_DEFAULT: SpkSortTrainerNeighborPattern.ValueType  # 0
SST_PATTERN_ARB: SpkSortTrainerNeighborPattern.ValueType  # 1
SST_PATTERN_DIST: SpkSortTrainerNeighborPattern.ValueType  # 2
SST_PATTERN_SPATIAL_TIGHT: SpkSortTrainerNeighborPattern.ValueType  # 3
SST_PATTERN_SPATIAL_LOOSE: SpkSortTrainerNeighborPattern.ValueType  # 4
global___SpkSortTrainerNeighborPattern = SpkSortTrainerNeighborPattern

class _SpkSortTrainerNetworkRelease:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _SpkSortTrainerNetworkReleaseEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SpkSortTrainerNetworkRelease.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    SST_NET_RELEASE_ANY: _SpkSortTrainerNetworkRelease.ValueType  # 0
    SST_NET_RELEASE_DEV: _SpkSortTrainerNetworkRelease.ValueType  # 1
    SST_NET_RELEASE_DEV_MOD: _SpkSortTrainerNetworkRelease.ValueType  # 2
    SST_NET_RELEASE_PROD: _SpkSortTrainerNetworkRelease.ValueType  # 3
    SST_NET_RELEASE_PROD_MOD: _SpkSortTrainerNetworkRelease.ValueType  # 4
    SST_NET_RELEASE_SANDBOX: _SpkSortTrainerNetworkRelease.ValueType  # 5
    SST_NET_RELEASE_SANDBOX_MOD: _SpkSortTrainerNetworkRelease.ValueType  # 6

class SpkSortTrainerNetworkRelease(_SpkSortTrainerNetworkRelease, metaclass=_SpkSortTrainerNetworkReleaseEnumTypeWrapper): ...

SST_NET_RELEASE_ANY: SpkSortTrainerNetworkRelease.ValueType  # 0
SST_NET_RELEASE_DEV: SpkSortTrainerNetworkRelease.ValueType  # 1
SST_NET_RELEASE_DEV_MOD: SpkSortTrainerNetworkRelease.ValueType  # 2
SST_NET_RELEASE_PROD: SpkSortTrainerNetworkRelease.ValueType  # 3
SST_NET_RELEASE_PROD_MOD: SpkSortTrainerNetworkRelease.ValueType  # 4
SST_NET_RELEASE_SANDBOX: SpkSortTrainerNetworkRelease.ValueType  # 5
SST_NET_RELEASE_SANDBOX_MOD: SpkSortTrainerNetworkRelease.ValueType  # 6
global___SpkSortTrainerNetworkRelease = SpkSortTrainerNetworkRelease

class _WrangleMode:
    ValueType = typing.NewType("ValueType", builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _WrangleModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_WrangleMode.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    WRANGLE_MODE_IMPORT_NNX_VEX_SPIKES_SIM: _WrangleMode.ValueType  # 0
    WRANGLE_MODE_MERGE_FIT_VIEW: _WrangleMode.ValueType  # 1
    WRANGLE_MODE_IMPORT_KILOSORT_SPIKES: _WrangleMode.ValueType  # 2

class WrangleMode(_WrangleMode, metaclass=_WrangleModeEnumTypeWrapper): ...

WRANGLE_MODE_IMPORT_NNX_VEX_SPIKES_SIM: WrangleMode.ValueType  # 0
WRANGLE_MODE_MERGE_FIT_VIEW: WrangleMode.ValueType  # 1
WRANGLE_MODE_IMPORT_KILOSORT_SPIKES: WrangleMode.ValueType  # 2
global___WrangleMode = WrangleMode

@typing.final
class SpkSortTrainerProfileReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DSRC_FIELD_NUMBER: builtins.int
    MODELUID_FIELD_NUMBER: builtins.int
    OUTPATH_FIELD_NUMBER: builtins.int
    ISBLOCK_FIELD_NUMBER: builtins.int
    PHASE1TRAIN_FIELD_NUMBER: builtins.int
    POSSCALE_FIELD_NUMBER: builtins.int
    EPS_FIELD_NUMBER: builtins.int
    MINPTS_FIELD_NUMBER: builtins.int
    modelUID: builtins.str
    outPath: builtins.str
    isBlock: builtins.bool
    phase1Train: builtins.bool
    posScale: builtins.float
    eps: builtins.float
    minPts: builtins.int
    @property
    def dsrc(self) -> common_pb2.FileDescriptor: ...
    def __init__(
        self,
        *,
        dsrc: common_pb2.FileDescriptor | None = ...,
        modelUID: builtins.str | None = ...,
        outPath: builtins.str | None = ...,
        isBlock: builtins.bool | None = ...,
        phase1Train: builtins.bool | None = ...,
        posScale: builtins.float | None = ...,
        eps: builtins.float | None = ...,
        minPts: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["dsrc", b"dsrc", "eps", b"eps", "isBlock", b"isBlock", "minPts", b"minPts", "modelUID", b"modelUID", "outPath", b"outPath", "phase1Train", b"phase1Train", "posScale", b"posScale"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["dsrc", b"dsrc", "eps", b"eps", "isBlock", b"isBlock", "minPts", b"minPts", "modelUID", b"modelUID", "outPath", b"outPath", "phase1Train", b"phase1Train", "posScale", b"posScale"]) -> None: ...

global___SpkSortTrainerProfileReq = SpkSortTrainerProfileReq

@typing.final
class SpkSortTrainerDeleteModelReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    RELEASE_FIELD_NUMBER: builtins.int
    ISDELETENAMED_FIELD_NUMBER: builtins.int
    release: global___SpkSortTrainerNetworkRelease.ValueType
    isDeleteNamed: builtins.bool
    """!!TODO will need to complete this as needed."""
    def __init__(
        self,
        *,
        release: global___SpkSortTrainerNetworkRelease.ValueType | None = ...,
        isDeleteNamed: builtins.bool | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["isDeleteNamed", b"isDeleteNamed", "release", b"release"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["isDeleteNamed", b"isDeleteNamed", "release", b"release"]) -> None: ...

global___SpkSortTrainerDeleteModelReq = SpkSortTrainerDeleteModelReq

@typing.final
class SpkSortNetworkParams(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    INPUTFEATURETYPE_FIELD_NUMBER: builtins.int
    NUMFEATURES_FIELD_NUMBER: builtins.int
    LATENTDIM_FIELD_NUMBER: builtins.int
    inputFeatureType: spikesorter_pb2.InputFeatureType.ValueType
    numFeatures: builtins.int
    latentDim: builtins.int
    def __init__(
        self,
        *,
        inputFeatureType: spikesorter_pb2.InputFeatureType.ValueType | None = ...,
        numFeatures: builtins.int | None = ...,
        latentDim: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["inputFeatureType", b"inputFeatureType", "latentDim", b"latentDim", "numFeatures", b"numFeatures"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["inputFeatureType", b"inputFeatureType", "latentDim", b"latentDim", "numFeatures", b"numFeatures"]) -> None: ...

global___SpkSortNetworkParams = SpkSortNetworkParams

@typing.final
class DeepClustererCreationParams(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    ENCDIMS_FIELD_NUMBER: builtins.int
    ENCACT_FIELD_NUMBER: builtins.int
    DECDIMS_FIELD_NUMBER: builtins.int
    DECACT_FIELD_NUMBER: builtins.int
    DROPOUTRATE_FIELD_NUMBER: builtins.int
    DROPOUTVAL_FIELD_NUMBER: builtins.int
    BATCHNORM_FIELD_NUMBER: builtins.int
    BATCHNORMMOMENTUM_FIELD_NUMBER: builtins.int
    BATCHNORMBEFOREACTIVATION_FIELD_NUMBER: builtins.int
    BATCHNORMLATENT_FIELD_NUMBER: builtins.int
    BATCHNORMRECONSTRUCTION_FIELD_NUMBER: builtins.int
    ACTRECONSTRUCTION_FIELD_NUMBER: builtins.int
    ACTLATENT_FIELD_NUMBER: builtins.int
    SAVEPATH_FIELD_NUMBER: builtins.int
    BASENAME_FIELD_NUMBER: builtins.int
    BASESEED_FIELD_NUMBER: builtins.int
    PROJDIMS_FIELD_NUMBER: builtins.int
    PROJACT_FIELD_NUMBER: builtins.int
    SEED_FIELD_NUMBER: builtins.int
    encAct: builtins.str
    decAct: builtins.str
    dropoutRate: builtins.float
    dropoutVal: builtins.float
    batchNorm: builtins.bool
    batchNormMomentum: builtins.float
    batchNormBeforeActivation: builtins.bool
    batchNormLatent: builtins.bool
    batchNormReconstruction: builtins.bool
    actReconstruction: builtins.str
    actLatent: builtins.str
    savePath: builtins.str
    baseName: builtins.str
    baseSeed: builtins.int
    projAct: builtins.str
    seed: builtins.int
    @property
    def encDims(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
    @property
    def decDims(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
    @property
    def projDims(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]: ...
    def __init__(
        self,
        *,
        encDims: collections.abc.Iterable[builtins.int] | None = ...,
        encAct: builtins.str | None = ...,
        decDims: collections.abc.Iterable[builtins.int] | None = ...,
        decAct: builtins.str | None = ...,
        dropoutRate: builtins.float | None = ...,
        dropoutVal: builtins.float | None = ...,
        batchNorm: builtins.bool | None = ...,
        batchNormMomentum: builtins.float | None = ...,
        batchNormBeforeActivation: builtins.bool | None = ...,
        batchNormLatent: builtins.bool | None = ...,
        batchNormReconstruction: builtins.bool | None = ...,
        actReconstruction: builtins.str | None = ...,
        actLatent: builtins.str | None = ...,
        savePath: builtins.str | None = ...,
        baseName: builtins.str | None = ...,
        baseSeed: builtins.int | None = ...,
        projDims: collections.abc.Iterable[builtins.int] | None = ...,
        projAct: builtins.str | None = ...,
        seed: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["actLatent", b"actLatent", "actReconstruction", b"actReconstruction", "baseName", b"baseName", "baseSeed", b"baseSeed", "batchNorm", b"batchNorm", "batchNormBeforeActivation", b"batchNormBeforeActivation", "batchNormLatent", b"batchNormLatent", "batchNormMomentum", b"batchNormMomentum", "batchNormReconstruction", b"batchNormReconstruction", "decAct", b"decAct", "dropoutRate", b"dropoutRate", "dropoutVal", b"dropoutVal", "encAct", b"encAct", "projAct", b"projAct", "savePath", b"savePath", "seed", b"seed"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["actLatent", b"actLatent", "actReconstruction", b"actReconstruction", "baseName", b"baseName", "baseSeed", b"baseSeed", "batchNorm", b"batchNorm", "batchNormBeforeActivation", b"batchNormBeforeActivation", "batchNormLatent", b"batchNormLatent", "batchNormMomentum", b"batchNormMomentum", "batchNormReconstruction", b"batchNormReconstruction", "decAct", b"decAct", "decDims", b"decDims", "dropoutRate", b"dropoutRate", "dropoutVal", b"dropoutVal", "encAct", b"encAct", "encDims", b"encDims", "projAct", b"projAct", "projDims", b"projDims", "savePath", b"savePath", "seed", b"seed"]) -> None: ...

global___DeepClustererCreationParams = DeepClustererCreationParams

@typing.final
class SpkSortModelBuilderParams(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DEEPCLUSTERERCREATIONPARAMS_FIELD_NUMBER: builtins.int
    INPUTFEATURETYPE_FIELD_NUMBER: builtins.int
    NUMFEATURES_FIELD_NUMBER: builtins.int
    WFMRESAMPPTS_FIELD_NUMBER: builtins.int
    MODELUID_FIELD_NUMBER: builtins.int
    inputFeatureType: spikesorter_pb2.InputFeatureType.ValueType
    numFeatures: builtins.int
    wfmResampPts: builtins.int
    modelUID: builtins.str
    @property
    def deepClustererCreationParams(self) -> global___DeepClustererCreationParams: ...
    def __init__(
        self,
        *,
        deepClustererCreationParams: global___DeepClustererCreationParams | None = ...,
        inputFeatureType: spikesorter_pb2.InputFeatureType.ValueType | None = ...,
        numFeatures: builtins.int | None = ...,
        wfmResampPts: builtins.int | None = ...,
        modelUID: builtins.str | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["deepClustererCreationParams", b"deepClustererCreationParams", "inputFeatureType", b"inputFeatureType", "modelUID", b"modelUID", "numFeatures", b"numFeatures", "wfmResampPts", b"wfmResampPts"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["deepClustererCreationParams", b"deepClustererCreationParams", "inputFeatureType", b"inputFeatureType", "modelUID", b"modelUID", "numFeatures", b"numFeatures", "wfmResampPts", b"wfmResampPts"]) -> None: ...

global___SpkSortModelBuilderParams = SpkSortModelBuilderParams

@typing.final
class SpkSortModelTrainParams(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    DSETTRAIN_FIELD_NUMBER: builtins.int
    TRAINPHASE_FIELD_NUMBER: builtins.int
    NUMEPOCHS_FIELD_NUMBER: builtins.int
    MINIBATCHSIZE_FIELD_NUMBER: builtins.int
    BASEALPHA_FIELD_NUMBER: builtins.int
    ALPHADECAYRATE_FIELD_NUMBER: builtins.int
    ALPHADECAYSTEP_FIELD_NUMBER: builtins.int
    LOSSRECON_FIELD_NUMBER: builtins.int
    LOSSCLASS_FIELD_NUMBER: builtins.int
    LOSSCLUST_FIELD_NUMBER: builtins.int
    L1_FIELD_NUMBER: builtins.int
    L2_FIELD_NUMBER: builtins.int
    NUMLOGS_FIELD_NUMBER: builtins.int
    ISSAVEMODEL_FIELD_NUMBER: builtins.int
    TEMPERATURE_FIELD_NUMBER: builtins.int
    BRAINREGION_FIELD_NUMBER: builtins.int
    PROBEID_FIELD_NUMBER: builtins.int
    NUMGTNEURONS_FIELD_NUMBER: builtins.int
    trainPhase: global___TrainPhase.ValueType
    numEpochs: builtins.int
    minibatchSize: builtins.int
    baseAlpha: builtins.float
    alphaDecayRate: builtins.float
    alphaDecayStep: builtins.int
    lossRecon: builtins.bool
    lossClass: builtins.bool
    lossClust: builtins.bool
    l1: builtins.float
    l2: builtins.float
    numLogs: builtins.int
    isSaveModel: builtins.bool
    temperature: builtins.float
    brainRegion: builtins.str
    probeID: builtins.str
    numGtNeurons: builtins.int
    @property
    def dsetTrain(self) -> datasource_pb2.DataSourceSetSaveRequest: ...
    def __init__(
        self,
        *,
        dsetTrain: datasource_pb2.DataSourceSetSaveRequest | None = ...,
        trainPhase: global___TrainPhase.ValueType | None = ...,
        numEpochs: builtins.int | None = ...,
        minibatchSize: builtins.int | None = ...,
        baseAlpha: builtins.float | None = ...,
        alphaDecayRate: builtins.float | None = ...,
        alphaDecayStep: builtins.int | None = ...,
        lossRecon: builtins.bool | None = ...,
        lossClass: builtins.bool | None = ...,
        lossClust: builtins.bool | None = ...,
        l1: builtins.float | None = ...,
        l2: builtins.float | None = ...,
        numLogs: builtins.int | None = ...,
        isSaveModel: builtins.bool | None = ...,
        temperature: builtins.float | None = ...,
        brainRegion: builtins.str | None = ...,
        probeID: builtins.str | None = ...,
        numGtNeurons: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["alphaDecayRate", b"alphaDecayRate", "alphaDecayStep", b"alphaDecayStep", "baseAlpha", b"baseAlpha", "brainRegion", b"brainRegion", "dsetTrain", b"dsetTrain", "isSaveModel", b"isSaveModel", "l1", b"l1", "l2", b"l2", "lossClass", b"lossClass", "lossClust", b"lossClust", "lossRecon", b"lossRecon", "minibatchSize", b"minibatchSize", "numEpochs", b"numEpochs", "numGtNeurons", b"numGtNeurons", "numLogs", b"numLogs", "probeID", b"probeID", "temperature", b"temperature", "trainPhase", b"trainPhase"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["alphaDecayRate", b"alphaDecayRate", "alphaDecayStep", b"alphaDecayStep", "baseAlpha", b"baseAlpha", "brainRegion", b"brainRegion", "dsetTrain", b"dsetTrain", "isSaveModel", b"isSaveModel", "l1", b"l1", "l2", b"l2", "lossClass", b"lossClass", "lossClust", b"lossClust", "lossRecon", b"lossRecon", "minibatchSize", b"minibatchSize", "numEpochs", b"numEpochs", "numGtNeurons", b"numGtNeurons", "numLogs", b"numLogs", "probeID", b"probeID", "temperature", b"temperature", "trainPhase", b"trainPhase"]) -> None: ...

global___SpkSortModelTrainParams = SpkSortModelTrainParams

@typing.final
class SpkSortTrainerNewReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PARAMSMODELBUILDER_FIELD_NUMBER: builtins.int
    PARAMSTRAINPHASE1_FIELD_NUMBER: builtins.int
    PARAMSTRAINPHASE2_FIELD_NUMBER: builtins.int
    PARAMSTRAINPHASE3_FIELD_NUMBER: builtins.int
    ISBLOCK_FIELD_NUMBER: builtins.int
    isBlock: builtins.bool
    @property
    def paramsModelBuilder(self) -> global___SpkSortModelBuilderParams: ...
    @property
    def paramsTrainPhase1(self) -> global___SpkSortModelTrainParams: ...
    @property
    def paramsTrainPhase2(self) -> global___SpkSortModelTrainParams: ...
    @property
    def paramsTrainPhase3(self) -> global___SpkSortModelTrainParams: ...
    def __init__(
        self,
        *,
        paramsModelBuilder: global___SpkSortModelBuilderParams | None = ...,
        paramsTrainPhase1: global___SpkSortModelTrainParams | None = ...,
        paramsTrainPhase2: global___SpkSortModelTrainParams | None = ...,
        paramsTrainPhase3: global___SpkSortModelTrainParams | None = ...,
        isBlock: builtins.bool | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["isBlock", b"isBlock", "paramsModelBuilder", b"paramsModelBuilder", "paramsTrainPhase1", b"paramsTrainPhase1", "paramsTrainPhase2", b"paramsTrainPhase2", "paramsTrainPhase3", b"paramsTrainPhase3"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["isBlock", b"isBlock", "paramsModelBuilder", b"paramsModelBuilder", "paramsTrainPhase1", b"paramsTrainPhase1", "paramsTrainPhase2", b"paramsTrainPhase2", "paramsTrainPhase3", b"paramsTrainPhase3"]) -> None: ...

global___SpkSortTrainerNewReq = SpkSortTrainerNewReq

@typing.final
class SpkSortLearnHyperParamsReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODELUID_FIELD_NUMBER: builtins.int
    ISBLOCK_FIELD_NUMBER: builtins.int
    ISPOSSCALE_FIELD_NUMBER: builtins.int
    ISDBSCAN_FIELD_NUMBER: builtins.int
    DSRC_FIELD_NUMBER: builtins.int
    modelUID: builtins.str
    isBlock: builtins.bool
    isPosScale: builtins.bool
    isDBScan: builtins.bool
    @property
    def dsrc(self) -> common_pb2.FileDescriptor: ...
    def __init__(
        self,
        *,
        modelUID: builtins.str | None = ...,
        isBlock: builtins.bool | None = ...,
        isPosScale: builtins.bool | None = ...,
        isDBScan: builtins.bool | None = ...,
        dsrc: common_pb2.FileDescriptor | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["dsrc", b"dsrc", "isBlock", b"isBlock", "isDBScan", b"isDBScan", "isPosScale", b"isPosScale", "modelUID", b"modelUID"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["dsrc", b"dsrc", "isBlock", b"isBlock", "isDBScan", b"isDBScan", "isPosScale", b"isPosScale", "modelUID", b"modelUID"]) -> None: ...

global___SpkSortLearnHyperParamsReq = SpkSortLearnHyperParamsReq

@typing.final
class SpkSortTrainerDatasetParam(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    NIPATHTRAIN_FIELD_NUMBER: builtins.int
    NIBASENAMETRAIN_FIELD_NUMBER: builtins.int
    NBHDDIM_FIELD_NUMBER: builtins.int
    RADIUSUM_FIELD_NUMBER: builtins.int
    MAXNUMSAMPLESTEST_FIELD_NUMBER: builtins.int
    NETWORKMASKINGFRAC_FIELD_NUMBER: builtins.int
    NETWORKINITWEIGHTSSTDDEV_FIELD_NUMBER: builtins.int
    NETWORKINITBIASSTDDEV_FIELD_NUMBER: builtins.int
    NETWORKL1LAMBDA_FIELD_NUMBER: builtins.int
    NETWORKHIDDENLAYERSHAPERELINPUTDIM_FIELD_NUMBER: builtins.int
    NETWORKNUMFEATURES2_FIELD_NUMBER: builtins.int
    niPathTrain: builtins.str
    niBaseNameTrain: builtins.str
    NbhdDim: builtins.int
    radiusUm: builtins.float
    maxNumSamplesTest: builtins.int
    networkMaskingFrac: builtins.float
    networkInitWeightsStdDev: builtins.float
    networkInitBiasStdDev: builtins.float
    networkL1lambda: builtins.float
    networkNumFeatures2: builtins.int
    @property
    def networkHiddenLayerShapeRelInputDim(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    def __init__(
        self,
        *,
        niPathTrain: builtins.str | None = ...,
        niBaseNameTrain: builtins.str | None = ...,
        NbhdDim: builtins.int | None = ...,
        radiusUm: builtins.float | None = ...,
        maxNumSamplesTest: builtins.int | None = ...,
        networkMaskingFrac: builtins.float | None = ...,
        networkInitWeightsStdDev: builtins.float | None = ...,
        networkInitBiasStdDev: builtins.float | None = ...,
        networkL1lambda: builtins.float | None = ...,
        networkHiddenLayerShapeRelInputDim: collections.abc.Iterable[builtins.float] | None = ...,
        networkNumFeatures2: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["NbhdDim", b"NbhdDim", "maxNumSamplesTest", b"maxNumSamplesTest", "networkInitBiasStdDev", b"networkInitBiasStdDev", "networkInitWeightsStdDev", b"networkInitWeightsStdDev", "networkL1lambda", b"networkL1lambda", "networkMaskingFrac", b"networkMaskingFrac", "networkNumFeatures2", b"networkNumFeatures2", "niBaseNameTrain", b"niBaseNameTrain", "niPathTrain", b"niPathTrain", "radiusUm", b"radiusUm"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["NbhdDim", b"NbhdDim", "maxNumSamplesTest", b"maxNumSamplesTest", "networkHiddenLayerShapeRelInputDim", b"networkHiddenLayerShapeRelInputDim", "networkInitBiasStdDev", b"networkInitBiasStdDev", "networkInitWeightsStdDev", b"networkInitWeightsStdDev", "networkL1lambda", b"networkL1lambda", "networkMaskingFrac", b"networkMaskingFrac", "networkNumFeatures2", b"networkNumFeatures2", "niBaseNameTrain", b"niBaseNameTrain", "niPathTrain", b"niPathTrain", "radiusUm", b"radiusUm"]) -> None: ...

global___SpkSortTrainerDatasetParam = SpkSortTrainerDatasetParam

@typing.final
class SpkSortTrainerNetworkTrainingParams(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    NUMEPOCHS_FIELD_NUMBER: builtins.int
    MINIBATCHSIZE_FIELD_NUMBER: builtins.int
    MAXNUMSAMPLES_FIELD_NUMBER: builtins.int
    ALPHA_FIELD_NUMBER: builtins.int
    ALPHABIAS_FIELD_NUMBER: builtins.int
    ERRORTOLPRETRAIN_FIELD_NUMBER: builtins.int
    NUMSAMPLESTESTMSE_FIELD_NUMBER: builtins.int
    numEpochs: builtins.int
    minibatchSize: builtins.int
    maxNumSamples: builtins.int
    alpha: builtins.float
    alphaBias: builtins.float
    errorTolPretrain: builtins.float
    numSamplesTestMSE: builtins.int
    def __init__(
        self,
        *,
        numEpochs: builtins.int | None = ...,
        minibatchSize: builtins.int | None = ...,
        maxNumSamples: builtins.int | None = ...,
        alpha: builtins.float | None = ...,
        alphaBias: builtins.float | None = ...,
        errorTolPretrain: builtins.float | None = ...,
        numSamplesTestMSE: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["alpha", b"alpha", "alphaBias", b"alphaBias", "errorTolPretrain", b"errorTolPretrain", "maxNumSamples", b"maxNumSamples", "minibatchSize", b"minibatchSize", "numEpochs", b"numEpochs", "numSamplesTestMSE", b"numSamplesTestMSE"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["alpha", b"alpha", "alphaBias", b"alphaBias", "errorTolPretrain", b"errorTolPretrain", "maxNumSamples", b"maxNumSamples", "minibatchSize", b"minibatchSize", "numEpochs", b"numEpochs", "numSamplesTestMSE", b"numSamplesTestMSE"]) -> None: ...

global___SpkSortTrainerNetworkTrainingParams = SpkSortTrainerNetworkTrainingParams

@typing.final
class SpkSortTrainerStoreDescriptor(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    BRAINREGION_FIELD_NUMBER: builtins.int
    NETWORKSIZE_FIELD_NUMBER: builtins.int
    NBRPATTERN_FIELD_NUMBER: builtins.int
    NETWORKID_FIELD_NUMBER: builtins.int
    NBHDDIM_FIELD_NUMBER: builtins.int
    RELEASE_FIELD_NUMBER: builtins.int
    brainRegion: builtins.str
    networkSize: global___SpkSortTrainerNetworkSize.ValueType
    nbrPattern: global___SpkSortTrainerNeighborPattern.ValueType
    networkID: builtins.str
    NbhdDim: builtins.int
    release: global___SpkSortTrainerNetworkRelease.ValueType
    def __init__(
        self,
        *,
        brainRegion: builtins.str | None = ...,
        networkSize: global___SpkSortTrainerNetworkSize.ValueType | None = ...,
        nbrPattern: global___SpkSortTrainerNeighborPattern.ValueType | None = ...,
        networkID: builtins.str | None = ...,
        NbhdDim: builtins.int | None = ...,
        release: global___SpkSortTrainerNetworkRelease.ValueType | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["NbhdDim", b"NbhdDim", "brainRegion", b"brainRegion", "nbrPattern", b"nbrPattern", "networkID", b"networkID", "networkSize", b"networkSize", "release", b"release"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["NbhdDim", b"NbhdDim", "brainRegion", b"brainRegion", "nbrPattern", b"nbrPattern", "networkID", b"networkID", "networkSize", b"networkSize", "release", b"release"]) -> None: ...

global___SpkSortTrainerStoreDescriptor = SpkSortTrainerStoreDescriptor

@typing.final
class SpkSortTrainerSetModeReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODE_FIELD_NUMBER: builtins.int
    mode: builtins.int
    def __init__(
        self,
        *,
        mode: builtins.int | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["mode", b"mode"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["mode", b"mode"]) -> None: ...

global___SpkSortTrainerSetModeReq = SpkSortTrainerSetModeReq

@typing.final
class SpkSortTrainerCmdReq(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    class _SpkSortTrainerCmd:
        ValueType = typing.NewType("ValueType", builtins.int)
        V: typing_extensions.TypeAlias = ValueType

    class _SpkSortTrainerCmdEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[SpkSortTrainerCmdReq._SpkSortTrainerCmd.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
        CMD_ON: SpkSortTrainerCmdReq._SpkSortTrainerCmd.ValueType  # 0
        """must match DECsorterState enums"""
        CMD_OFF: SpkSortTrainerCmdReq._SpkSortTrainerCmd.ValueType  # 1

    class SpkSortTrainerCmd(_SpkSortTrainerCmd, metaclass=_SpkSortTrainerCmdEnumTypeWrapper): ...
    CMD_ON: SpkSortTrainerCmdReq.SpkSortTrainerCmd.ValueType  # 0
    """must match DECsorterState enums"""
    CMD_OFF: SpkSortTrainerCmdReq.SpkSortTrainerCmd.ValueType  # 1

    CMD_FIELD_NUMBER: builtins.int
    cmd: global___SpkSortTrainerCmdReq.SpkSortTrainerCmd.ValueType
    def __init__(
        self,
        *,
        cmd: global___SpkSortTrainerCmdReq.SpkSortTrainerCmd.ValueType | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["cmd", b"cmd"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["cmd", b"cmd"]) -> None: ...

global___SpkSortTrainerCmdReq = SpkSortTrainerCmdReq

@typing.final
class SpkSortTrainerStatusReply(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MSGJSON_FIELD_NUMBER: builtins.int
    msgJson: builtins.bytes
    def __init__(
        self,
        *,
        msgJson: builtins.bytes | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["msgJson", b"msgJson"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["msgJson", b"msgJson"]) -> None: ...

global___SpkSortTrainerStatusReply = SpkSortTrainerStatusReply

@typing.final
class WrangleRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    MODE_FIELD_NUMBER: builtins.int
    SPEC_FIELD_NUMBER: builtins.int
    mode: global___WrangleMode.ValueType
    @property
    def spec(self) -> global___WrangleMerge: ...
    def __init__(
        self,
        *,
        mode: global___WrangleMode.ValueType | None = ...,
        spec: global___WrangleMerge | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["mode", b"mode", "spec", b"spec"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["mode", b"mode", "spec", b"spec"]) -> None: ...

global___WrangleRequest = WrangleRequest

@typing.final
class WrangleSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    IMPORT_FIELD_NUMBER: builtins.int
    MERGE_FIELD_NUMBER: builtins.int
    @property
    def merge(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WrangleMerge]: ...
    def __init__(
        self,
        *,
        merge: collections.abc.Iterable[global___WrangleMerge] | None = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["import", b"import", "merge", b"merge"]) -> None: ...

global___WrangleSpec = WrangleSpec

@typing.final
class WrangleImport(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    VEXSPIKESSIM_FIELD_NUMBER: builtins.int
    @property
    def vexSpikesSim(self) -> global___WrangleImportVexSpikesSim: ...
    def __init__(
        self,
        *,
        vexSpikesSim: global___WrangleImportVexSpikesSim | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["vexSpikesSim", b"vexSpikesSim"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["vexSpikesSim", b"vexSpikesSim"]) -> None: ...

global___WrangleImport = WrangleImport

@typing.final
class WrangleImportVexSpikesSim(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SOURCE_FIELD_NUMBER: builtins.int
    ISOVERWRITE_FIELD_NUMBER: builtins.int
    NOTE_FIELD_NUMBER: builtins.int
    isOverwrite: builtins.bool
    note: builtins.str
    @property
    def source(self) -> global___WrangleFileDesc: ...
    def __init__(
        self,
        *,
        source: global___WrangleFileDesc | None = ...,
        isOverwrite: builtins.bool | None = ...,
        note: builtins.str | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["isOverwrite", b"isOverwrite", "note", b"note", "source", b"source"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["isOverwrite", b"isOverwrite", "note", b"note", "source", b"source"]) -> None: ...

global___WrangleImportVexSpikesSim = WrangleImportVexSpikesSim

@typing.final
class WrangleFileDesc(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    PATH_FIELD_NUMBER: builtins.int
    BASENAME_FIELD_NUMBER: builtins.int
    FILETYPE_FIELD_NUMBER: builtins.int
    path: builtins.str
    baseName: builtins.str
    fileType: builtins.str
    def __init__(
        self,
        *,
        path: builtins.str | None = ...,
        baseName: builtins.str | None = ...,
        fileType: builtins.str | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["baseName", b"baseName", "fileType", b"fileType", "path", b"path"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["baseName", b"baseName", "fileType", b"fileType", "path", b"path"]) -> None: ...

global___WrangleFileDesc = WrangleFileDesc

@typing.final
class WrangleMerge(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    VEXSPIKESVIEW_FIELD_NUMBER: builtins.int
    @property
    def vexSpikesView(self) -> global___WrangleMergeVexSpikesView: ...
    def __init__(
        self,
        *,
        vexSpikesView: global___WrangleMergeVexSpikesView | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["vexSpikesView", b"vexSpikesView"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["vexSpikesView", b"vexSpikesView"]) -> None: ...

global___WrangleMerge = WrangleMerge

@typing.final
class WrangleMergeVexSpikesView(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SOURCEVEX_FIELD_NUMBER: builtins.int
    SOURCEBIO_FIELD_NUMBER: builtins.int
    VIEW_FIELD_NUMBER: builtins.int
    NOTE_FIELD_NUMBER: builtins.int
    ISBANDPASSFILTER_FIELD_NUMBER: builtins.int
    BANDPASSFILTERSPEC_FIELD_NUMBER: builtins.int
    ISOVERWRITE_FIELD_NUMBER: builtins.int
    SPIKEWINDOWMS_FIELD_NUMBER: builtins.int
    SPIKESHADOWMS_FIELD_NUMBER: builtins.int
    note: builtins.str
    isBandpassFilter: builtins.bool
    isOverwrite: builtins.bool
    spikeShadowMs: builtins.float
    @property
    def sourceVex(self) -> global___WrangleFileDesc: ...
    @property
    def sourceBio(self) -> global___WrangleFileDesc: ...
    @property
    def view(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WrangleMergeVexSpikesViewSpec]: ...
    @property
    def bandpassFilterSpec(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    @property
    def spikeWindowMs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]: ...
    def __init__(
        self,
        *,
        sourceVex: global___WrangleFileDesc | None = ...,
        sourceBio: global___WrangleFileDesc | None = ...,
        view: collections.abc.Iterable[global___WrangleMergeVexSpikesViewSpec] | None = ...,
        note: builtins.str | None = ...,
        isBandpassFilter: builtins.bool | None = ...,
        bandpassFilterSpec: collections.abc.Iterable[builtins.float] | None = ...,
        isOverwrite: builtins.bool | None = ...,
        spikeWindowMs: collections.abc.Iterable[builtins.float] | None = ...,
        spikeShadowMs: builtins.float | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["isBandpassFilter", b"isBandpassFilter", "isOverwrite", b"isOverwrite", "note", b"note", "sourceBio", b"sourceBio", "sourceVex", b"sourceVex", "spikeShadowMs", b"spikeShadowMs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["bandpassFilterSpec", b"bandpassFilterSpec", "isBandpassFilter", b"isBandpassFilter", "isOverwrite", b"isOverwrite", "note", b"note", "sourceBio", b"sourceBio", "sourceVex", b"sourceVex", "spikeShadowMs", b"spikeShadowMs", "spikeWindowMs", b"spikeWindowMs", "view", b"view"]) -> None: ...

global___WrangleMergeVexSpikesView = WrangleMergeVexSpikesView

@typing.final
class WrangleMergeVexSpikesViewSpec(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SINKBIO_FIELD_NUMBER: builtins.int
    SITENEIGHBORRADIUSUM_FIELD_NUMBER: builtins.int
    REQNUMSITENEIGHBORS_FIELD_NUMBER: builtins.int
    SPIKEWINDOWMS_FIELD_NUMBER: builtins.int
    SPIKESHADOWMS_FIELD_NUMBER: builtins.int
    NOTE_FIELD_NUMBER: builtins.int
    siteNeighborRadiusUm: builtins.float
    reqNumSiteNeighbors: builtins.int
    spikeShadowMs: builtins.float
    note: builtins.str
    @property
    def sinkBio(self) -> global___WrangleFileDesc: ...
    @property
    def spikeWindowMs(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]:
        """pre-peak, post-peak wrt reference time"""

    def __init__(
        self,
        *,
        sinkBio: global___WrangleFileDesc | None = ...,
        siteNeighborRadiusUm: builtins.float | None = ...,
        reqNumSiteNeighbors: builtins.int | None = ...,
        spikeWindowMs: collections.abc.Iterable[builtins.float] | None = ...,
        spikeShadowMs: builtins.float | None = ...,
        note: builtins.str | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["note", b"note", "reqNumSiteNeighbors", b"reqNumSiteNeighbors", "sinkBio", b"sinkBio", "siteNeighborRadiusUm", b"siteNeighborRadiusUm", "spikeShadowMs", b"spikeShadowMs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["note", b"note", "reqNumSiteNeighbors", b"reqNumSiteNeighbors", "sinkBio", b"sinkBio", "siteNeighborRadiusUm", b"siteNeighborRadiusUm", "spikeShadowMs", b"spikeShadowMs", "spikeWindowMs", b"spikeWindowMs"]) -> None: ...

global___WrangleMergeVexSpikesViewSpec = WrangleMergeVexSpikesViewSpec

@typing.final
class RecgenImport(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    FILEPATHS_FIELD_NUMBER: builtins.int
    OUTPATHS_FIELD_NUMBER: builtins.int
    ISIMPORTXDAT_FIELD_NUMBER: builtins.int
    ISIMPORTSPIKES_FIELD_NUMBER: builtins.int
    SCRAPENEIGHBORHOODUM_FIELD_NUMBER: builtins.int
    isImportXdat: builtins.bool
    isImportSpikes: builtins.bool
    scrapeNeighborhoodUm: builtins.float
    @property
    def filePaths(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
    @property
    def outPaths(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]: ...
    def __init__(
        self,
        *,
        filePaths: collections.abc.Iterable[builtins.str] | None = ...,
        outPaths: collections.abc.Iterable[builtins.str] | None = ...,
        isImportXdat: builtins.bool | None = ...,
        isImportSpikes: builtins.bool | None = ...,
        scrapeNeighborhoodUm: builtins.float | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["isImportSpikes", b"isImportSpikes", "isImportXdat", b"isImportXdat", "scrapeNeighborhoodUm", b"scrapeNeighborhoodUm"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["filePaths", b"filePaths", "isImportSpikes", b"isImportSpikes", "isImportXdat", b"isImportXdat", "outPaths", b"outPaths", "scrapeNeighborhoodUm", b"scrapeNeighborhoodUm"]) -> None: ...

global___RecgenImport = RecgenImport
