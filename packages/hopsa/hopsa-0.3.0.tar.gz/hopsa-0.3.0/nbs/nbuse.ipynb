{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook utilities\n",
    "\n",
    "> Utilities for working with notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp nbuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import ast\n",
    "import inspect\n",
    "import nbformat\n",
    "import tomli_w\n",
    "import tomllib\n",
    "from pathlib import Path\n",
    "from typing import Type, Any, Optional, Dict, get_type_hints, get_origin, get_args\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create markdown table from a Pydantic dataclass\n",
    "\n",
    "Especially confenient for Documentation written automatically from the Notebooks by nbdev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _format_type(type_hint: Any) -> str:\n",
    "    \"\"\"Format a type hint into a readable string.\"\"\"\n",
    "    if get_origin(type_hint) is not None:\n",
    "        # Handle generic types like List[str], Optional[int], etc.\n",
    "        origin = get_origin(type_hint)\n",
    "        args = get_args(type_hint)\n",
    "        \n",
    "        if origin is Union:\n",
    "            # Handle Optional (Union[X, None])\n",
    "            if len(args) == 2 and args[1] is type(None):\n",
    "                return f\"Optional[{_format_type(args[0])}]\"\n",
    "            else:\n",
    "                return f\"Union[{', '.join(_format_type(arg) for arg in args)}]\"\n",
    "        \n",
    "        # Handle other generic types\n",
    "        origin_name = origin.__name__ if hasattr(origin, \"__name__\") else str(origin).replace(\"typing.\", \"\")\n",
    "        args_str = \", \".join(_format_type(arg) for arg in args)\n",
    "        return f\"{origin_name}[{args_str}]\"\n",
    "    \n",
    "    # Handle non-generic types\n",
    "    if hasattr(type_hint, \"__name__\"):\n",
    "        return type_hint.__name__\n",
    "    \n",
    "    return str(type_hint).replace(\"typing.\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _escape_table_cell(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Escape special characters in markdown table cells.\n",
    "    The key is to escape pipe characters with HTML entity or backslash.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # Replace pipe characters with HTML entity\n",
    "    # This is the most reliable way to prevent them from being interpreted as column separators\n",
    "    return text.replace(\"|\", \"\\|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pydantic_to_markdown_table(model_class: Type[BaseModel]) -> None:\n",
    "    \"\"\"\n",
    "    Convert a Pydantic model class to a markdown table and display it in Jupyter notebook.\n",
    "    \n",
    "    Args:\n",
    "        model_class: A Pydantic model class (subclass of BaseModel)\n",
    "    \"\"\"\n",
    "    if not issubclass(model_class, BaseModel):\n",
    "        raise TypeError(\"Input must be a Pydantic BaseModel class\")\n",
    "    \n",
    "    md_name = f\"## {model_class.__name__}\\n\"\n",
    "    md_docstring = f\"{inspect.getdoc(model_class)}\\n\" or \"\"\n",
    "    \n",
    "    # Get source code lines to extract comments\n",
    "    try:\n",
    "        source_lines = inspect.getsource(model_class).splitlines()\n",
    "    except (OSError, TypeError):\n",
    "        source_lines = []\n",
    "    \n",
    "    # Extract property comments from source code\n",
    "    property_comments = {}\n",
    "    for i, line in enumerate(source_lines):\n",
    "        if \":\" in line and \"#\" in line:\n",
    "            # Extract property name and comment\n",
    "            property_part = line.split(\":\")[0].strip()\n",
    "            comment_part = line.split(\"#\")[1].strip()\n",
    "            property_comments[property_part] = comment_part\n",
    "    \n",
    "    # Start building the markdown table\n",
    "    table = \"\\n| Variable | Type | Default | Details |\\n\"\n",
    "    table += \"|---|---|---|---|\\n\"\n",
    "    \n",
    "    # Get type hints and model fields\n",
    "    type_hints = get_type_hints(model_class)\n",
    "    \n",
    "    # Handle both Pydantic v1 and v2\n",
    "    model_fields = getattr(model_class, \"model_fields\", None)\n",
    "    if model_fields is None:\n",
    "        model_fields = getattr(model_class, \"__fields__\", {})\n",
    "    \n",
    "    # Process each field\n",
    "    for field_name, field_type in type_hints.items():\n",
    "        # Skip private fields and methods\n",
    "        if field_name.startswith('_'):\n",
    "            continue\n",
    "        \n",
    "        # Get field info\n",
    "        field_info = None\n",
    "        if model_fields and field_name in model_fields:\n",
    "            field_info = model_fields[field_name]\n",
    "        \n",
    "        # Format type string\n",
    "        type_str = _format_type(field_type)\n",
    "        \n",
    "        # Get default value\n",
    "        default_value = \"...\"  # Pydantic's notation for required fields\n",
    "        \n",
    "        # Try to get default from field info\n",
    "        if field_info:\n",
    "            # For Pydantic v2\n",
    "            if hasattr(field_info, \"default\") and field_info.default is not inspect.Signature.empty:\n",
    "                default_value = _escape_table_cell(repr(field_info.default))\n",
    "            # For Pydantic v1\n",
    "            elif hasattr(field_info, \"default\") and not field_info.required:\n",
    "                default_value = _escape_table_cell(repr(field_info.default))\n",
    "        \n",
    "        # Get description\n",
    "        description = \"\"\n",
    "        \n",
    "        # Try to get description from Field\n",
    "        if field_info and hasattr(field_info, \"description\") and field_info.description:\n",
    "            description = _escape_table_cell(field_info.description)\n",
    "        # Fallback to comment\n",
    "        elif field_name in property_comments:\n",
    "            description = _escape_table_cell(property_comments[field_name])\n",
    "        \n",
    "        # For nested Pydantic models, add a reference note\n",
    "        if issubclass(field_type, BaseModel) if isinstance(field_type, type) else False:\n",
    "            description += f\" (see `{field_type.__name__}` table)\"\n",
    "        \n",
    "        # Add row to table\n",
    "        table += f\"| `{field_name}` | `{type_str}` | {default_value} | {description} |\\n\"\n",
    "    \n",
    "    return display(Markdown(md_name + md_docstring + table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyChild(BaseModel):\n",
    "    \"\"\"A simple dataclass model\"\"\"\n",
    "    model_name: str = Field(..., description=\"Name or path of the model to use\") # Name\n",
    "    provider: str = Field(default=\"huggingface\", description=\"Model provider (huggingface, openai, etc)\")\n",
    "    api_key_env_var: Optional[str] = Field(default=None, description=\"Environment variable name for API key\")\n",
    "    api_base_url: Optional[str] = Field(default=None, description=\"Base URL for API reqeuest\")\n",
    "    temperature: float = Field(default=0.7, description=\"Temperature for generation\")\n",
    "\n",
    "class DummyParent(BaseModel):\n",
    "    \"\"\"Main configuration for a chat application\"\"\"\n",
    "    app_name: str = Field(..., description=\"Name of the application\")\n",
    "    description: str = Field(default=\"\", description=\"Description of the application\")\n",
    "    system_prompt: str = Field(..., description=\"System prompt for the LLM\")\n",
    "    model: DummyChild\n",
    "    show_system_prompt: bool = Field(default=True, description=\"Whether to show system prompt in UI\")\n",
    "    show_context: bool = Field(default=True, description=\"Whether to show context in UI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## DummyParent\n",
       "Main configuration for a chat application\n",
       "\n",
       "| Variable | Type | Default | Details |\n",
       "|---|---|---|---|\n",
       "| `app_name` | `str` | PydanticUndefined | Name of the application |\n",
       "| `description` | `str` | '' | Description of the application |\n",
       "| `system_prompt` | `str` | PydanticUndefined | System prompt for the LLM |\n",
       "| `model` | `DummyChild` | PydanticUndefined |  (see `DummyChild` table) |\n",
       "| `show_system_prompt` | `bool` | True | Whether to show system prompt in UI |\n",
       "| `show_context` | `bool` | True | Whether to show context in UI |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pydantic_to_markdown_table(DummyParent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tree structure from a Python dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to clearly display the structure of a Python dictionary. The output only shows the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_dict_structure(\n",
    "    d: Dict, # The dictionary that will be pretty printed\n",
    "    indent=0 # The indent that is used for subkeys\n",
    "    ) -> str:\n",
    "    for key, value in d.items():\n",
    "        print(\"  \" * indent + f\"├── {key}\")\n",
    "        if isinstance(value, dict):\n",
    "            print_dict_structure(value, indent + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── The Big Lebowski\n",
      "  ├── characters\n",
      "    ├── Dude\n",
      "    ├── Walter\n",
      "    ├── Donny\n",
      "  ├── setting\n",
      "    ├── location\n",
      "    ├── object\n",
      "├── Office Space\n",
      "  ├── characters\n",
      "    ├── Peter\n",
      "    ├── Milton\n",
      "    ├── Lumbergh\n",
      "  ├── setting\n",
      "    ├── company\n",
      "    ├── object\n",
      "├── The Princess Bride\n",
      "  ├── characters\n",
      "    ├── Westley\n",
      "    ├── Inigo\n",
      "  ├── setting\n",
      "    ├── location\n",
      "├── Labyrinth\n",
      "  ├── characters\n",
      "    ├── Sarah\n",
      "    ├── Jareth\n"
     ]
    }
   ],
   "source": [
    "movie_dict = {\n",
    "    \"The Big Lebowski\": {\n",
    "        \"characters\": {\n",
    "            \"Dude\": \"White Russian\",\n",
    "            \"Walter\": \"Vietnam\",\n",
    "            \"Donny\": \"Bowling\"\n",
    "        },\n",
    "        \"setting\": {\n",
    "            \"location\": \"Bowling Alley\",\n",
    "            \"object\": \"Rug\"\n",
    "        }\n",
    "    },\n",
    "    \"Office Space\": {\n",
    "        \"characters\": {\n",
    "            \"Peter\": \"TPS report\",\n",
    "            \"Milton\": \"Red stapler\",\n",
    "            \"Lumbergh\": \"Memos\"\n",
    "        },\n",
    "        \"setting\": {\n",
    "            \"company\": \"Initech\",\n",
    "            \"object\": \"Printer\"\n",
    "        }\n",
    "    },\n",
    "    \"The Princess Bride\": {\n",
    "        \"characters\": {\n",
    "            \"Westley\": \"Farm Boy\",\n",
    "            \"Inigo\": \"Revenge\"\n",
    "        },\n",
    "        \"setting\": {\n",
    "            \"location\": \"Cliffs of Insanity\"\n",
    "        }\n",
    "    },\n",
    "    \"Labyrinth\": {\n",
    "        \"characters\": {\n",
    "            \"Sarah\": \"Labyrinth\",\n",
    "            \"Jareth\": \"Goblin King\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print_dict_structure(movie_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export notebook variables to toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to create a TOML file from the contents of a Jupyter Notebook. This helps to create a simple interface to set the parameters of the application, without the need to build a complete GUI or demand of the user to edit TOML files directly without the ease and explanations possible in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOML can't handle None values. So if you want to set a value to None, just don't add that variable to the Jupyter Notebook or comment it out.\n",
    "\n",
    "The function will replace any spaces in a heading with underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def export_ipynb_toml(\n",
    "    nb_path: Optional[str] = None,\n",
    "    output_path: Optional[str] = None\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Export the content of the current Jupyter notebook to a TOML file.\n",
    "    \n",
    "    This function reads the content of the notebook where it's being executed,\n",
    "    extracts all level 2 (##) markdown cells as groups, and all parameter assignments\n",
    "    in code cells as key-value pairs within those groups. Regular text markdown cells are ignored.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    nb_path : str, optional\n",
    "        Path to the notebook file. If None, the function will try to determin the\n",
    "        current notebook path automatically (works in standard Jupyter but may not\n",
    "        work in all environments like VS Code).\n",
    "    output_path : str, optional\n",
    "        Path where the TOML file should be saved. If None, the TOML file will be\n",
    "        saved in the same directory as the notebook with the same name but with\n",
    "        a .toml extension.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if nb_path is None:\n",
    "        raise ValueError(\n",
    "            \"Please provide the notebook_path parameter explicitly.\"\n",
    "        )\n",
    "    \n",
    "    with open(nb_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    if output_path is None:\n",
    "        notebook_path = Path(nb_path)\n",
    "        output_path = notebook_path.with_suffix('.toml')\n",
    "    \n",
    "    data = {}\n",
    "    current_group = None\n",
    "    \n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            for line in cell.source.split('\\n'):\n",
    "                if line.startswith('## '):\n",
    "                    current_group = line[3:].strip().replace(' ', '_')\n",
    "        \n",
    "        elif cell.cell_type == 'code' and current_group is not None:\n",
    "            try:\n",
    "                tree = ast.parse(cell.source)\n",
    "            except SyntaxError:\n",
    "                # Skip malformed code cells\n",
    "                print(f\"skipped: {cell.source}\")\n",
    "                continue\n",
    "            \n",
    "            if current_group not in data:\n",
    "                data[current_group] = {}\n",
    "            \n",
    "            for node in tree.body:\n",
    "                if isinstance(node, ast.Assign):\n",
    "                    for target in node.targets:\n",
    "                        if isinstance(target, ast.Name):\n",
    "                            # TODO: for some reason this doesn't work if there's a variable in the variable, like so: `v = f\"{x}eny\"`\n",
    "                            key = target.id\n",
    "                            if key.startswith('export_ipynb_'):\n",
    "                                continue\n",
    "                            value = globals().get(key, None)\n",
    "                            if value is None:\n",
    "                                try:\n",
    "                                    value = ast.literal_eval(node.value)\n",
    "                                except (ValueError, SyntaxError):\n",
    "                                    print(f\"Warning: Could not evaluate value for '{key}' in group '{current_group}'\")\n",
    "                                    continue\n",
    "                            data[current_group][key] = value\n",
    "            \n",
    "    with open(output_path, 'wb') as f:\n",
    "        # 'wb', because \n",
    "        tomli_w.dump(data, f)\n",
    "    \n",
    "    print(f\"TOML file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage of `globals()` and `ast`\n",
    "\n",
    "The ast (Abstract Syntax Tree) module in Python allows you to parse Python source code into its syntax tree representation. This lets you analyze and manipulate Python code programmatically.\n",
    "\n",
    "`ast.parse(source)`: Parses Python code (as a string) into an AST tree.\n",
    "\n",
    "`globals()` is a built-in function that returns the current global symbol table as a dictionary.\n",
    "\n",
    "**Why use globals() first?**\n",
    "\n",
    "_Dynamic or computed variables_: In Jupyter notebooks, variables can be set by code that isn’t just a literal assignment. For example:\n",
    "\n",
    "```python\n",
    "a = 1 + 2\n",
    "b = some_function()\n",
    "c = [i for i in range(5)]\n",
    "```\n",
    "\n",
    "- globals()['a'] will give 3.\n",
    "- globals()['b'] will give the result of some_function().\n",
    "- globals()['c'] will give the actual list [0, 1, 2, 3, 4].\n",
    "\n",
    "\n",
    "**ast.literal_eval limitations**:\n",
    "\n",
    "- ast.literal_eval can only evaluate simple literals (strings, numbers, lists, dicts, etc.), not arbitrary Python expressions or anything involving variables/functions.\n",
    "- For example, it fails on a = 1 + 2, b = some_function(), or c = [i for i in range(5)].\n",
    "\n",
    "\n",
    "**Notebook context:**\n",
    "\n",
    "- In a notebook, users often assign variables dynamically, not just with literals.\n",
    "- Using globals() ensures you get the actual value as it exists in the current kernel session, reflecting any computation or function calls.\n",
    "\n",
    "**Why fall back to ast.literal_eval?**\n",
    "\n",
    "For simple assignments:\n",
    "- If the variable isn’t found in globals() (maybe the cell wasn’t run, or the variable was deleted), you can try to parse the value directly from the code if it’s a literal.\n",
    "-   This works for things like x = 42 or y = \"hello\", but not for expressions or function calls.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- globals(): Gets the current, actual value in the notebook, including results of computations.\n",
    "- ast.literal_eval: Only works for simple literals, but is a safe fallback if the variable isn’t in globals().\n",
    "\n",
    "\n",
    "#### Write TOML files using binary\n",
    "\n",
    "We write using binary, because tomli-w is designed to work the same way as the built-in tomllib, which only reads from binary streams.\n",
    "\n",
    "This ensures consistent encoding (UTF-8) and avoids issues with text encodings across platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somewhere = \"/home/jared/lost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOML file saved to: ../tests/variables_user.toml\n"
     ]
    }
   ],
   "source": [
    "export_ipynb_toml(\"nbuse.ipynb\", \"../tests/variables_user.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then read the TOML file using the `tomllib` module by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "├── Create_markdown_table_from_a_Pydantic_dataclass\n",
      "├── Create_a_tree_structure_from_a_Python_dictionary\n",
      "  ├── movie_dict\n",
      "    ├── The Big Lebowski\n",
      "      ├── characters\n",
      "        ├── Dude\n",
      "        ├── Walter\n",
      "        ├── Donny\n",
      "      ├── setting\n",
      "        ├── location\n",
      "        ├── object\n",
      "    ├── Office Space\n",
      "      ├── characters\n",
      "        ├── Peter\n",
      "        ├── Milton\n",
      "        ├── Lumbergh\n",
      "      ├── setting\n",
      "        ├── company\n",
      "        ├── object\n",
      "    ├── The Princess Bride\n",
      "      ├── characters\n",
      "        ├── Westley\n",
      "        ├── Inigo\n",
      "      ├── setting\n",
      "        ├── location\n",
      "    ├── Labyrinth\n",
      "      ├── characters\n",
      "        ├── Sarah\n",
      "        ├── Jareth\n",
      "├── Export_notebook_variables_to_toml\n",
      "  ├── somewhere\n",
      "├── Default_nbdev_code_cells\n"
     ]
    }
   ],
   "source": [
    "with open(\"../tests/variables_user.toml\", \"rb\") as tml:\n",
    "    usr_toml = tomllib.load(tml)\n",
    "\n",
    "print_dict_structure(usr_toml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default nbdev code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
