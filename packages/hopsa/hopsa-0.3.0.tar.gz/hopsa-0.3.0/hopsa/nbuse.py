"""Utilities for working with notebooks"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/nbuse.ipynb.

# %% auto 0
__all__ = ['pydantic_to_markdown_table', 'print_dict_structure', 'export_ipynb_toml']

# %% ../nbs/nbuse.ipynb 3
import ast
import inspect
import nbformat
import tomli_w
import tomllib
from pathlib import Path
from typing import Type, Any, Optional, Dict, get_type_hints, get_origin, get_args
from pydantic import BaseModel, Field
from IPython.display import display, Markdown


# %% ../nbs/nbuse.ipynb 5
def _format_type(type_hint: Any) -> str:
    """Format a type hint into a readable string."""
    if get_origin(type_hint) is not None:
        # Handle generic types like List[str], Optional[int], etc.
        origin = get_origin(type_hint)
        args = get_args(type_hint)
        
        if origin is Union:
            # Handle Optional (Union[X, None])
            if len(args) == 2 and args[1] is type(None):
                return f"Optional[{_format_type(args[0])}]"
            else:
                return f"Union[{', '.join(_format_type(arg) for arg in args)}]"
        
        # Handle other generic types
        origin_name = origin.__name__ if hasattr(origin, "__name__") else str(origin).replace("typing.", "")
        args_str = ", ".join(_format_type(arg) for arg in args)
        return f"{origin_name}[{args_str}]"
    
    # Handle non-generic types
    if hasattr(type_hint, "__name__"):
        return type_hint.__name__
    
    return str(type_hint).replace("typing.", "")

# %% ../nbs/nbuse.ipynb 6
def _escape_table_cell(text: str) -> str:
    """
    Escape special characters in markdown table cells.
    The key is to escape pipe characters with HTML entity or backslash.
    """
    if not isinstance(text, str):
        text = str(text)
    
    # Replace pipe characters with HTML entity
    # This is the most reliable way to prevent them from being interpreted as column separators
    return text.replace("|", "\|")

# %% ../nbs/nbuse.ipynb 7
def pydantic_to_markdown_table(model_class: Type[BaseModel]) -> None:
    """
    Convert a Pydantic model class to a markdown table and display it in Jupyter notebook.
    
    Args:
        model_class: A Pydantic model class (subclass of BaseModel)
    """
    if not issubclass(model_class, BaseModel):
        raise TypeError("Input must be a Pydantic BaseModel class")
    
    md_name = f"## {model_class.__name__}\n"
    md_docstring = f"{inspect.getdoc(model_class)}\n" or ""
    
    # Get source code lines to extract comments
    try:
        source_lines = inspect.getsource(model_class).splitlines()
    except (OSError, TypeError):
        source_lines = []
    
    # Extract property comments from source code
    property_comments = {}
    for i, line in enumerate(source_lines):
        if ":" in line and "#" in line:
            # Extract property name and comment
            property_part = line.split(":")[0].strip()
            comment_part = line.split("#")[1].strip()
            property_comments[property_part] = comment_part
    
    # Start building the markdown table
    table = "\n| Variable | Type | Default | Details |\n"
    table += "|---|---|---|---|\n"
    
    # Get type hints and model fields
    type_hints = get_type_hints(model_class)
    
    # Handle both Pydantic v1 and v2
    model_fields = getattr(model_class, "model_fields", None)
    if model_fields is None:
        model_fields = getattr(model_class, "__fields__", {})
    
    # Process each field
    for field_name, field_type in type_hints.items():
        # Skip private fields and methods
        if field_name.startswith('_'):
            continue
        
        # Get field info
        field_info = None
        if model_fields and field_name in model_fields:
            field_info = model_fields[field_name]
        
        # Format type string
        type_str = _format_type(field_type)
        
        # Get default value
        default_value = "..."  # Pydantic's notation for required fields
        
        # Try to get default from field info
        if field_info:
            # For Pydantic v2
            if hasattr(field_info, "default") and field_info.default is not inspect.Signature.empty:
                default_value = _escape_table_cell(repr(field_info.default))
            # For Pydantic v1
            elif hasattr(field_info, "default") and not field_info.required:
                default_value = _escape_table_cell(repr(field_info.default))
        
        # Get description
        description = ""
        
        # Try to get description from Field
        if field_info and hasattr(field_info, "description") and field_info.description:
            description = _escape_table_cell(field_info.description)
        # Fallback to comment
        elif field_name in property_comments:
            description = _escape_table_cell(property_comments[field_name])
        
        # For nested Pydantic models, add a reference note
        if issubclass(field_type, BaseModel) if isinstance(field_type, type) else False:
            description += f" (see `{field_type.__name__}` table)"
        
        # Add row to table
        table += f"| `{field_name}` | `{type_str}` | {default_value} | {description} |\n"
    
    return display(Markdown(md_name + md_docstring + table))

# %% ../nbs/nbuse.ipynb 13
def print_dict_structure(
    d: Dict, # The dictionary that will be pretty printed
    indent=0 # The indent that is used for subkeys
    ) -> str:
    for key, value in d.items():
        print("  " * indent + f"├── {key}")
        if isinstance(value, dict):
            print_dict_structure(value, indent + 1)

# %% ../nbs/nbuse.ipynb 19
def export_ipynb_toml(
    nb_path: Optional[str] = None,
    output_path: Optional[str] = None
    ) -> None:
    """
    Export the content of the current Jupyter notebook to a TOML file.
    
    This function reads the content of the notebook where it's being executed,
    extracts all level 2 (##) markdown cells as groups, and all parameter assignments
    in code cells as key-value pairs within those groups. Regular text markdown cells are ignored.
    
    Parameters:
    -----------
    nb_path : str, optional
        Path to the notebook file. If None, the function will try to determin the
        current notebook path automatically (works in standard Jupyter but may not
        work in all environments like VS Code).
    output_path : str, optional
        Path where the TOML file should be saved. If None, the TOML file will be
        saved in the same directory as the notebook with the same name but with
        a .toml extension.
    
    Returns:
    --------
    None
    """
    if nb_path is None:
        raise ValueError(
            "Please provide the notebook_path parameter explicitly."
        )
    
    with open(nb_path, 'r', encoding='utf-8') as f:
        notebook = nbformat.read(f, as_version=4)

    if output_path is None:
        notebook_path = Path(nb_path)
        output_path = notebook_path.with_suffix('.toml')
    
    data = {}
    current_group = None
    
    for cell in notebook.cells:
        if cell.cell_type == 'markdown':
            for line in cell.source.split('\n'):
                if line.startswith('## '):
                    current_group = line[3:].strip().replace(' ', '_')
        
        elif cell.cell_type == 'code' and current_group is not None:
            try:
                tree = ast.parse(cell.source)
            except SyntaxError:
                # Skip malformed code cells
                print(f"skipped: {cell.source}")
                continue
            
            if current_group not in data:
                data[current_group] = {}
            
            for node in tree.body:
                if isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            # TODO: for some reason this doesn't work if there's a variable in the variable, like so: `v = f"{x}eny"`
                            key = target.id
                            if key.startswith('export_ipynb_'):
                                continue
                            value = globals().get(key, None)
                            if value is None:
                                try:
                                    value = ast.literal_eval(node.value)
                                except (ValueError, SyntaxError):
                                    print(f"Warning: Could not evaluate value for '{key}' in group '{current_group}'")
                                    continue
                            data[current_group][key] = value
            
    with open(output_path, 'wb') as f:
        # 'wb', because 
        tomli_w.dump(data, f)
    
    print(f"TOML file saved to: {output_path}")
