def mondip():
    #     # -*- coding: utf-8 -*-
    # """GJK.ipynb

    # Automatically generated by Colab.

    # Original file is located at
    #     https://colab.research.google.com/drive/17MUiWX6wNQoWKoMKj9JWGElm-mmowWBs

    # # P-1 numpy
    # """

    # import numpy as np
    # print(np.__version__)

    # arr1= np.array([1, 2, 3, 4, 5, 6])
    # print(arr1)
    # print(arr1.dtype)
    # print(arr1.shape)

    # arr2=np.array([[1.1, 1.2, 3.4],[2.1, 7.2, 2.3]])
    # print(arr2)
    # print(arr2.dtype)
    # print(arr2.shape)

    # lst=[[1,2,3],[11,12,13],[21,22,23],[31,32,33]]
    # arr=np.array(lst)
    # print(arr)
    # print(arr.dtype)
    # print(arr.shape)

    # print(arr[0])
    # print(arr[1,2])

    # print(arr[1,:])
    # print(arr[:,0])
    # print(arr[2,1:3])

    # x=arr[:,0:2]
    # y=arr[:,-1]
    # print(x)
    # print(y)

    # print(arr[arr%3==0])
    # print(arr[arr>10])

    # for x in arr:
    #     print(x)

    # for x in arr:
    #     for v in x:
    #         print(v)

    # ans= np.sum(arr)
    # print("Sum:",ans)
    # ans= np.min(arr)
    # print("Min:",ans)
    # ans= np.mean(arr)
    # print("Mean:",ans)
    # ans= np.median(arr)
    # print("Median:",ans)
    # ans= np.std(arr)
    # print("Standard deviation:",ans)
    # ans= np.percentile(arr, 50)
    # print("Percentile:",ans)

    # print(arr)
    # ans= np.sum(arr, axis=0)
    # print("Sum of Column:",ans)
    # ans= np.sum(arr, axis=1)
    # print("Sum of Rows:",ans)
    # ans=np.mean(arr, axis=0)
    # print("Mean of Colms")

    # """# P-2 Pandas"""

    # import pandas as pd
    # print(pd.__version__)

    # df1 = pd.DataFrame([[1, 2, 3],[7, 4, 9],[3, 9, 2],[1, 8, 4],[2, 6, 5],[5, 8, 3]])
    # print(df1)
    # print(df1.shape)

    # df1.head()

    # print(df1.head(3))

    # print(df1.tail())
    # print("Last Three recoerds")
    # print(df1.tail(3))

    # print(df1[0])

    # print(df1.iloc[1,2])
    # print(df1.iloc[2,:])
    # print(df1.iloc[:,0])
    # print(df1.iloc[1:4,1:3])

    # mydata= pd.read_csv("income_expense.csv")
    # print(mydata.shape)
    # print(mydata.head)

    # print(mydata.isnull().sum())

    # mydata.info()

    # print(mydata.mean())
    # print(mydata.median())
    # print(mydata.quantile(0.5))

    # mydata["Income"] = mydata["Income"].fillna(mydata["Income"].median())
    # mydata.isnull().sum()

    # print(mydata["Age"].mean())
    # print(mydata["Income"].median())
    # print(mydata["Expense"].quantile(0.75))

    # mydata.describe()

    # mydata.corr()

    # """# P-3 matplotlib"""

    # import matplotlib
    # print(matplotlib.__version__)

    # import matplotlib.pyplot as plt
    # import numpy as np
    # xpoints = np.array([0,2,4,6])
    # ypoints = np.array([0,75,100,250])
    # plt.title("Title of charts")
    # plt.xlabel("X - Label")
    # plt.ylabel("Y - Label")
    # plt.plot(xpoints, ypoints)
    # plt.show()

    # x = np.array([1, 3, 5, 7])
    # y = np.array([25, 85, 140, 240])
    # plt.plot(x, y, marker = 'o', ms = 10, mec = 'r', mfc = 'r', linestyle = 'dotted', color = 'b', linewidth = '3')
    # plt.show()

    # x = np.array([5, 7, 8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6])
    # y = np.array([99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86])
    # plt.scatter(x, y)
    # plt.show()

    # x = np.array(["A", "B", "C", "D"])
    # y = np.array([30, 58, 45, 60])
    # plt.bar(x, y)
    # plt.show()

    # y = np.array([15, 35, 20, 30])
    # plt.pie(y)
    # plt.show()

    # """# P-4 sklearn"""

    # import pandas as pd
    # from sklearn.linear_model import LinearRegression

    # data = pd.read_csv("Linear_Simple_Salary_Data.csv")
    # x, y = data.drop("Salary", axis=1), data["Salary"]

    # model = LinearRegression().fit(x, y)
    # print("Score:", model.score(x, y))
    # print("Predict 7.5:", model.predict([[7.5]]))
    # print("Coef:", model.coef_, "Intercept:", model.intercept_)
    # print(f"Formula: y = {model.coef_[0]} * x + {model.intercept_}")

    # import pandas as pd
    # from sklearn.preprocessing import LabelEncoder

    # # Sample data for encoding
    # mydata = pd.DataFrame([
    #     [21, 45000, "govt"],
    #     [33, 42000, "private"],
    #     [18, 30000, "semi-govt"],
    #     [36, 53000, "private"],
    #     [45, 55000, "govt"],
    #     [34, 48000, "semi-govt"]
    # ], columns=["age", "salary", "job"])

    # le = LabelEncoder()
    # encoded = le.fit_transform(mydata["job"])

    # print("Encoded jobs:", encoded)
    # print("Classes:", le.classes_)

    # from sklearn.datasets import load_breast_cancer
    # from sklearn.model_selection import train_test_split
    # from sklearn.preprocessing import MinMaxScaler, StandardScaler
    # import pandas as pd

    # bc = load_breast_cancer()
    # x, y = bc.data, bc.target
    # print("Features:", bc.feature_names)
    # print("Targets:", bc.target_names)

    # print(pd.DataFrame(x, columns=bc.feature_names)["mean radius"].describe())

    # x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)

    # mydata = pd.DataFrame([
    #     [21, 45000, "govt"], [33, 42000, "private"], [18, 30000, "semi-govt"],
    #     [36, 53000, "private"], [45, 55000, "govt"], [34, 48000, "semi-govt"]
    # ], columns=["age", "salary", "job"])

    # print("MinMax:\n", MinMaxScaler().fit_transform(mydata[["age", "salary"]]))
    # print("Standard:\n", StandardScaler().fit_transform(mydata[["age", "salary"]]))
    # print("\nJob:\n", mydata["job"])



    # """# P-5 KNN"""

    # import matplotlib.pyplot as plt
    # from sklearn.datasets import load_iris
    # from sklearn.model_selection import train_test_split
    # from sklearn.preprocessing import StandardScaler
    # from sklearn.neighbors import KNeighborsClassifier
    # from sklearn.metrics import confusion_matrix, classification_report
    # import numpy as np

    # iris = load_iris()
    # X, Y = iris.data, iris.target

    # colors = ["green", "blue", "red"]
    # for i, c in enumerate(colors):
    #     plt.scatter(X[Y==i, 2], X[Y==i, 3], color=c, marker="+")
    # plt.xlabel("Petal Length"); plt.ylabel("Petal Width"); plt.show()

    # X = StandardScaler().fit_transform(X)
    # x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)

    # model = KNeighborsClassifier(n_neighbors=33).fit(x_train, y_train)
    # y_pred = model.predict(x_test)
    # print(confusion_matrix(y_test, y_pred))
    # print(classification_report(y_test, y_pred))

    # errors = [np.mean(KNeighborsClassifier(n_neighbors=k).fit(x_train, y_train).predict(x_test) != y_test) for k in range(1, 60)]
    # plt.plot(range(1, 60), errors, 'ro--', markerfacecolor="blue")
    # plt.title("Error Rate vs. K Value"); plt.xlabel("K Value"); plt.ylabel("Mean Error"); plt.show()

    # """# P-6 Decison Tree Classifier"""

    # from sklearn.datasets import load_iris
    # from sklearn.model_selection import train_test_split
    # from sklearn.tree import DecisionTreeClassifier, plot_tree
    # from sklearn.metrics import accuracy_score
    # import matplotlib.pyplot as plt

    # x, y = load_iris(return_X_y=True)
    # x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)

    # acc = [accuracy_score(y_test, DecisionTreeClassifier(max_depth=d, random_state=0).fit(x_train, y_train).predict(x_test)) for d in range(1, 11)]
    # plt.plot(range(1, 11), acc, 'bo-')

    # model = DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=0)
    # model.fit(x_train, y_train)
    # pred = model.predict(x_test)
    # print(f"Accuracy: {accuracy_score(y_test, pred)*100:.2f}%")
    # print(f"Test sample: {x_test[3]}\nActual: {y_test[3]}, Predicted: {model.predict([x_test[3]])[0]}")

    # plt.figure(figsize=(12, 6))
    # plot_tree(model, filled=True)
    # plt.show()

    # import pandas as pd
    # import matplotlib.pyplot as plt
    # from sklearn.preprocessing import LabelEncoder
    # from sklearn.tree import DecisionTreeClassifier, plot_tree

    # df = pd.read_csv("weather_play.csv")
    # X = df.drop('play', axis=1).apply(LabelEncoder().fit_transform)
    # y = df['play']

    # model = DecisionTreeClassifier(criterion='entropy').fit(X, y)

    # print("Prediction:", model.predict([[0, 1, 1, 0]]))
    # plot_tree(model, feature_names=X.columns, class_names=model.classes_, filled=True)
    # plt.show()

    # """# P-7 KMeans"""

    # import pandas as pd
    # from sklearn.cluster import KMeans
    # from sklearn.preprocessing import MinMaxScaler
    # import matplotlib.pyplot as plt

    # df = pd.read_csv("IncomeKMean.csv")
    # df[['Income', 'Age']] = MinMaxScaler().fit_transform(df[['Income', 'Age']])

    # plt.scatter(df["Age"], df["Income"])
    # plt.xlabel("Age"); plt.ylabel("Income"); plt.show()

    # kmeans = KMeans(n_clusters=3).fit(df[['Age', 'Income']])
    # df['cluster'] = kmeans.labels_

    # colors = ['green', 'red', 'blue']
    # for i, c in enumerate(colors):
    #     plt.scatter(df[df.cluster == i].Age, df[df.cluster == i].Income, color=c, label=f'Cluster {i}')
    # plt.scatter(*kmeans.cluster_centers_.T, color='purple', marker='*', s=200, label='Centroids')
    # plt.legend(); plt.show()

    # sse = [KMeans(n_clusters=k).fit(df[['Age', 'Income']]).inertia_ for k in range(1, 10)]
    # plt.plot(range(1, 10), sse, marker='o')
    # plt.xlabel('K'); plt.ylabel('SSE'); plt.title('Elbow Method'); plt.show()

    # """# P-8 Svm"""

    # from sklearn.datasets import load_digits
    # from sklearn.model_selection import train_test_split
    # from sklearn import svm
    # from sklearn.metrics import accuracy_score

    # digits = load_digits()
    # X, y = digits.images.reshape(len(digits.images), -1), digits.target
    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # models = [
    #     svm.SVC(kernel='linear'),
    #     svm.SVC(kernel='rbf'),
    #     svm.SVC(gamma=0.003),
    #     svm.SVC(gamma=0.001, C=0.1)
    # ]

    # for i, m in enumerate(models, 1):
    #     m.fit(X_train, y_train)
    #     print(f"Model {i} accuracy: {accuracy_score(y_test, m.predict(X_test))*100:.2f}%")

    # """# P-9 Random forest"""

    # import matplotlib.pyplot as plt
    # from sklearn.datasets import load_digits
    # from sklearn.model_selection import train_test_split
    # from sklearn.ensemble import RandomForestClassifier
    # from sklearn.metrics import accuracy_score

    # digits = load_digits()
    # X, y = digits.data, digits.target

    # plt.gray(); plt.matshow(digits.images[109]); plt.show()

    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    # for n in [10, 15, 20, 25]:
    #     model = RandomForestClassifier(n_estimators=n).fit(X_train, y_train)
    #     print(f"Estimators={n} Accuracy={accuracy_score(y_test, model.predict(X_test))*100:.2f}%")

    # """# P-10 Naive Bayers"""

    # import pandas as pd
    # from sklearn.model_selection import train_test_split
    # from sklearn.naive_bayes import GaussianNB
    # from sklearn.metrics import accuracy_score

    # df = pd.read_csv("titanic.csv")
    # df['Sex'] = df['Sex'].map({'male':0,'female':1})
    # df.drop(columns=['Ticket','Cabin','Embarked','Name'], inplace=True)
    # df.dropna(inplace=True)

    # X, y = df.drop("Survived", axis=1), df["Survived"]
    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)

    # model = GaussianNB().fit(X_train, y_train)
    # print("Accuracy =", accuracy_score(y_test, model.predict(X_test))*100)

    # import pandas as pd
    # from sklearn.preprocessing import LabelEncoder
    # from sklearn.naive_bayes import CategoricalNB

    # df = pd.read_csv("weather_play.csv")
    # x, y = df.drop('play', axis=1), df['play']
    # x = x.apply(LabelEncoder().fit_transform)

    # model = CategoricalNB().fit(x, y)
    # print("Score:", model.score(x, y))
    # print("Prediction:", model.predict([[0,1,1,0]]))
    # print("Actual:", y.iloc[12])
    print("mondip")