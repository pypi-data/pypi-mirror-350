#co_tools_beta.py
from finlab import data
import finlab
import pickle
import os
import plotly.express as px
import plotly.graph_objects as go
from finlab.backtest import sim
from finlab.tools.event_study import create_factor_data
import tqdm
import numpy as np 
import pandas as pd
from finlab.dataframe import FinlabDataFrame
import cufflinks as cf
from sklearn.linear_model import LinearRegression
from datetime import datetime
from IPython.display import display, HTML
import time
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from typing import List, Tuple, Dict
import fitz  # PyMuPDF
# import df_type

db_path = "/home/sb0487/trade/finlab/finlab_db" #è³‡æ–™å„²å­˜è·¯å¾‘



"""
ç¨‹å¼ç¢¼å‚·çœ¼æ»²å…¥


"""
#è‹¥æœªä¾†ç›¸é—œå‡½å¼å¢å¤šå†é–‹ç™¼
class cofindf(FinlabDataFrame):
    @property
    def pr(self):
        # è¨ˆç®—æ¯è¡Œçš„æœ‰æ•ˆå€¼æ•¸é‡
        valid_counts = self.count(axis=1)
        valid_counts = valid_counts.replace(0, np.nan)
        rank_df = self.rank(axis=1, ascending=True, na_option='keep')
        pr_df = rank_df.div(valid_counts, axis=0) * 100
        return pr_df


#è¼‰å…¥å€----------------------------------------------------------------------------------------------------------------

class Codata():
    def __init__(self, df_type="findf", db_path="", force_download=False, 
                 html_file="tmp_finlab_report.html",
                 image_file_1="tmp_finlab_report_img1.png", 
                 image_file_2="tmp_finlab_report_img2.png"):
        # super().__init__()
        self.df_type = df_type
        self.db_path = db_path
        data.set_storage(data.FileStorage(db_path))
        data.use_local_data_only = False
        data.force_cloud_download = force_download

        #HTMLèˆ‡åœ–ç‰‡æš«å­˜
        self.html_file = html_file
        self.image_file_1 = image_file_1
        self.image_file_2 = image_file_2
    
    def get_file_path(self,file_name): 
        return os.path.join(self.db_path, file_name.replace(":", "#") + ".pickle")

    
    def get_update_time(self,filename):
        if os.path.exists(self.get_file_path(filename)):
            modification_time = os.path.getmtime(self.get_file_path(filename))
            last_modified = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modification_time))
            print(f"æœ€å¾Œæ›´æ–°æ™‚é–“: {last_modified}, {[filename]}")
        else:
            print("æª”æ¡ˆä¸å­˜åœ¨,è«‹æŸ¬æŸ¥è·¯å¾‘")

    
    def ouput_type_df(self,file_df):
        if self.df_type == "findf":
            type_df = file_df
        elif self.df_type == "cudf":
            import cudf
            type_df = cudf.DataFrame(file_df)
        elif self.df_type == "sparkdf":
            from pyspark.sql import SparkSession
            spark = SparkSession.builder.appName("Pandas to Spark DataFrame").getOrCreate()
            type_df = spark.createDataFrame(file_df)
        return type_df


    def get(self, file_name, force_download = False ):
        if not os.path.isdir(self.db_path):
            raise OSError("è³‡æ–™å¤¾è·¯å¾‘éŒ¯èª¤")

        if force_download == True:
            data.force_cloud_download = True 
            type_df = data.get(file_name)
            data.force_cloud_download = False
        else:
            type_df = data.get(file_name)
            
        #é¸æ“‡dfè¼¸å‡ºå‹æ…‹
        type_df = self.ouput_type_df(type_df)
        self.get_update_time(file_name)
        return type_df

    # @staticmethod
    # def get_update_time(filename):
    #     data.get_update_time(filename)  # è°ƒç”¨ data ç±»çš„ get_update_time æ–¹æ³•

    

#ç”¢æ¥­å€----------------------------------------------------------------------------------------------------------------
    
    #æŠŠcategoryæ‹†æˆä¸»åˆ†é¡èˆ‡ç´°åˆ†é¡
    def get_industry_pro(self):
        industry = self.get('security_industry_themes').dropna()
        def extract_majcategory(category_list):
            matching_categories = set([category.split(':')[0] for category in eval(category_list) if ':' in category])
            return str(list(matching_categories))
        
        def extract_subcategory(category_list):
            matching_categories = [category.split(':')[-1] for category in eval(category_list) if ':' in category]
            return str(matching_categories)
        
        # åº”ç”¨è‡ªå®šä¹‰å‡½æ•°åˆ° DataFrame çš„æ¯ä¸€è¡Œ
        industry['maj_category'] = industry['category'].apply(extract_majcategory)
        industry['sub_category'] = industry['category'].apply(extract_subcategory)
        
        return industry

    
    def show_industry(self):
        industry = self.get_industry_pro()
        sub_category_counts_df = pd.DataFrame(industry['sub_category'].apply(eval).explode('sub_category').value_counts()).reset_index()
        maj_category_counts_df = pd.DataFrame(industry['maj_category'].apply(eval).explode('maj_category').value_counts()).reset_index()
        
        industry["maj_category"] = industry["maj_category"].apply(eval)
        industry["sub_category"] = industry["sub_category"].apply(eval)
        industry_explode = industry.explode('maj_category').explode('sub_category')
        industry_explode["count"] = 1
        
        fig = px.treemap(industry_explode, path=[px.Constant("å°è‚¡ç”¢æ¥­ç¸½ç¸½è¦½"), "maj_category", "sub_category","name"], values='count')
        fig.update_layout(
            margin=dict(t=1, l=1, r=1, b=1)
        )
        
        fig.show()
        return maj_category_counts_df,sub_category_counts_df
    
    def filter_industry(self,file_df, keyword_list, category_type = "maj_category", remove_or_add="remove", exact_or_fuzzy="fuzzy"):
        industry_pro = self.get_industry_pro()
        
        if exact_or_fuzzy == "fuzzy":
            if remove_or_add == "remove":
                
                file_filtered_df = (file_df
                    .loc[:, ~file_df.columns.isin(
                        industry_pro[industry_pro[category_type]
                        .apply(lambda x: bool(set(eval(x)) & set(keyword_list)))]['stock_id']
                        .tolist())]
                )
           
            elif remove_or_add == "add":
                file_filtered_df = (file_df
                    .loc[:, file_df.columns.isin(
                        industry_pro[industry_pro[category_type]
                        .apply(lambda x: bool(set(eval(x)) & set(keyword_list)))]['stock_id']
                        .tolist())]
                )
    
        
        if exact_or_fuzzy == "exact":
            if remove_or_add == "remove": # å®Œå…¨ä¸€æ¨£æ‰ç§»é™¤
                
                file_filtered_df = (file_df
                    .loc[:, ~file_df.columns.isin(
                        industry_pro[industry_pro[category_type]
                        .apply(lambda x: bool(set(eval(x)) == set(keyword_list)))]['stock_id']
                        .tolist())]
                )
    
            elif remove_or_add == "add": # å®Œå…¨ä¸€æ¨£æ‰åŠ å…¥
                file_filtered_df = (file_df
                    .loc[:, file_df.columns.isin(
                        industry_pro[industry_pro[category_type]
                        .apply(lambda x: bool(set(eval(x)) == set(keyword_list)))]['stock_id']
                        .tolist())]
                )
        
        return file_filtered_df



    
    
    #æŠŠcategoryæ‹†æˆä¸»åˆ†é¡èˆ‡ç´°åˆ†é¡
    def get_industry_pro(self):
        industry = self.get('security_industry_themes').dropna()
        def extract_majcategory(category_list):
            matching_categories = set([category.split(':')[0] for category in eval(category_list) if ':' in category])
            return str(list(matching_categories))
        
        def extract_subcategory(category_list):
            matching_categories = [category.split(':')[-1] for category in eval(category_list) if ':' in category]
            return str(matching_categories)
        
        # åº”ç”¨è‡ªå®šä¹‰å‡½æ•°åˆ° DataFrame çš„æ¯ä¸€è¡Œ
        industry['maj_category'] = industry['category'].apply(extract_majcategory)
        industry['sub_category'] = industry['category'].apply(extract_subcategory)
        
        return industry

#ä¾¿åˆ©å·¥å…·å€----------------------------------------------------------------------------------------------------------------

        # def month_forward_sell(self,forward_days = 1):
        #     exits_df = self.get('price:æ”¶ç›¤åƒ¹')<0
        #     def update_row(row):
        #         if row.name in self.monthly_revenue.index:
        #             return True
        #         else:
        #             return row
        
        #     rev_date = exits_df.apply(update_row, axis=1)
        #     rev_date_shifted = rev_date.shift(-1)
        #     for i in range(1,forward_days+1):
        #         rev_date_shifted_n = rev_date.shift(-i)
        #         rev_date_shifted = rev_date_shifted  | rev_date_shifted_n
                
        return rev_date_shifted
    
    #æŠŠæ—¥è³‡æ–™è½‰æˆæœˆè³‡æ–™(ç‡Ÿæ”¶ç™¼å¸ƒæˆªæ­¢æ—¥),ä»–å€‘æœ‰èªªä¹‹å¾Œæœƒæ”¹æˆé›»å­æª”ä¸Šå‚³æ—¥
    def day_to_month(self,file_df):
        monthly_index_df = FinlabDataFrame(index=self.get("monthly_revenue:ç•¶æœˆç‡Ÿæ”¶").index)
        file_df  = monthly_index_df.join(file_df, how='left')
        return file_df

    def to_day(self,file_df):
        monthly_index_df = FinlabDataFrame(index=self.get('price:æ”¶ç›¤åƒ¹').index)
        file_df  = monthly_index_df.join(file_df, how='left')
        return file_df
    
    #è½‰ç‚ºæ—¥è³‡æ–™ä¸¦è—‰ç”±è³‡æ–™ç•°å‹•æ™‚é–“é»ä¿ç•™è²¡å ±ç™¼å¸ƒæ—¥è³‡è¨Š(index_str_to_dateæœƒå‘ä¸‹å¡«æ»¿)    
    def q_to_day(self,file_df):
        file_df =file_df.index_str_to_date()
        file_df =file_df.where(file_df.ne(file_df.shift()), np.nan)
        day_index_df = FinlabDataFrame(index=self.get('price:æ”¶ç›¤åƒ¹').index)
        c = pd.concat([file_df,day_index_df])
        file_df = FinlabDataFrame(c[~c.index.duplicated()].sort_index())
        return file_df
        
    def get_pr(self, file_df):
        # è¨ˆç®—æ¯è¡Œçš„æœ‰æ•ˆå€¼æ•¸é‡
        valid_counts = file_df.count(axis=1)
        valid_counts[valid_counts == 0] = np.nan
        rank_df = file_df.rank(axis=1, ascending=True, na_option='keep')
        pr_df = rank_df.div(valid_counts, axis=0) * 100
        
        return pr_df
   
    def display_report_statis(self, file_df):
        mean_return = file_df["return"].mean()
        return_std = file_df["return"].std()
        mean_period = file_df["period"].mean()
        
        # è¤‡åˆ©å ±é…¬ç‡è¨ˆç®—
        log_return_mean = mean_return - 0.5 * (return_std ** 2)
        periods_per_year = 240 / mean_period
        annual_compound_return = (1 + log_return_mean) ** periods_per_year - 1
        
        # è¨ˆç®—å‹ç‡
        win_rate = (file_df["return"] > 0).mean()
        
        # çµ„æˆ JSON è³‡æ–™ (å°æ•¸ä½æ•¸æ¯”ç…§ HTML)
        stats_json = {
            "äº¤æ˜“ç­†æ•¸": len(file_df),
            "å¹³å‡å ±é…¬ç‡": f"{mean_return * 100:.2f}%",  # 3ä½å°æ•¸è½‰ç™¾åˆ†æ¯” = 1ä½å°æ•¸
            "å¹³å‡MDD": f"{file_df['mdd'].mean():.3f}",
            "å ±é…¬ç‡æ¨™æº–å·®": f"{return_std:.3f}",
            "å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥)": f"{mean_period:.3f}",
            "å‹ç‡": f"{win_rate * 100:.2f}%",  # 3ä½å°æ•¸è½‰ç™¾åˆ†æ¯” = 1ä½å°æ•¸
            "æœ€å¤§å¹´åŒ–å ±é…¬ç‡(æ³¢å‹•èª¿æ•´_æ³°å‹’å±•é–‹)": f"{annual_compound_return * 100:.2f}%"  # 3ä½å°æ•¸è½‰ç™¾åˆ†æ¯” = 1ä½å°æ•¸
        }
        
        html_content = """
        <sorry style="font-size: larger;">äº¤æ˜“çµ±è¨ˆ</sorry>
        <ul>
          <li>äº¤æ˜“ç­†æ•¸: {}</li>
          <li>å¹³å‡å ±é…¬ç‡: {}</li>
          <li>å¹³å‡MDD: {}</li>
          <li>å ±é…¬ç‡æ¨™æº–å·®: {}</li>
          <li>å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥): {}</li>
          <li>å‹ç‡: {}</li>
          <li>æœ€å¤§å¹´åŒ–å ±é…¬ç‡(æ³¢å‹•èª¿æ•´_æ³°å‹’å±•é–‹): {}</li>
        </ul>
        """.format(len(file_df),
                   stats_json["å¹³å‡å ±é…¬ç‡"],
                   stats_json["å¹³å‡MDD"],
                   stats_json["å ±é…¬ç‡æ¨™æº–å·®"],
                   stats_json["å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥)"],
                   stats_json["å‹ç‡"],
                   stats_json["æœ€å¤§å¹´åŒ–å ±é…¬ç‡(æ³¢å‹•èª¿æ•´_æ³°å‹’å±•é–‹)"])
        
        display(HTML(html_content))
        return stats_json
#çˆ¬èŸ²å€----------------------------------------------------------------------------------------------------------------------
    
    #çˆ¬å¹´å ±
    def crawl_annual_report_(self,year,symbol,save_dir,sleep = 2):
        #init
        chrome_options = Options()
        chrome_options.add_argument("--headless")  # ç„¡é ­æ¨¡å¼
        year = str(year)
        symbol = str(symbol)
        
    
        d = webdriver.Chrome(options=chrome_options)
        d.maximize_window()
    
        try:
            while True:
                d.get(f'https://doc.twse.com.tw/server-java/t57sb01?step=1&colorchg=1&co_id={symbol}&year={year}&mtype=F&dtype=F04&') 
                time.sleep(sleep)
                
                page_content = d.page_source
                if "æŸ¥è©¢éé‡" in page_content:
                    print(f"ç•¶å‰è‚¡ç¥¨ç‚º{symbol},æŸ¥è©¢éé‡ï¼Œè¢«è­‰äº¤æ‰€æª”ä¸‹ï¼Œä¼‘æ¯10ç§’")
                    time.sleep(10)
                    continue  
                else:
                    break  # å¦‚æœæ²¡æœ‰æŸ¥è©¢éé‡ï¼Œé€€å‡ºå¾ªç¯
    
            pdf_link = d.find_element(By.XPATH, "//a[contains(@href, 'javascript:readfile2') and contains(@href, 'F04')]")
            pdf_link.click()
            time.sleep(sleep)
        
            # åˆ‡æ›åˆ†é 
            all_tabs = d.window_handles
            d.switch_to.window(all_tabs[1])
            time.sleep(sleep)
    
            
            # æ‰¾åˆ°pdfé€£çµ,æ³¨æ„æ­¤é€£çµç‚ºä¸å®šæ™‚æµ®å‹•
            pdf_link2 = d.find_element(By.XPATH, "//a[contains(@href, '.pdf')]")
            pdf_url = pdf_link2.get_attribute('href')
        
            
            # å»ºæ§‹dir(è‹¥ç„¡),ä¿å­˜pdf
            os.makedirs(save_dir, exist_ok=True)
            file_name = f"{year}_{symbol}.pdf" 
            file_path = os.path.join(save_dir, file_name)
            
            # ä¸‹è½½ PDF æ–‡ä»¶å¹¶ä¿å­˜
            response = requests.get(pdf_url)
            with open(file_path, "wb") as file:
                file.write(response.content)
            print(f"PDF æ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")
            failed_symbol =None
            
        except ModuleNotFoundError as e:
            print(f"Module not found error: {e}")
            
        except NameError as e:
            print(f"Name not defined error: {e}") 
            
        except Exception as e:
            print(f"{symbol}_{year}å¹´å¹´å ±æœªæ‰¾åˆ°")
            failed_symbol = symbol
            
        finally:
            d.quit()
            
        return failed_symbol
    #çˆ¬å¹´å ±,å¤šå€‹
    def crawl_annual_reports(self,year,stock_list,save_dir,sleep = 2):
        failed_list = list(filter(None, (self.crawl_annual_report_(year, x, save_dir, sleep) for x in stock_list)))
        return failed_list
        
    #çˆ¬å­£å ±
    def crawl_quarterly_report_(self,year,quarter,symbol,save_dir,sleep = 2):
        
        #init
        chrome_options = Options()
        chrome_options.add_argument("--headless")  # ç„¡é ­æ¨¡å¼
        year = str(year)
        symbol = str(symbol)
        format_quarter = "0"+str(quarter)
        ad = str(int(year)+1911)
        # åˆå§‹åŒ–Chromeç€è¦½å™¨
        # driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        
    
        d = webdriver.Chrome(options=chrome_options)
        d.maximize_window()
    
        try:
            while True:
                d.get(f'https://doc.twse.com.tw/server-java/t57sb01?step=1&colorchg=1&co_id={symbol}&year={year}&seamon=&mtype=A&dtype=AI1&') 
                time.sleep(sleep)
                
                page_content = d.page_source
                if "æŸ¥è©¢éé‡" in page_content:
                    print(f"ç•¶å‰è‚¡ç¥¨ç‚º{symbol},æŸ¥è©¢éé‡ï¼Œè¢«è­‰äº¤æ‰€æª”ä¸‹ï¼Œä¼‘æ¯10ç§’")
                    time.sleep(10)
                    continue  
                else:
                    break  # å¦‚æœæ²¡æœ‰æŸ¥è©¢éé‡ï¼Œé€€å‡ºå¾ªç¯
           
            pdf_name = f"{ad}{format_quarter}_{symbol}_AI1.pdf"
            pdf_link = d.find_element(By.XPATH, f"//a[contains(@href, 'javascript:readfile2') and contains(@href,'{pdf_name}')]")
            pdf_link.click()
            time.sleep(sleep)
        
            # åˆ‡æ›åˆ†é 
            all_tabs = d.window_handles
            d.switch_to.window(all_tabs[1])
            time.sleep(sleep)
    
            # æ‰¾åˆ°pdfé€£çµ,æ³¨æ„æ­¤é€£çµç‚ºä¸å®šæ™‚æµ®å‹•
            pdf_link2 = d.find_element(By.XPATH, "//a[contains(@href, '.pdf')]")
            pdf_url = pdf_link2.get_attribute('href')
        
            
            # å»ºæ§‹dir(è‹¥ç„¡),ä¿å­˜pdf
            os.makedirs(save_dir, exist_ok=True)
            file_name = f"{year}_Q{quarter}_{symbol}.pdf" 
            file_path = os.path.join(save_dir, file_name)
            
            # ä¸‹è½½ PDF æ–‡ä»¶å¹¶ä¿å­˜
            response = requests.get(pdf_url)
            with open(file_path, "wb") as file:
                file.write(response.content)
            print(f"PDF æ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")
            failed_symbol =None
            
        except ModuleNotFoundError as e:
            print(f"Module not found error: {e}")
            
        except NameError as e:
            print(f"Name not defined error: {e}") 
        
        except:
            print(f"{symbol}_{year}_Q{quarter}å­£å ±æœªæ‰¾åˆ°")
            failed_symbol = symbol
            
        finally:
            d.quit()
        return failed_symbol
    #çˆ¬å­£å ±,å¤šå€‹
    def crawl_quarterly_reports(self,year,quarter,stock_list,save_dir,sleep = 2):
        failed_list = list(filter(None, (self.crawl_quarterly_report_(year,quarter, x, save_dir, sleep) for x in stock_list)))
        return failed_list


    #ç”¨save_diræŠ“ä¸‹ä¾†çš„æª”æ¡ˆèˆ‡å…¨éƒ¨çš„è‚¡ç¥¨ä»£è™Ÿæ¸…å–®all_stock_listæ¯”è¼ƒ,æ‰¾å‡ºå°šæœªä¸‹è¼‰çš„pdf
    def get_undownloaded_stocks(self,save_dir,all_stock_list):
        download_stock_list = [f.split('.')[0][-4:] for f in os.listdir(save_dir) if os.path.isfile(os.path.join(save_dir, f))]
        result = [elem for elem in all_stock_list if elem not in download_stock_list]
        return result

#è®€æª”pdfå€----------------------------------------------------------------------------------------------------------------------
    
    #ç”¨sparkåˆ†æ•£å¼è®€å–
    def load_pdf_spark(self,stock_list,pdf_path,memory = "5g"):
        from pyspark.sql import SparkSession
        
        # èµ· Spark
        spark = SparkSession.builder.appName("Read PDFs with Spark")\
        .config("spark.driver.memory", memory)\
        .config("spark.driver.maxResultSize", memory)\
        .getOrCreate() # å…§å­˜å¤§å°
    
        def process_pdf(filename):
            if filename.endswith('.pdf'):
                #stock_symbol = filename.split('_')[1].split('.')[0] # åˆ†å‰²,å–å‡ºè‚¡ç¥¨ä»£è€—
                stock_symbol = filename.split('.')[0][-4:]
                if stock_symbol in stock_list: 
                    file_path = os.path.join(pdf_path, filename)
                    content = "".join(page.get_text() for page in fitz.open(file_path)) #æ‰“é–‹pdf, é€è¡Œè®€å–ä¸¦åˆä½µ
                    return stock_symbol, content
    
        # ä½¿ç”¨ Spark è®€å–æ¯å€‹ PDF æ–‡ä»¶
        pdf_contents = spark.sparkContext.parallelize(os.listdir(pdf_path)).map(process_pdf).filter(lambda x: x).collect()
        
        # å°‡çµæœè½‰æ›ç‚º Pandas DataFrame
        pdf_df = pd.DataFrame(pdf_contents, columns=["Stock Symbol", "PDF Content"]).set_index("Stock Symbol")
        return pdf_df

    #å–®ç·šç¨‹è®€å–
    def load_pdf(self,stock_list, pdf_path):
        def process_pdf(filename):
            if filename.endswith('.pdf'):
                stock_symbol = filename.split('.')[0][-4:]
                if stock_symbol in stock_list:
                    file_path = os.path.join(pdf_path, filename)
                    content = "".join(page.get_text() for page in fitz.open(file_path))  
                    return stock_symbol, content
        
        pdf_contents = [process_pdf(filename) for filename in os.listdir(pdf_path) if filename.endswith('.pdf')]
        pdf_contents = [item for item in pdf_contents if item is not None]
        
        # å°†ç»“æœè½¬æ¢ä¸º Pandas DataFrame
        pdf_df = pd.DataFrame(pdf_contents, columns=["Stock Symbol", "PDF Content"]).set_index("Stock Symbol")
        return pdf_df

#ç›¸é—œä¿‚æ•¸å€----------------------------------------------------------------------------------------------------------------------

    # ç›¸é—œæ•¸æ’å
    def get_corr_ranked(self,stock_symbol: str, close: pd.DataFrame) -> None:
        stock_symbol = str(stock_symbol)
        correlation_with_target = close.corr()[stock_symbol].drop(stock_symbol)
        most_related = correlation_with_target.nlargest(30)
        least_related = correlation_with_target.nsmallest(30)
        
        for title, data in [("Most", most_related), ("Least", least_related)]:
            fig = px.bar(data, title=f'Top 30 Stocks {title} Related to {stock_symbol}', labels={'value': 'Correlation', 'index': 'Stocks'})
            fig.show()

    # æ™‚é–“åºåˆ—æ¯”è¼ƒåœ–
    def get_tm_series_chart(self,stock_symbols: list, close: pd.DataFrame, lag: int = 0) -> None:
        stock1, stock2 = map(str, stock_symbols)
        
        if lag > 0:
            shifted_stock2 = close[stock2].shift(lag)
            valid_idx = ~shifted_stock2.isna()
            stock2_values = shifted_stock2[valid_idx]
            stock1_values = close[stock1][valid_idx]
        else:
            stock1_values = close[stock1]
            stock2_values = close[stock2]
        
        correlation = stock1_values.corr(stock2_values)
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(x=close.index, y=close[stock1], mode='lines', name=stock1, yaxis='y1'))
        fig.add_trace(go.Scatter(x=close.index, y=shifted_stock2 if lag > 0 else close[stock2], mode='lines', name=f'{stock2} (lag={lag})', yaxis='y2'))
        
        fig.update_layout(
            title=f'æ™‚é–“åºåˆ—æ¯”è¼ƒåœ– (lag={lag}, correlation={correlation:.2f})',
            xaxis=dict(title='æ—¥æœŸ'),
            yaxis=dict(title=f'{stock1} æ”¶ç›¤åƒ¹', side='left'),
            yaxis2=dict(title=f'{stock2} æ”¶ç›¤åƒ¹', side='right', overlaying='y')
        )
        
        fig.show()

#å› å­æ¸¬è©¦å€----------------------------------------------------------------------------------------------------------------------



    def get_quartertly_factor_analysis(self,factor_list: List[str], pr: Tuple[int, int], n_high_or_low: int)-> pd.DataFrame:
        close = self.get('price:æ”¶ç›¤åƒ¹')
        market_value = self.get('etl:market_value')
        
        # Initialize DataFrame to store results
        factor_report_df_all = pd.DataFrame(columns=[
            "å› å­åç¨±", "ç­–ç•¥æ¢ä»¶", "PR_Range", "é™åˆ¶å› å­æ•¸å€¼æ­£è² ", "å‰µnæœŸé«˜orä½", "ç¸½äº¤æ˜“ç­†æ•¸", 
            "ç­–ç•¥å¹´åŒ–å ±é…¬ç‡", "ç­–ç•¥MDD", "ç­–ç•¥sortino(æ—¥)", "å€‹è‚¡å¹³å‡å ±é…¬ç‡", "å€‹è‚¡å¹³å‡MDD", 
            "å€‹è‚¡å ±é…¬ç‡æ¨™æº–å·®", "å€‹è‚¡å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥)", "å€‹è‚¡å¹³å‡è™•æ–¼ç²åˆ©å¤©æ•¸", 
            "å€‹è‚¡æœ€å¤§å¹´åŒ–è¤‡åˆ©å ±é…¬"
        ])
    
        def calculate_factor_report(conditions: pd.DataFrame, factor_name: str, strategy_type: str, pr: Tuple[int, int], pn: str, n_high_or_low: int):
            pr_range = np.nan
            if strategy_type in ["qoq", "yoy", "factor_market_value_ratio","origin_value"]:
                n_high_or_low = np.nan
                pr_range = f"{pr[0]}-{pr[1]}"
            
            try:
                # Simulate strategy and generate report
                report = sim(position=conditions, position_limit=1, fee_ratio=1.425/1000*0.2, trade_at_price="open",upload=False)
                trades = report.get_trades()
                
                report_data = {
                    'å› å­åç¨±': factor_name,
                    'ç­–ç•¥æ¢ä»¶': strategy_type,
                    'PR_Range': pr_range,
                    'é™åˆ¶å› å­æ•¸å€¼æ­£è² ': pn,
                    'å‰µnæœŸé«˜orä½': n_high_or_low,
                    'ç¸½äº¤æ˜“ç­†æ•¸': len(trades),
                    'ç­–ç•¥å¹´åŒ–å ±é…¬ç‡': report.get_stats()["cagr"],
                    'ç­–ç•¥MDD': report.get_stats()["max_drawdown"],
                    'ç­–ç•¥sortino(æ—¥)': report.get_stats()["daily_sortino"],
                    'å€‹è‚¡å¹³å‡å ±é…¬ç‡': trades["return"].mean(),
                    'å€‹è‚¡å¹³å‡MDD': trades["mdd"].mean(),
                    'å€‹è‚¡å ±é…¬ç‡æ¨™æº–å·®': trades["return"].std(),
                    'å€‹è‚¡å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥)': trades["period"].mean(),
                    'å€‹è‚¡å¹³å‡è™•æ–¼ç²åˆ©å¤©æ•¸': trades["pdays"].mean(),
                    'å€‹è‚¡æœ€å¤§å¹´åŒ–è¤‡åˆ©å ±é…¬': (1 + trades["return"].mean()) ** (240 / trades["period"].mean()) - 1,
                }
                return pd.DataFrame([report_data])
            except Exception:
                return None
    
        def generate_conditions(factor_df : pd.DataFrame, strategy_type: str, pr: Tuple[int, int], pn: str, n_high_or_low: int):
            pr_down, pr_up = pr
            conditions = None
            
            if pn == "pos":
                if strategy_type == "qoq":
                    conditions = (
                        (self.get_pr(factor_df / factor_df.shift(1)) > pr_down) & 
                        (self.get_pr(factor_df / factor_df.shift(1)) < pr_up) &
                        (factor_df > 0) & (close > 0)
                    )
                elif strategy_type == "yoy":
                    conditions = (
                        (self.get_pr(factor_df / factor_df.shift(4)) > pr_down) & 
                        (self.get_pr(factor_df / factor_df.shift(4)) < pr_up) &
                        (factor_df > 0) & (close > 0)
                    )
                elif strategy_type == "higest":
                    conditions = (factor_df == factor_df.rolling(n_high_or_low).max()) & (factor_df > 0) & (close > 0)
                elif strategy_type == "factor_market_value_ratio":
                    factor_market_value_ratio = factor_df / market_value
                    conditions = (
                        (self.get_pr(factor_market_value_ratio / factor_market_value_ratio.shift(4)) > pr_down) & 
                        (self.get_pr(factor_market_value_ratio / factor_market_value_ratio.shift(4)) < pr_up) &
                        (factor_df > 0) & (close > 0)
                    )
                elif strategy_type == "lowest":
                    conditions = (factor_df == factor_df.rolling(n_high_or_low).min()) & (factor_df > 0) & (close > 0)
                elif strategy_type == "origin_value":
                    conditions = (self.get_pr(factor_df)>pr_down) & (self.get_pr(factor_df)<pr_up)& (factor_df > 0) & (close > 0)
                    
            elif pn == "neg":
                if strategy_type == "qoq":
                    conditions = (
                        (self.get_pr(factor_df / factor_df.shift(1)) > pr_down) & 
                        (self.get_pr(factor_df / factor_df.shift(1)) < pr_up) &
                        (factor_df < 0) & (close > 0)
                    )
                elif strategy_type == "yoy":
                    conditions = (
                        (self.get_pr(factor_df / factor_df.shift(4)) > pr_down) & 
                        (self.get_pr(factor_df / factor_df.shift(4)) < pr_up) &
                        (factor_df < 0) & (close > 0)
                    )
                elif strategy_type == "higest":
                    conditions = (factor_df == factor_df.rolling(n_high_or_low).max()) & (factor_df < 0) & (close > 0)
                elif strategy_type == "factor_market_value_ratio":
                    factor_market_value_ratio = factor_df / market_value
                    conditions = (
                        (self.get_pr(factor_market_value_ratio / factor_market_value_ratio.shift(4)) > pr_down) & 
                        (self.get_pr(factor_market_value_ratio / factor_market_value_ratio.shift(4)) < pr_up) &
                        (factor_df < 0) & (close > 0)
                    )
                elif strategy_type == "lowest":
                    conditions = (factor_df == factor_df.rolling(n_high_or_low).min()) & (factor_df < 0) & (close > 0)
                elif strategy_type == "origin_value":
                    conditions = (self.get_pr(factor_df)>pr_down) & (self.get_pr(factor_df)<pr_up)& (factor_df < 0) & (close > 0)
                    
            return conditions
    
        def run_factor_analysis(factor_list, strategy_types, pos_neg_options, pr, n_high_or_low):
            factor_report_df_all = pd.DataFrame()
            for factor in factor_list:
                factor_df = self.get(factor)
                factor_name = factor.split(":")[1]
                
                for strategy_type in strategy_types:
                    for pn in pos_neg_options:
                        conditions = generate_conditions(factor_df, strategy_type, pr, pn, n_high_or_low)
                        report_df = calculate_factor_report(conditions, factor_name, strategy_type, pr, pn, n_high_or_low)
                        
                        if report_df is not None:
                            factor_report_df_all = pd.concat([factor_report_df_all, report_df])
            
            return factor_report_df_all
    
        # Run the analysis loop
        strategy_types = ["qoq", "yoy", "higest", "factor_market_value_ratio", "lowest","origin_value"]
        pos_neg_options = ["pos", "neg"]
        factor_report_df_all = run_factor_analysis(factor_list, strategy_types, pos_neg_options, pr, n_high_or_low)
        
        return factor_report_df_all.reset_index(drop=True)



#tg----------------------------------------------------------------------------------------------------------------------


# åœ¨ co_tools_beta.py çš„ Codata é¡ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•

    def tg_extract_position_info(self, report):
        """æå–æŒå€‰è³‡è¨Š
        
        Args:
            report: finlab å›æ¸¬å ±å‘Šç‰©ä»¶
            
        Returns:
            tuple: (é€²å ´è‚¡ç¥¨åˆ—è¡¨, æŒæœ‰è‚¡ç¥¨åˆ—è¡¨, å‡ºå ´è‚¡ç¥¨åˆ—è¡¨, æœ€å¾Œæ—¥æœŸ)
        """
        trades = report.get_trades()
        last_date = report.daily_benchmark.index[-1]
        position_info = report.position_info2()
        
        if isinstance(position_info, dict) and 'positions' in position_info:
            positions = position_info['positions']
        else:
            positions = []
        
        enter_stocks = []
        hold_stocks = []
        exit_stocks = []
        
        for position in positions:
            if not isinstance(position, dict):
                continue
                
            asset_id = position.get('assetId', '')
            asset_name = position.get('assetName', '')
            stock_display = f"{asset_id} {asset_name}" if asset_id and asset_name else (asset_id or asset_name)
            
            action_type = position.get('action', {}).get('type', '')
            current_weight = position.get('currentWeight', 0)
            
            # å¿½ç•¥éå»çš„äº¤æ˜“è¨˜éŒ„
            if action_type == 'exit_p':
                continue
                
            # æ ¹æ“šå‹•ä½œé¡å‹åˆ†é¡
            if action_type == 'entry':
                enter_stocks.append(stock_display)
            elif current_weight != 0:
                hold_stocks.append(stock_display)
                if action_type == 'exit':
                    exit_stocks.append(stock_display)
        
        return enter_stocks, hold_stocks, exit_stocks, last_date
    
    def tg_generate_strategy_message(self, report, strategy_config):
        """ç”Ÿæˆç­–ç•¥ Telegram è¨Šæ¯
        
        Args:
            report: finlab å›æ¸¬å ±å‘Šç‰©ä»¶
            strategy_config: ç­–ç•¥é…ç½®å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹éµå€¼ï¼š
                - name: ç­–ç•¥åç¨±
                - description: ç­–ç•¥èªªæ˜
                - author: ç­–ç•¥ä½œè€…
                - direction: ç­–ç•¥å¤šç©ºæ–¹å‘ (å¤š/ç©º)
                - notes: ç­–ç•¥å‚™è¨» (å¯é¸)
                - enter_label: é€²å ´æ¨™ç±¤ (å¯é¸)
                - hold_label: æŒå€‰æ¨™ç±¤ (å¯é¸)
                - exit_label: å‡ºå ´æ¨™ç±¤ (å¯é¸)
                
        Returns:
            str: æ ¼å¼åŒ–çš„ Telegram è¨Šæ¯
        """
        # æå–æŒå€‰è³‡è¨Š
        trades = report.get_trades()
        enter_stocks, hold_stocks, exit_stocks, last_date = self.tg_extract_position_info(report)
        
        # ç²å–çµ±è¨ˆæ•¸æ“š
        stats_dict = self.display_report_statis(trades)
        
        # è™•ç†ç­–ç•¥é…ç½®é è¨­å€¼
        direction = strategy_config.get('direction', 'å¤š')
        notes = strategy_config.get('notes', '')
        
        # æ ¹æ“šå¤šç©ºæ–¹å‘è¨­å®šæ¨™ç±¤
        if direction == 'ç©º':
            enter_label = strategy_config.get('enter_label', 'æ”¾ç©ºè‚¡ç¥¨')
            exit_label = strategy_config.get('exit_label', 'å›è£œè‚¡ç¥¨')
        else:
            enter_label = strategy_config.get('enter_label', 'è²·å…¥è‚¡ç¥¨')
            exit_label = strategy_config.get('exit_label', 'è³£å‡ºè‚¡ç¥¨')
        
        hold_label = strategy_config.get('hold_label', 'ç•¶å‰æŒå€‰')
        
        # ç”Ÿæˆè¨Šæ¯
        msg = f"""ğŸ””ğŸ””ğŸ””<b>ç­–ç•¥é€šçŸ¥</b>
<pre>ç­–ç•¥åç¨±: {strategy_config['name']}
ç­–ç•¥èªªæ˜: {strategy_config['description']}
ç­–ç•¥ä½œè€…: {strategy_config['author']}
ç­–ç•¥å¤šç©º: {direction}
ç­–ç•¥å‚™è¨»: {notes}

é å®šæ›è‚¡æ—¥: {last_date}

ğŸ“ˆ
{enter_label}: {enter_stocks}
{hold_label}: {hold_stocks}
{exit_label}: {exit_stocks}

ğŸ”¢
ç¸½äº¤æ˜“ç­†æ•¸: {stats_dict["äº¤æ˜“ç­†æ•¸"]}
å¹³å‡å ±é…¬ç‡: {stats_dict["å¹³å‡å ±é…¬ç‡"]}
å¹³å‡æŒæœ‰å¤©æ•¸: {stats_dict["å¹³å‡æŒæœ‰æœŸé–“(äº¤æ˜“æ—¥)"]}
å‹ç‡: {stats_dict["å‹ç‡"]}
æœ€å¤§å¹´åŒ–å ±é…¬ç‡(æ³¢å‹•èª¿æ•´_æ³°å‹’å±•é–‹): {stats_dict["æœ€å¤§å¹´åŒ–å ±é…¬ç‡(æ³¢å‹•èª¿æ•´_æ³°å‹’å±•é–‹)"]}</pre>"""
 
        
        return msg.strip()
    
    def tg_create_strategy_message_quick(self, report, strategy_name, strategy_description, 
                                    strategy_author, strategy_direction="å¤š", 
                                    strategy_notes="", **kwargs):
        """å¿«é€Ÿå‰µå»ºç­–ç•¥è¨Šæ¯çš„ä¾¿åˆ©æ–¹æ³•
        
        Args:
            report: finlab å›æ¸¬å ±å‘Š
            strategy_name: ç­–ç•¥åç¨±
            strategy_description: ç­–ç•¥èªªæ˜
            strategy_author: ç­–ç•¥ä½œè€…
            strategy_direction: ç­–ç•¥æ–¹å‘ (å¤š/ç©º)
            strategy_notes: ç­–ç•¥å‚™è¨»
            **kwargs: å…¶ä»–è‡ªå®šç¾©æ¨™ç±¤
            
        Returns:
            str: æ ¼å¼åŒ–çš„ Telegram è¨Šæ¯
        """
        strategy_config = {
            'name': strategy_name,
            'description': strategy_description,
            'author': strategy_author,
            'direction': strategy_direction,
            'notes': strategy_notes,
            **kwargs
        }
        
        return self.tg_generate_strategy_message(report, strategy_config)

    def tg_capture_report_images(self, html_filename=None, 
                                 output_image1=None,
                                 output_image2=None):
        """
        åŒæ­¥ç‰ˆæœ¬çš„ HTML è½‰åœ–ç‰‡æ–¹æ³•
        
        Args:
            html_filename: HTML æª”æ¡ˆåç¨± (None å‰‡ä½¿ç”¨é è¨­)
            output_image1: ç¬¬ä¸€å¼µæˆªåœ–æª”å (None å‰‡ä½¿ç”¨é è¨­)
            output_image2: ç¬¬äºŒå¼µæˆªåœ–æª”å (None å‰‡ä½¿ç”¨é è¨­)
        """
        import asyncio
        
        # ä½¿ç”¨é è¨­å€¼æˆ–å‚³å…¥å€¼
        html_filename = html_filename or self.html_file
        output_image1 = output_image1 or self.image_file_1
        output_image2 = output_image2 or self.image_file_2
        
        if not os.path.exists(html_filename):
            print(f"éŒ¯èª¤: HTML æª”æ¡ˆ '{html_filename}' ä¸å­˜åœ¨")
            return False
        
        try:
            asyncio.run(self.tg_capture_html_to_image(html_filename, output_image1, output_image2))
            return True
        except Exception as e:
            print(f"æˆªåœ–å¤±æ•—: {e}")
            return False

    
    async def tg_capture_html_to_image(self, html_file_path, output_image_path1, output_image_path2, 
                                       browser_type='chromium', full_page=True, 
                                       viewport_width=1920, viewport_height=1080):
        """
        å°‡æœ¬åœ° HTML æª”æ¡ˆè½‰æ›ç‚ºåœ–ç‰‡
        
        Args:
            html_file_path: HTML æª”æ¡ˆè·¯å¾‘
            output_image_path1: ç¬¬ä¸€å¼µæˆªåœ–è·¯å¾‘ï¼ˆåŸå§‹é é¢ï¼‰
            output_image_path2: ç¬¬äºŒå¼µæˆªåœ–è·¯å¾‘ï¼ˆé»é¸å¾Œé é¢ï¼‰
            browser_type: ç€è¦½å™¨é¡å‹ ('chromium', 'firefox', 'webkit')
            full_page: æ˜¯å¦æˆªå–å®Œæ•´é é¢
            viewport_width: è¦–çª—å¯¬åº¦
            viewport_height: è¦–çª—é«˜åº¦
        """
        from playwright.async_api import async_playwright
        
        async with async_playwright() as p:
            # å•Ÿå‹•ç€è¦½å™¨
            if browser_type == 'chromium':
                browser = await p.chromium.launch()
            elif browser_type == 'firefox':
                browser = await p.firefox.launch()
            elif browser_type == 'webkit':
                browser = await p.webkit.launch()
            else:
                raise ValueError("ä¸æ”¯æ´çš„ç€è¦½å™¨é¡å‹")
            
            # è½‰æ›ç‚ºçµ•å°è·¯å¾‘
            abs_html_file_path = os.path.abspath(html_file_path)
            file_url = f"file:///{abs_html_file_path.replace(os.sep, '/')}"
            print(f"æ­£åœ¨é–‹å•Ÿ: {file_url}")
            
            page = await browser.new_page()
            await page.set_viewport_size({"width": viewport_width, "height": viewport_height})
            
            try:
                # è¼‰å…¥é é¢
                await page.goto(file_url, wait_until="networkidle")
                await page.wait_for_timeout(2000)
                
                # ç¬¬ä¸€æ¬¡æˆªåœ–ï¼šåŸå§‹é é¢
                print(f"æ­£åœ¨æ“·å–åŸå§‹é é¢åˆ°: {output_image_path1}")
                await page.screenshot(path=output_image_path1, full_page=full_page)
                
                # å°‹æ‰¾é¸è‚¡æŒ‰éˆ• - ä½¿ç”¨å¤šç¨®é¸æ“‡å™¨å˜—è©¦
                selectors = [
                    'a:has-text("é¸è‚¡")',  # ç°¡å–®æ–‡å­—é¸æ“‡å™¨
                    'a[role="tab"]:has-text("é¸è‚¡")',  # å¸¶roleå±¬æ€§
                    '.tab:has-text("é¸è‚¡")',  # classé¸æ“‡å™¨
                    'a.tab-active:has-text("é¸è‚¡")',  # åŸå§‹é¸æ“‡å™¨
                ]
                
                element_found = False
                for selector in selectors:
                    try:
                        print(f"å˜—è©¦é¸æ“‡å™¨: {selector}")
                        await page.wait_for_selector(selector, timeout=5000)
                        print(f"æ‰¾åˆ°é¸è‚¡æŒ‰éˆ•ï¼Œæ­£åœ¨é»é¸...")
                        await page.click(selector)
                        element_found = True
                        break
                    except Exception as e:
                        print(f"é¸æ“‡å™¨ {selector} å¤±æ•—: {e}")
                        continue
                
                if not element_found:
                    print("ç„¡æ³•æ‰¾åˆ°é¸è‚¡æŒ‰éˆ•ï¼Œåˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„é¸é …...")
                    # åˆ—å‡ºæ‰€æœ‰åŒ…å«"é¸è‚¡"çš„å…ƒç´ 
                    elements = await page.query_selector_all('*')
                    for element in elements[:20]:  # åªæª¢æŸ¥å‰20å€‹å…ƒç´ é¿å…å¤ªå¤šè¼¸å‡º
                        text = await element.text_content()
                        if text and "é¸è‚¡" in text:
                            tag_name = await element.evaluate('el => el.tagName')
                            class_name = await element.get_attribute('class')
                            print(f"æ‰¾åˆ°åŒ…å«'é¸è‚¡'çš„å…ƒç´ : {tag_name}, class: {class_name}, text: {text}")
                    
                    # å˜—è©¦ç›´æ¥é»æ“Šä»»ä½•åŒ…å«"é¸è‚¡"æ–‡å­—çš„å…ƒç´ 
                    try:
                        await page.click('text=é¸è‚¡')
                        element_found = True
                        print("ä½¿ç”¨ text=é¸è‚¡ æˆåŠŸé»æ“Š")
                    except:
                        print("æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—")
                
                if element_found:
                    await page.wait_for_timeout(2000)  # ç­‰å¾…é é¢æ›´æ–°
                    
                    # ç¬¬äºŒæ¬¡æˆªåœ–ï¼šé»é¸å¾Œ
                    print(f"æ­£åœ¨æ“·å–é¸è‚¡å¾Œé é¢åˆ°: {output_image_path2}")
                    await page.screenshot(path=output_image_path2, full_page=full_page)
                    print("æ“·å–æˆåŠŸï¼")
                else:
                    print("ç„¡æ³•é»æ“Šé¸è‚¡æŒ‰éˆ•ï¼Œåªä¿å­˜åŸå§‹æˆªåœ–")
                    
            except Exception as e:
                print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
                # é™¤éŒ¯ï¼šå°å‡ºé é¢å…§å®¹
                try:
                    html_content = await page.content()
                    print("é é¢ HTML å…§å®¹ç‰‡æ®µï¼š", html_content[:500])
                except:
                    print("ç„¡æ³•å–å¾—é é¢å…§å®¹")
                    
            finally:
                await browser.close()

    def tg_send_photo(self, bot_token, channel_ids, photo_path, caption=""):
        """
        ç™¼é€åœ–ç‰‡åˆ° Telegram
        
        Args:
            bot_token: Bot token
            channel_ids: é »é“IDåˆ—è¡¨
            photo_path: åœ–ç‰‡è·¯å¾‘
            caption: åœ–ç‰‡èªªæ˜
            
        Returns:
            dict: ç™¼é€çµæœ
        """
        if not os.path.exists(photo_path):
            print(f"åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {photo_path}")
            return {}
            
        url = f"https://api.telegram.org/bot{bot_token}/sendPhoto"
        results = {}
        
        for cid in channel_ids:
            try:
                with open(photo_path, 'rb') as photo:
                    files = {'photo': photo}
                    data = {'chat_id': cid, 'caption': caption}
                    resp = requests.post(url, files=files, data=data)
                    results[cid] = resp.status_code
                    
                    if resp.status_code != 200:
                        print(f"ç™¼é€åœ–ç‰‡è‡³ {cid} å¤±æ•—: {resp.text}")
                    else:
                        print(f"åœ–ç‰‡æˆåŠŸç™¼é€è‡³ {cid}")
                        
            except Exception as e:
                print(f"ç™¼é€åœ–ç‰‡è‡³ {cid} ç™¼ç”ŸéŒ¯èª¤: {e}")
                results[cid] = 0
                
        return results

    def tg_clean_files(self, clean_html=True, clean_images=True):
        """
        æ¸…ç†ç”¢ç”Ÿçš„æª”æ¡ˆ
        
        Args:
            clean_html: æ˜¯å¦åˆªé™¤ HTML æª”æ¡ˆ
            clean_images: æ˜¯å¦åˆªé™¤åœ–ç‰‡æª”æ¡ˆ
        """
        files_to_clean = []
        
        if clean_html and os.path.exists(self.html_file):
            files_to_clean.append(self.html_file)
            
        if clean_images:
            if os.path.exists(self.image_file_1):
                files_to_clean.append(self.image_file_1)
            if os.path.exists(self.image_file_2):
                files_to_clean.append(self.image_file_2)
        
        cleaned_files = []
        for file_path in files_to_clean:
            try:
                os.remove(file_path)
                cleaned_files.append(file_path)
                print(f"å·²åˆªé™¤æª”æ¡ˆ: {file_path}")
            except Exception as e:
                print(f"åˆªé™¤æª”æ¡ˆ {file_path} å¤±æ•—: {e}")
                
        return cleaned_files

    def tg_generate_and_send_complete(self, report, strategy_config, bot_token, channel_ids, 
                                      send_images=True, clean_files=True, 
                                      clean_html=True, clean_images=True):
        """
        å®Œæ•´çš„ç­–ç•¥æ¨é€æµç¨‹ï¼šç”Ÿæˆè¨Šæ¯ -> æˆªåœ– -> ç™¼é€ -> æ¸…ç†
        
        Args:
            report: finlab å›æ¸¬å ±å‘Š
            strategy_config: ç­–ç•¥é…ç½®
            bot_token: Bot token
            channel_ids: é »é“IDåˆ—è¡¨
            send_images: æ˜¯å¦ç™¼é€åœ–ç‰‡
            clean_files: æ˜¯å¦æ¸…ç†æª”æ¡ˆ
            clean_html: æ˜¯å¦åˆªé™¤ HTML æª”æ¡ˆ
            clean_images: æ˜¯å¦åˆªé™¤åœ–ç‰‡æª”æ¡ˆ
            
        Returns:
            dict: åŸ·è¡Œçµæœ
        """
        results = {'message_sent': False, 'images_sent': [], 'files_cleaned': []}
        
        try:
            # 1. ç”Ÿæˆæ–‡å­—è¨Šæ¯ä¸¦ç™¼é€
            msg = self.tg_generate_strategy_message(report, strategy_config)
            
            # ç™¼é€æ–‡å­—è¨Šæ¯
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
            for cid in channel_ids:
                payload = {"chat_id": cid, "text": msg, "parse_mode": "HTML"}
                resp = requests.post(url, json=payload)
                if resp.status_code == 200:
                    results['message_sent'] = True
                    print(f"æ–‡å­—è¨Šæ¯æˆåŠŸç™¼é€è‡³ {cid}")
                else:
                    print(f"æ–‡å­—è¨Šæ¯ç™¼é€è‡³ {cid} å¤±æ•—: {resp.text}")
            
            # 2. å¦‚æœéœ€è¦ç™¼é€åœ–ç‰‡
            if send_images:
                # ç”Ÿæˆæˆªåœ–
                if self.tg_capture_report_images():
                    # ç™¼é€ç¬¬ä¸€å¼µåœ–ç‰‡
                    if os.path.exists(self.image_file_1):
                        result1 = self.tg_send_photo(bot_token, channel_ids, self.image_file_1, "ç­–ç•¥å ±å‘Š - åŸå§‹é é¢")
                        if any(status == 200 for status in result1.values()):
                            results['images_sent'].append(self.image_file_1)
                    
                    # ç™¼é€ç¬¬äºŒå¼µåœ–ç‰‡
                    if os.path.exists(self.image_file_2):
                        result2 = self.tg_send_photo(bot_token, channel_ids, self.image_file_2, "ç­–ç•¥å ±å‘Š - é¸è‚¡é é¢")
                        if any(status == 200 for status in result2.values()):
                            results['images_sent'].append(self.image_file_2)
                else:
                    print("æˆªåœ–å¤±æ•—ï¼Œè·³éåœ–ç‰‡ç™¼é€")
            
            # 3. æ¸…ç†æª”æ¡ˆ
            if clean_files:
                cleaned = self.tg_clean_files(clean_html, clean_images)
                results['files_cleaned'] = cleaned
                
        except Exception as e:
            print(f"å®Œæ•´æ¨é€æµç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        return results



