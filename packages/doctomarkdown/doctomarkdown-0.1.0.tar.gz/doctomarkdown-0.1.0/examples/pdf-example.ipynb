{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb14978",
   "metadata": {},
   "source": [
    "# DocToMarkdown Example Notebook\n",
    "\n",
    "This notebook demonstrates how to use the DocToMarkdown library to convert PDF documents to Markdown using different types of API clients. It showcases both extraction with and without LLM (Large Language Model) support.\n",
    "\n",
    "## Supported API Clients in this Notebook\n",
    "\n",
    "- **Groq API Client**: Use Groq's LLM for PDF-to-Markdown conversion.\n",
    "- **Gemini API Client**: Use Google's Gemini Vision model for advanced extraction.\n",
    "- **Azure OpenAI Client**: Use Azure-hosted OpenAI models (e.g., GPT-4o) for document conversion.\n",
    "- **Ollama API Client**: Use local or remote Ollama models via OpenAI-compatible API.\n",
    "- **No LLM (Standard Extraction)**: Extracts text and images using only local libraries (fitz) without any LLM.\n",
    "\n",
    "Each section below provides example code for initializing and using these clients with DocToMarkdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a161201a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Azure OpenAI client\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from groq import Groq\n",
    "import os\n",
    "from doctomarkdown import DocToMarkdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0da19c",
   "metadata": {},
   "source": [
    "## Groq API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a6c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: \n",
      "# IDRH\n",
      "## Non-text-searchable PDF\n",
      "\n",
      "This is an example of a non-text-searchable PDF. Because it was created from an image rather than a text document, it cannot be rendered as plain text by the PDF reader. Thus, attempting to select the text on the page as though it were a text document or website will not work, regardless of how neatly it is organized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client_groq = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "app = DocToMarkdown(llm_client=client_groq, \n",
    "                    llm_model='meta-llama/llama-4-scout-17b-16e-instruct')\n",
    "\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/Non-text-searchable.pdf\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242b6457",
   "metadata": {},
   "source": [
    "## Extraction without LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abb57fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: IDRH\n",
      "Non-text-searchable PDF\n",
      "\n",
      "This is an example ofa non-text-searchable PDF. Because it was created from\n",
      "an image rather than a text document, it cannot be rendered as plain text by the\n",
      "PDF reader. Thus, attempting to select the text on the page as though it were a\n",
      "text document or website will not work, regardless of how neatly it is organized,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from doctomarkdown import DocToMarkdown\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\sayantghosh\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "app = DocToMarkdown()\n",
    "\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/Non-text-searchable.pdf\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08819cfd",
   "metadata": {},
   "source": [
    "## Gemini API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11814ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: \n",
      "# IDRH\n",
      "## Non-text-searchable PDF\n",
      "\n",
      "This is an example of a non-text-searchable PDF. Because it was created from an image rather than a text document, it cannot be rendered as plain text by the PDF reader. Thus, attempting to select the text on the page as though it were a text document or website will not work, regardless of how neatly it is organized.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import asyncio\n",
    "import google.generativeai as genai\n",
    "from doctomarkdown import DocToMarkdown\n",
    "\n",
    "# Setup Gemini API\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Use Gemini Pro Vision model\n",
    "vision_model = genai.GenerativeModel(\"gemini-1.5-flash\") # CHOOSE YOUR GOOGLE VISION MODEL\n",
    "\n",
    "# Initialize DocToMarkdown with Gemini client\n",
    "app = DocToMarkdown(\n",
    "    llm_client=vision_model\n",
    ")\n",
    "\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/Non-text-searchable.pdf\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e051a74e",
   "metadata": {},
   "source": [
    "## Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cb9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: \n",
      "```\n",
      "IDRH\n",
      "Non-text-searchable PDF\n",
      "\n",
      "This is an example of a non-text-searchable PDF. Because it was created from\n",
      "an image rather than a text document, it cannot be rendered as plain text by the\n",
      "PDF reader. Thus, attempting to select the text on the page as though it were a\n",
      "text document or website will not work, regardless of how neatly it is organized.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "clinet = AzureOpenAI(\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "app = DocToMarkdown(llm_client=clinet, \n",
    "                    llm_model='gpt-4o')\n",
    "\n",
    "\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/Non-text-searchable.pdf\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f148a28",
   "metadata": {},
   "source": [
    "## Ollama API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c323d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Number: 1 | Page Content: \n",
      "# IDRH\n",
      "\n",
      "Non-text-searchable PDF\n",
      "\n",
      "This is an example of a non-text-searchable PDF. Because it was created from an image rather than a text document, it cannot be rendered as plain text by the PDF reader. Thus, attempting to select the text on the page as though it were a text document or website will not work, regardless of how neatly it is organized.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "ollama_client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "app = DocToMarkdown(llm_client=ollama_client, \n",
    "                    llm_model='gemma3:4b')\n",
    "result = app.convert_pdf_to_markdown(\n",
    "    filepath=\"sample_docs/Non-text-searchable.pdf\",\n",
    "    extract_images=True,\n",
    "    extract_tables=True,\n",
    "    output_path=\"markdown_output\"\n",
    ")\n",
    "\n",
    "for page in result.pages:\n",
    "    print(f\"Page Number: {page.page_number} | Page Content: {page.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef702f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
