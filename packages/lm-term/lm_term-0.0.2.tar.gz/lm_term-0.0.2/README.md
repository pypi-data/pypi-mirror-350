<p align="right">
<a href="https://pypi.org/project/llm-console/" target="_blank"><img src="https://badge.fury.io/py/llm-console.svg" alt="PYPI Release"></a>
<a href="https://github.com/Nayjest/LLM-Console/actions/workflows/code-style.yml" target="_blank"><img src="https://github.com/Nayjest/LLM-Console/actions/workflows/code-style.yml/badge.svg" alt="Code Style"></a>
<a href="https://github.com/Nayjest/LLM-Console/actions/workflows/tests.yml" target="_blank"><img src="https://github.com/Nayjest/LLM-Console/actions/workflows/tests.yml/badge.svg" alt="Tests"></a>
<a href="https://github.com/Nayjest/LLM-Console/blob/main/LICENSE" target="_blank"><img src="https://img.shields.io/static/v1?label=license&message=MIT&color=d08aff" alt="License"></a>
</p>

# LM-Term

**LM-Term** is a cross-platform vendor-agnostic command-line interface for LLMs.

**Development Status**: bookmark it and go away, it is still in early development.

## ‚ú® Features

- @todo
- Flexible configuration via [`.env` file](https://github.com/Nayjest/LLM-Console/blob/main/.env.example)
- Extremely fast, parallel LLM usage
- Model-agnostic (OpenAI, Anthropic, Google, local PyTorch inference, etc.)


## üöÄ Quickstart
```bash
# Install LLM Console via pip
pip install lm-term

# Run the interactive wizard to configure the connection to your language model.
llm configure

# Talk to your Language Model
llm "Wazzup, LLM"
```

## ü§ù Contributing

We ‚ù§Ô∏è contributions! See [CONTRIBUTING.md](CONTRIBUTING.md).

## üìù License

Licensed under the [MIT License](LICENSE).

¬© 2022&mdash;2025 [Vitalii Stepanenko](mailto:mail@vitaliy.in)
