Metadata-Version: 2.3
Name: ragql
Version: 0.1.0
Summary: This project implements a local-first RAG chat system that reads and processes various text-based log files. It splits the content into manageable chunks, generates embeddings using Ollama or OpenAI, and allows users to interactively query the logs for specific information. The application features a customizable response format and supports configuration for user preferences.
Author: Cristian Camargo Filho
Author-email: ccf@cdone.com.br
Requires-Python: >=3.10,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: faiss-cpu (>=1.11,<2.0)
Requires-Dist: numpy (>=2.2.6,<3.0.0)
Requires-Dist: ollama (>=0.4.8,<0.5.0)
Requires-Dist: openai (>=1.25,<2.0)
Requires-Dist: pandas (>=2.2,<3.0)
Requires-Dist: python-dotenv (>=1.1.0,<2.0.0)
Requires-Dist: requests (>=2.32,<3.0)
Requires-Dist: tabulate (>=0.9,<0.10)
Requires-Dist: tqdm (>=4.67,<5.0)
Description-Content-Type: text/markdown


1. **Initialize the venv:**

```shell
py -m venv .venv
```

2. **Activate the requirements:**

```shell
.\.venv\Scripts\activate
```

3. **Install the requirements:**

```
python -m pip install --upgrade pip wheel setuptools
```

4. **Install the requirements**

```
python -m pip install -r requirements.txt
```

5. **Run inside ollama the `nomic-embed-text` embeddings model just to verify and test if that works:**

```shell
ollama serve               # make sure itâ€™s running
ollama pull nomic-embed-text
curl -X POST http://localhost:11434/api/embeddings \
     -d '{"model":"nomic-embed-text","prompt":"hello"}'
```


