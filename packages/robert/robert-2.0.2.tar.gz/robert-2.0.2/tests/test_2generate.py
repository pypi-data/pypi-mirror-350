#!/usr/bin/env python

######################################################.
# 	        Testing GENERATE with pytest 	         #
######################################################.

import os
import glob
import pytest
import shutil
import subprocess
import pandas as pd
from pathlib import Path

# saves the working directory
path_main = os.getcwd()
path_generate = os.getcwd() + "/GENERATE"

# GENERATE tests
@pytest.mark.parametrize(
    "test_job",
    [
        (
            "reduced"
        ),  # test with less models and partition sizes
        (
            "reduced_noPFI"
        ),  # test to disable the PFI analysis
        (
            "reduced_PFImax"
        ),  # test to select the number of PFI features
        (
            "reduced_kfold"
        ),  # test with different kfold and repetitions
        (
            "reduced_gp"
        ),  # test for other GP model (important since PFI filter gives different results compared to standard)        
        (
            "reduced_adab"
        ),  # test for other GP model (important since PFI filter tries to discard all the descriptors)     
        (
            "reduced_clas"
        ),  # test for clasification models
        (
            "standard"
        ),  # standard test
    ],
)
def test_GENERATE(test_job):

    # leave the folders as they were initially to run a different batch of tests
    if os.path.exists(f"{path_generate}"):
        shutil.rmtree(f"{path_generate}")
        # remove DAT and CSV files generated by GENERATE
        dat_files = glob.glob("*.dat")
        for dat_file in dat_files:
            if "GENERATE" in dat_file:
                os.remove(dat_file)
    if test_job == 'reduced_clas' and os.path.exists(f"{path_main}/GENERATE_clas"):
        shutil.rmtree(f"{path_main}/GENERATE_clas")

    # runs the program with the different tests
    if test_job == 'reduced_clas':
        csv_name = 'tests/Robert_example_clas.csv'
    else:
        csv_name = 'CURATE/Robert_example_CURATE.csv'

    cmd_robert = [
        "python",
        "-m",
        "robert",
        "--generate",
        "--csv_name", csv_name,
        '--y', 'Target_values',
        ]

    if test_job != 'standard':
        # add model
        if test_job not in ['reduced_gp','reduced_adab']:
            model_list = ['RF']
        elif test_job == 'reduced_gp':
            model_list = ['GP']
        elif test_job == 'reduced_adab':
            model_list = ['Adab']

        # adjust cmd for tests
        if test_job == "reduced_noPFI":
            cmd_robert = cmd_robert + ["--pfi_filter", "False"]
        elif test_job == 'reduced_PFImax':
            cmd_robert = cmd_robert + ["--pfi_max", "1"]
        elif test_job == "reduced_kfold":
            cmd_robert = cmd_robert + ["--kfold", "10", "--repeat_kfolds", "5"]
        elif test_job in ['reduced_clas']:
            cmd_robert = cmd_robert + ["--type", "clas"]
        
        cmd_robert = cmd_robert + ['--init_points', '1',
                                   '--n_iter', '1']
        
    else: # needed to define the variables, change if default options change
        model_list = ['RF','GB','NN','MVL']
    
    cmd_robert = cmd_robert + [
        "--model", f"{model_list}"]
    
    subprocess.run(cmd_robert)

    if test_job not in []:  
        # check that the DAT file is created
        assert not os.path.exists(f"{path_main}/GENERATE_data.dat")
        outfile = open(f"{path_generate}/GENERATE_data.dat", "r")
        outlines = outfile.readlines()
        outfile.close()
        assert "ROBERT v" in outlines[0]
        assert "- 37 datapoints" in outlines[9]
        if test_job == 'reduced_clas':
            assert "- 9 accepted descriptors" in outlines[10]
        else:
            assert "- 10 accepted descriptors" in outlines[10]
        assert "- 1 ignored descriptors" in outlines[11]
        assert "- 0 discarded descriptors" in outlines[12]

        # find GENERATE evaluation
        finding_line = 0
        reproducibility = 0
        finding_changed_kfold = 0
        for line in outlines:
            if f"o Starting BO-based hyperoptimization using the combined target:" in line:
                finding_line += 1
            elif f"1. 50% = RMSE from a 10x repeated 5-fold CV (interpoplation)" in line:
                finding_line += 1
            elif f"2. 50% = RMSE from the bottom or top (worst performing) fold in a sorted 5-fold CV (extrapolation)" in line:
                finding_line += 1
            elif f"o  Before hyperoptimization, 20% of the data (or 4 points at least) was separated as test set, using an even distribution of data points across the range of y values." in line:
                finding_line += 0.5 # it appears two times, in PFI and no PFI
                # this elif adds 4 points to the standard test (0.5*2(PFI and no PFI)*4(models)
            elif f"o Best combined RMSE (target) found in BO for RF (no PFI filter): 0.53" in line:
                reproducibility += 1
            elif f"o Combined RMSE for RF (with PFI filter): 0.58" in line:
                reproducibility += 1
            # lines only for standard
            elif f"- 1/4 - ML model: RF" in line:
                finding_line += 1
            elif f"- 2/4 - ML model: GB" in line:
                finding_line += 1
            elif f"- 3/4 - ML model: NN" in line:
                finding_line += 1
            elif f"- 4/4 - ML model: MVL" in line:
                finding_line += 1
            elif f'o Best combined RMSE (target) found in BO for RF (no PFI filter): 0.52' in line:
                reproducibility += 1
            elif f"o Combined RMSE for RF (with PFI filter): 0.54" in line:
                reproducibility += 1
            elif f"o Best combined RMSE (target) found in BO for GB (no PFI filter): 0.39" in line:
                reproducibility += 1
            elif f"o Combined RMSE for GB (with PFI filter): 0.35" in line:
                reproducibility += 1
            elif f"o Best combined RMSE (target) found in BO for NN (no PFI filter): 0.33" in line:
                reproducibility += 1
            elif f"o Combined RMSE for NN (with PFI filter): 0.38" in line:
                reproducibility += 1
            elif f'o Combined RMSE for MVL (no BO needed) (no PFI filter): 0.45' in line:
                reproducibility += 1
            elif f"o Combined RMSE for MVL (with PFI filter): 0.38" in line:
                reproducibility += 1
            # lines only for
            elif f"1. 50% = RMSE from a 5x repeated 10-fold CV (interpoplation)" in line:
                finding_changed_kfold += 1

        if test_job == "reduced_noPFI":
            assert finding_line == 3.5
            assert reproducibility == 1
        elif test_job == "reduced":
            assert finding_line == 4
            assert reproducibility == 2
        if test_job == 'standard':
            assert finding_line == 11
            assert reproducibility == 8
        if test_job == "reduced_kfold":
            assert finding_changed_kfold == 1

        # check that the right amount of CSV files were created
        expected_amount = len(model_list) * 2
        if test_job != "reduced_noPFI":
            folders = ['No_PFI','PFI']
        else:
            folders = ['No_PFI']
            assert not os.path.exists(f'{path_generate}/Raw_data/PFI')

        for folder in folders:
            csv_amount = glob.glob(f'{path_generate}/Raw_data/{folder}/*.csv')
            assert expected_amount == len(csv_amount)

            best_amount = glob.glob(f'{path_generate}/Best_model/{folder}/*.csv')
            assert len(best_amount) == 2
            params_best = pd.read_csv(best_amount[0])
            db_best = pd.read_csv(best_amount[1])
            if test_job in ['reduced','reduced_PFImax','reduced_gp','reduced_adab']:
                if folder == 'No_PFI':
                    if test_job in ['reduced','reduced_PFImax','reduced_gp','reduced_adab']:
                        desc_list = ['x2', 'x7', 'x8', 'x9', 'x10', 'x11', 'ynoise', 'Csub-Csub', 'Csub-H', 'H-O']
                    elif test_job == 'reduced_clas':
                        desc_list = ['x1', 'x2', 'x3', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10']
                elif folder == 'PFI':
                    if test_job == 'reduced':
                        desc_list = ['x7', 'x10']
                    elif test_job == 'reduced_PFImax':
                        desc_list = ['x10']
                    elif test_job == 'reduced_gp':
                        desc_list = ['ynoise', 'Csub-Csub', 'Csub-H', 'x7', 'x10', 'x9']
                    elif test_job == 'reduced_adab':
                        desc_list = ['x2', 'x7', 'x10']

                if test_job in ['reduced']:
                    sum_split = 0
                    if db_best['Set'][0] == 'Training':
                        sum_split += 1
                    if db_best['Set'][1] == 'Training':
                        sum_split += 1
                    if db_best['Set'][2] == 'Training':
                        sum_split += 1
                    if db_best['Set'][3] == 'Test':
                        sum_split += 1
                    if db_best['Set'][4] == 'Test':
                        sum_split += 1            
                    if test_job == 'reduced':
                        assert sum_split == 5
                for var in desc_list:
                    assert var in params_best['X_descriptors'][0]
                assert len(desc_list) == len(params_best['X_descriptors'][0].split(','))
    
        # check that the heatmap plots were generated
        assert os.path.exists(f'{path_generate}/Raw_data/Heatmap_ML_models_No_PFI.png')
        if test_job != "reduced_noPFI":
            assert os.path.exists(f'{path_generate}/Raw_data/Heatmap_ML_models_PFI.png')
        else:
            assert not os.path.exists(f'{path_generate}/Raw_data/Heatmap_ML_models_PFI.png')

        # Check that the default metric for classification models is MCC
        if test_job == 'reduced_clas':
            csv_clas = glob.glob(f'{path_generate}/Best_model/PFI/RF_PFI.csv')
            df = pd.read_csv(csv_clas[0])
            if 'error_type' in df.columns:
                error_types = df['error_type'].tolist()
            assert 'mcc' in error_types

    if test_job == 'reduced_clas':
        filepath = Path(f"{path_generate}")
        filepath.rename(f"{path_main}/GENERATE_clas")
