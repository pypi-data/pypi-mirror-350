#!/usr/bin/env python3
"""
æ•°æ®å¤„ç†è®¡ç®—èŠ‚ç‚¹
å¤„ç†å®æ—¶ä¼ æ„Ÿå™¨æ•°æ®æµå¹¶è¿”å›ç»Ÿè®¡åˆ†æç»“æœ
"""
import asyncio
import time
import random
import numpy as np
import logging
from typing import Dict, List, Generator
from datetime import datetime
from easyremote import ComputeNode

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SensorDataProcessor:
    """ä¼ æ„Ÿå™¨æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.data_buffer = {
            'temperature': [],
            'humidity': [],
            'pressure': []
        }
        self.window_size = 10
        
    def generate_sensor_data(self, sensor_type: str) -> float:
        """ç”Ÿæˆæ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•°æ®"""
        base_values = {
            'temperature': 25.0,  # Â°C
            'humidity': 60.0,     # %
            'pressure': 1013.25   # hPa
        }
        
        # æ·»åŠ ä¸€äº›éšæœºå˜åŒ–å’Œè¶‹åŠ¿
        base = base_values.get(sensor_type, 0.0)
        noise = random.gauss(0, 0.5)
        trend = 0.1 * np.sin(time.time() / 100)  # ç¼“æ…¢çš„å‘¨æœŸæ€§å˜åŒ–
        
        return round(base + noise + trend, 2)
    
    def update_buffer(self, sensor_type: str, value: float):
        """æ›´æ–°æ•°æ®ç¼“å†²åŒº"""
        if sensor_type in self.data_buffer:
            self.data_buffer[sensor_type].append(value)
            if len(self.data_buffer[sensor_type]) > self.window_size:
                self.data_buffer[sensor_type].pop(0)
    
    def calculate_statistics(self, sensor_type: str) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        data = self.data_buffer.get(sensor_type, [])
        if not data:
            return {}
            
        return {
            'mean': round(np.mean(data), 2),
            'std': round(np.std(data), 2),
            'min': round(np.min(data), 2),
            'max': round(np.max(data), 2),
            'trend': self._calculate_trend(data),
            'samples': len(data)
        }
    
    def _calculate_trend(self, data: List[float]) -> str:
        """è®¡ç®—è¶‹åŠ¿æ–¹å‘"""
        if len(data) < 3:
            return 'insufficient_data'
            
        recent = data[-3:]
        if recent[-1] > recent[0]:
            return 'increasing'
        elif recent[-1] < recent[0]:
            return 'decreasing'
        else:
            return 'stable'

# åˆ›å»ºè®¡ç®—èŠ‚ç‚¹
node = ComputeNode("localhost:8080", node_id="data-node")
processor = SensorDataProcessor()

@node.register(stream=True, name="process_sensor_data_stream")
def process_sensor_data_stream(sensor_config: dict) -> Generator[Dict, None, None]:
    """
    å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®æµ
    
    Args:
        sensor_config: ä¼ æ„Ÿå™¨é…ç½®
            - sensors: ä¼ æ„Ÿå™¨ç±»å‹åˆ—è¡¨
            - sample_rate: é‡‡æ ·ç‡ (samples/second)
            - duration: æŒç»­æ—¶é—´ (seconds)
    
    Yields:
        Dict: å®æ—¶åˆ†æç»“æœ
    """
    sensors = sensor_config.get('sensors', ['temperature'])
    sample_rate = sensor_config.get('sample_rate', 1)
    duration = sensor_config.get('duration', 30)
    
    interval = 1.0 / sample_rate
    start_time = time.time()
    sample_count = 0
    
    logger.info(f"ğŸ“Š Starting sensor data stream: {sensors}")
    logger.info(f"ğŸ“ˆ Sample rate: {sample_rate} Hz, Duration: {duration}s")
    
    try:
        while time.time() - start_time < duration:
            current_time = datetime.now()
            readings = {}
            statistics = {}
            
            # ç”Ÿæˆå¹¶å¤„ç†æ¯ä¸ªä¼ æ„Ÿå™¨çš„æ•°æ®
            for sensor_type in sensors:
                # ç”Ÿæˆä¼ æ„Ÿå™¨è¯»æ•°
                value = processor.generate_sensor_data(sensor_type)
                readings[sensor_type] = value
                
                # æ›´æ–°ç¼“å†²åŒº
                processor.update_buffer(sensor_type, value)
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                statistics[sensor_type] = processor.calculate_statistics(sensor_type)
            
            sample_count += 1
            
            # æ„é€ è¿”å›ç»“æœ
            result = {
                'timestamp': current_time.isoformat(),
                'sample_id': sample_count,
                'elapsed_time': round(time.time() - start_time, 2),
                'readings': readings,
                'statistics': statistics,
                'health_status': 'healthy',
                'node_id': 'data-node'
            }
            
            # æ£€æµ‹å¼‚å¸¸å€¼
            anomalies = []
            for sensor_type, stats in statistics.items():
                if stats and stats.get('std', 0) > 2.0:  # æ ‡å‡†å·®è¿‡å¤§
                    anomalies.append(f"{sensor_type}_high_variance")
            
            if anomalies:
                result['anomalies'] = anomalies
                result['health_status'] = 'warning'
            
            yield result
            
            # ç­‰å¾…ä¸‹ä¸€ä¸ªé‡‡æ ·é—´éš”
            time.sleep(interval)
            
    except Exception as e:
        logger.error(f"âŒ Error in sensor data stream: {e}")
        yield {
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'health_status': 'error',
            'node_id': 'data-node'
        }
    
    logger.info(f"âœ… Sensor data stream completed: {sample_count} samples")

@node.register(name="get_sensor_status")
def get_sensor_status() -> Dict:
    """è·å–ä¼ æ„Ÿå™¨çŠ¶æ€"""
    return {
        'node_id': 'data-node',
        'status': 'online',
        'available_sensors': ['temperature', 'humidity', 'pressure'],
        'buffer_size': processor.window_size,
        'current_data': {
            sensor: len(data) for sensor, data in processor.data_buffer.items()
        },
        'capabilities': {
            'max_sample_rate': 100,  # Hz
            'max_duration': 3600,    # seconds
            'real_time_analysis': True,
            'anomaly_detection': True
        }
    }

@node.register(name="reset_data_buffer")
def reset_data_buffer() -> Dict:
    """é‡ç½®æ•°æ®ç¼“å†²åŒº"""
    processor.data_buffer = {
        'temperature': [],
        'humidity': [],
        'pressure': []
    }
    return {
        'node_id': 'data-node',
        'status': 'buffer_reset',
        'timestamp': datetime.now().isoformat()
    }

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ Starting Data Processing Node...")
    logger.info("ğŸ“Š Registered functions:")
    logger.info("  - process_sensor_data_stream (streaming)")
    logger.info("  - get_sensor_status")
    logger.info("  - reset_data_buffer")
    
    try:
        node.serve(blocking=True)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  Received shutdown signal")
        node.stop()
        logger.info("âœ… Data node stopped gracefully")

if __name__ == "__main__":
    asyncio.run(main()) 