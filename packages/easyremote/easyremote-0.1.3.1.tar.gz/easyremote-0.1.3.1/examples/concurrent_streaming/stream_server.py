#!/usr/bin/env python3
"""
å¹¶å‘æµå¼ä»»åŠ¡æœåŠ¡å™¨
æ”¯æŒåŒæ—¶è¿è¡Œå¤šä¸ªæµå¼ä»»åŠ¡çš„VPSæœåŠ¡å™¨
"""
import asyncio
import logging
from easyremote import Server, remote
from easyremote import get_performance_monitor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class StreamingServer:
    """æµå¼ä»»åŠ¡æœåŠ¡å™¨"""
    
    def __init__(self, port: int = 8080):
        self.port = port
        self.server = Server(port=port, max_queue_size=1000)
        self.performance_monitor = get_performance_monitor()
        
    async def start(self):
        """å¯åŠ¨æœåŠ¡å™¨å’Œæ€§èƒ½ç›‘æ§"""
        logger.info("ğŸš€ Starting EasyRemote Streaming Server...")
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        await self.performance_monitor.start()
        logger.info("ğŸ“Š Performance monitor started")
        
        # å¯åŠ¨æœåŠ¡å™¨
        logger.info(f"ğŸŒ Server starting on port {self.port}")
        logger.info("Waiting for compute nodes to connect...")
        logger.info("Available streaming functions:")
        logger.info("  - data_node: process_sensor_data_stream (real-time data analysis)")
        logger.info("  - ml_node: classify_image_stream (AI inference)")
        
        # é˜»å¡è¿è¡ŒæœåŠ¡å™¨
        self.server.start()
        
    async def stop(self):
        """åœæ­¢æœåŠ¡å™¨"""
        logger.info("ğŸ›‘ Stopping server...")
        await self.performance_monitor.stop()
        await self.server.stop()

# æ³¨å†Œè¿œç¨‹æµå¼å‡½æ•°ï¼ˆç”±è®¡ç®—èŠ‚ç‚¹å®ç°ï¼‰
@remote(node_id="data-node")
def process_sensor_data_stream(sensor_config: dict):
    """
    å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®æµ
    Args:
        sensor_config: ä¼ æ„Ÿå™¨é…ç½® {'sensors': [...], 'sample_rate': 100, 'duration': 60}
    Returns:
        Generator yielding analysis results
    """
    pass

@remote(node_id="ml-node") 
def classify_image_stream(model_config: dict):
    """
    å›¾åƒåˆ†ç±»æµå¼æ¨ç†
    Args:
        model_config: æ¨¡å‹é…ç½® {'model_name': 'resnet50', 'batch_size': 8, 'num_images': 100}
    Returns:
        Generator yielding classification results
    """
    pass

@remote(node_id="data-node")
def get_sensor_status() -> dict:
    """è·å–ä¼ æ„Ÿå™¨çŠ¶æ€ï¼ˆéæµå¼ï¼‰"""
    pass

@remote(node_id="ml-node")
def get_model_info() -> dict:
    """è·å–æ¨¡å‹ä¿¡æ¯ï¼ˆéæµå¼ï¼‰"""
    pass

def execute_concurrent_streams():
    """
    æ¼”ç¤ºå¹¶å‘æ‰§è¡Œä¸¤ä¸ªæµå¼ä»»åŠ¡
    è¿™ä¸ªå‡½æ•°å¯ä»¥è¢«å®¢æˆ·ç«¯è°ƒç”¨æ¥å¯åŠ¨å¹¶å‘æµ
    """
    try:
        server = Server.current()
        
        # é…ç½®æ•°æ®å¤„ç†æµ
        sensor_config = {
            'sensors': ['temperature', 'humidity', 'pressure'],
            'sample_rate': 10,  # 10 samples/second
            'duration': 30      # 30 seconds
        }
        
        # é…ç½®MLæ¨ç†æµ  
        model_config = {
            'model_name': 'mobilenet_v2',
            'batch_size': 4,
            'num_images': 50
        }
        
        logger.info("ğŸ”„ Starting concurrent streaming tasks...")
        
        # å¯åŠ¨æ•°æ®å¤„ç†æµ
        data_stream = process_sensor_data_stream(sensor_config)
        logger.info("ğŸ“Š Data processing stream started")
        
        # å¯åŠ¨MLæ¨ç†æµ
        ml_stream = classify_image_stream(model_config)
        logger.info("ğŸ¤– ML inference stream started")
        
        return {
            'data_stream': data_stream,
            'ml_stream': ml_stream,
            'status': 'concurrent_streams_started'
        }
        
    except Exception as e:
        logger.error(f"âŒ Error starting concurrent streams: {e}")
        return {'error': str(e)}

async def main():
    """ä¸»å‡½æ•°"""
    server = StreamingServer(port=8080)
    
    try:
        await server.start()
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  Received shutdown signal")
        await server.stop()
        logger.info("âœ… Server stopped gracefully")

if __name__ == "__main__":
    asyncio.run(main()) 