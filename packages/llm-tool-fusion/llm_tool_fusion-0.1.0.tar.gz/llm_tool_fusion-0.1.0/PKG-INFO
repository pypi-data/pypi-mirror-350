Metadata-Version: 2.4
Name: llm-tool-fusion
Version: 0.1.0
Summary: Biblioteca Python que simplifica e unifica a definiÃ§Ã£o e chamada de ferramentas para grandes modelos de linguagem (LLMs). CompatÃ­vel com Ollama, LangChain, OpenAI e outros frameworks.
Home-page: https://github.com/caua1503/llm-tool-fusion
Author: Caua ramos
Author-email: cauamedinax@gmail.com
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENSE
Dynamic: author
Dynamic: author-email
Dynamic: home-page
Dynamic: license-file

# llm-tool-fusion

[![Python](https://img.shields.io/badge/python->=3.12-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/version-0.1.0-orange.svg)](pyproject.toml)

## ğŸ‡§ğŸ‡· PortuguÃªs

### ğŸ“– DescriÃ§Ã£o

**llm-tool-fusion** Ã© uma biblioteca Python que simplifica e unifica a definiÃ§Ã£o e chamada de ferramentas para grandes modelos de linguagem (LLMs). CompatÃ­vel com frameworks populares que suportam tool calling, como Ollama, LangChain e OpenAI, ela permite integrar facilmente novas funÃ§Ãµes e mÃ³dulos, tornando o desenvolvimento de aplicativos avanÃ§ados de IA mais Ã¡gil e modular.

### âœ¨ Principais Recursos

- ğŸ”§ **UnificaÃ§Ã£o de APIs**: Interface Ãºnica para diferentes frameworks de LLM
- ğŸš€ **IntegraÃ§Ã£o Simplificada**: Adicione novas ferramentas com facilidade
- ğŸ”— **Compatibilidade Ampla**: Suporte para Ollama, LangChain, OpenAI e outros
- ğŸ“¦ **Modularidade**: Arquitetura modular para desenvolvimento escalÃ¡vel
- âš¡ **Performance**: Otimizado para aplicaÃ§Ãµes em produÃ§Ã£o

### ğŸš€ InstalaÃ§Ã£o

```bash
pip install llm-tool-fusion
```

### ğŸ“‹ Uso BÃ¡sico (Exemplo com OpenAI)

```python
from llm_tool_fusion import ToolManager
from openai import OpenAI

client = OpenAI()

# Inicialize o gerenciador de ferramentas
manager = ToolManager()

# Adicione suas ferramentas personalizadas
@manager.tool
def multiply(numero1: int, numero2: int) -> int:
    """
    Multiplica doi numeros
    Args:
        numero1: int
        numero2: int
    Returns:
        int
    """

    return numero1 * numero2

response = client.responses.create(
    model="gpt-4.1",
    input=[{"role": "user", "content": "Quanto e 25 * 557 ?"}],
    tools=manager.get_tools()
)

print(response.output)
# Use com seu framework preferido
# Exemplo com OpenAI, LangChain, Ollama, etc.
```

### ğŸ”§ Frameworks Suportados

- **OpenAI** - API oficial e modelos GPT
- **LangChain** - Framework completo para aplicaÃ§Ãµes LLM
- **Ollama** - ExecuÃ§Ã£o local de modelos
- **Anthropic Claude** - API da Anthropic
- **E muito mais...**

### ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ‡ºğŸ‡¸ English

### ğŸ“– Description

**llm-tool-fusion** is a Python library that simplifies and unifies tool definition and calling for Large Language Models (LLMs). Compatible with popular frameworks that support tool calling, such as Ollama, LangChain, and OpenAI, it allows easy integration of new functions and modules, making advanced AI application development more agile and modular.

### âœ¨ Key Features

- ğŸ”§ **API Unification**: Single interface for different LLM frameworks
- ğŸš€ **Simplified Integration**: Add new tools with ease
- ğŸ”— **Wide Compatibility**: Support for Ollama, LangChain, OpenAI, and others
- ğŸ“¦ **Modularity**: Modular architecture for scalable development
- âš¡ **Performance**: Optimized for production applications

### ğŸš€ Installation

```bash
pip install llm-tool-fusion
```

### ğŸ“‹ Basic Usage (Example with OpenAI)

```python
from llm_tool_fusion import ToolManager
from openai import OpenAI

client = OpenAI()

# Inicialize o gerenciador de ferramentas
manager = ToolManager()

# Adicione suas ferramentas personalizadas
@manager.tool
def multiply(number1: int, number2: int) -> int:
    """
    Multiplies two numbers
    Args:
        number1: int
        number2: int
    Returns:
        int
    """

    return number1 * number2

response = client.responses.create(
    model="gpt-4.1",
    input=[{"role": "user", "content": "what is 25 * 557 ?"}],
    tools=manager.get_tools()
)

print(response.output)

# Use with your preferred framework
# Example with OpenAI, LangChain, Ollama, etc.
```

### ğŸ”§ Supported Frameworks

- **OpenAI** - Official API and GPT models
- **LangChain** - Complete framework for LLM applications
- **Ollama** - Local model execution
- **Anthropic Claude** - Anthropic's API
- **And many more...**

### ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ› ï¸ Development

### Prerequisites

- Python >= 3.12
- pip or poetry for dependency management

### Setup Development Environment

```bash
# Clone the repository
git clone https://github.com/caua1503/llm-tool-fusion.git
cd llm-tool-fusion

# Install dependencies
pip install -e .

# Run tests
python -m pytest
```

### Project Structure

```
llm-tool-fusion/
â”œâ”€â”€ llm_tool_fusion/
â”‚   â””â”€â”€ __init__.py
|   â””â”€â”€ _core.py
|   â””â”€â”€ _utils.py
â”‚      
â”œâ”€â”€ tests/
â”œâ”€â”€ examples/
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no GitHub!**

**â­ If this project was helpful to you, consider starring it on GitHub!**
